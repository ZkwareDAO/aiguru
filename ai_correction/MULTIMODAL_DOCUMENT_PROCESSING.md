# å¤šæ¨¡æ€å¤§æ¨¡å‹æ–‡æ¡£å¤„ç†æ–¹æ¡ˆ

## ğŸ¯ æŠ€æœ¯æ¦‚è¿°

æœ¬ç³»ç»Ÿé‡‡ç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹æŠ€æœ¯ï¼Œç›´æ¥å¤„ç†å„ç§æ–‡æ¡£æ ¼å¼ï¼Œæ— éœ€ä¼ ç»Ÿçš„OCRæ–‡å­—è¯†åˆ«æ­¥éª¤ã€‚é€šè¿‡å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œç³»ç»Ÿèƒ½å¤Ÿç†è§£æ–‡æ¡£çš„å†…å®¹ã€ç»“æ„å’Œè¯­ä¹‰ã€‚

## ğŸ”§ æ ¸å¿ƒæŠ€æœ¯æ¶æ„

### å¤šæ¨¡æ€å¤„ç†æµç¨‹

```
æ–‡æ¡£è¾“å…¥ â†’ æ ¼å¼æ£€æµ‹ â†’ å¤šæ¨¡æ€æ¨¡å‹å¤„ç† â†’ å†…å®¹ç†è§£ â†’ ç»“æœè¾“å‡º
```

### æ”¯æŒçš„æ¨¡å‹

- **Google Gemini 2.5 Flash**: ä¸»è¦æ¨¡å‹ï¼Œæ”¯æŒå›¾åƒå’Œæ–‡æœ¬ç†è§£
- **Claude 3 Haiku**: å¤‡ç”¨æ¨¡å‹ï¼Œä¼˜ç§€çš„æ–‡æ¡£ç†è§£èƒ½åŠ›
- **GPT-4 Vision**: å¯é€‰æ¨¡å‹ï¼Œå¼ºå¤§çš„è§†è§‰ç†è§£

## ğŸ“„ æ–‡æ¡£å¤„ç†ç­–ç•¥

### 1. PDFæ–‡æ¡£å¤„ç†

**ä¼ ç»Ÿæ–¹æ¡ˆï¼ˆå·²åºŸå¼ƒï¼‰**:
```python
# æ—§æ–¹æ¡ˆï¼šPDF â†’ OCR â†’ æ–‡æœ¬æå–
pdf_text = extract_text_with_ocr(pdf_file)
```

**æ–°æ–¹æ¡ˆï¼ˆå¤šæ¨¡æ€ï¼‰**:
```python
# æ–°æ–¹æ¡ˆï¼šPDF â†’ å›¾åƒ â†’ å¤šæ¨¡æ€æ¨¡å‹ç›´æ¥ç†è§£
def process_pdf_with_multimodal(pdf_path):
    # å°†PDFè½¬æ¢ä¸ºé«˜è´¨é‡å›¾åƒ
    images = convert_pdf_to_images(pdf_path)
    
    # ç›´æ¥å‘é€ç»™å¤šæ¨¡æ€å¤§æ¨¡å‹
    results = []
    for image in images:
        result = multimodal_model.process(
            image=image,
            prompt="è¯·ç†è§£è¿™ä¸ªæ–‡æ¡£é¡µé¢çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ–‡å­—ã€å›¾è¡¨ã€å…¬å¼ç­‰"
        )
        results.append(result)
    
    return combine_results(results)
```

### 2. å›¾åƒæ–‡æ¡£å¤„ç†

```python
def process_image_document(image_path):
    # ç›´æ¥å¤„ç†å›¾åƒï¼Œæ— éœ€é¢„å¤„ç†
    return multimodal_model.process(
        image=image_path,
        prompt="è¯·åˆ†æè¿™ä¸ªå›¾åƒä¸­çš„æ–‡æ¡£å†…å®¹"
    )
```

### 3. Wordæ–‡æ¡£å¤„ç†

```python
def process_word_document(word_path):
    # æå–æ–‡æœ¬å†…å®¹
    text_content = extract_word_text(word_path)
    
    # å¦‚æœåŒ…å«å›¾åƒï¼Œä¹Ÿæå–å›¾åƒ
    images = extract_word_images(word_path)
    
    if images:
        # å¤šæ¨¡æ€å¤„ç†ï¼šæ–‡æœ¬ + å›¾åƒ
        return multimodal_model.process(
            text=text_content,
            images=images,
            prompt="è¯·ç†è§£è¿™ä¸ªWordæ–‡æ¡£çš„å®Œæ•´å†…å®¹"
        )
    else:
        # çº¯æ–‡æœ¬å¤„ç†
        return text_model.process(text_content)
```

## ğŸš€ ä¼˜åŠ¿å¯¹æ¯”

### ä¼ ç»ŸOCRæ–¹æ¡ˆ vs å¤šæ¨¡æ€å¤§æ¨¡å‹

| ç‰¹æ€§ | ä¼ ç»ŸOCR | å¤šæ¨¡æ€å¤§æ¨¡å‹ |
|------|---------|-------------|
| æ–‡å­—è¯†åˆ«å‡†ç¡®åº¦ | 85-95% | 95-99% |
| æ‰‹å†™å†…å®¹è¯†åˆ« | è¾ƒå·® | ä¼˜ç§€ |
| è¡¨æ ¼ç†è§£ | éœ€è¦é¢å¤–å¤„ç† | ç›´æ¥ç†è§£ |
| å›¾è¡¨åˆ†æ | æ— æ³•å¤„ç† | æ·±åº¦ç†è§£ |
| å…¬å¼è¯†åˆ« | éœ€è¦ä¸“é—¨å·¥å…· | åŸç”Ÿæ”¯æŒ |
| è¯­ä¹‰ç†è§£ | æ—  | å¼ºå¤§ |
| ä¸Šä¸‹æ–‡å…³è” | æ—  | ä¼˜ç§€ |
| å¤šè¯­è¨€æ”¯æŒ | æœ‰é™ | å¹¿æ³› |

## ğŸ› ï¸ å®ç°ç»†èŠ‚

### æ–‡æ¡£é¢„å¤„ç†

```python
def preprocess_document(file_path):
    """æ–‡æ¡£é¢„å¤„ç†ï¼Œä¼˜åŒ–å¤šæ¨¡æ€æ¨¡å‹è¾“å…¥"""
    file_type = detect_file_type(file_path)
    
    if file_type == 'pdf':
        # PDFè½¬é«˜è´¨é‡å›¾åƒ
        return convert_pdf_to_high_quality_images(file_path)
    elif file_type == 'image':
        # å›¾åƒä¼˜åŒ–
        return optimize_image_for_model(file_path)
    elif file_type == 'word':
        # Wordæ–‡æ¡£å¤„ç†
        return extract_word_content(file_path)
    else:
        # æ–‡æœ¬æ–‡ä»¶
        return read_text_file(file_path)
```

### å¤šæ¨¡æ€APIè°ƒç”¨

```python
def call_multimodal_api(content, content_type):
    """è°ƒç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹API"""
    
    if content_type == 'image':
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "è¯·åˆ†æè¿™ä¸ªæ–‡æ¡£çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ–‡å­—ã€å›¾è¡¨ã€å…¬å¼ç­‰æ‰€æœ‰ä¿¡æ¯"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{content}"
                        }
                    }
                ]
            }
        ]
    else:
        messages = [
            {
                "role": "user", 
                "content": f"è¯·åˆ†æä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼š\n{content}"
            }
        ]
    
    response = openai.ChatCompletion.create(
        model="google/gemini-2.5-flash",
        messages=messages,
        max_tokens=4000
    )
    
    return response.choices[0].message.content
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. å›¾åƒè´¨é‡ä¼˜åŒ–

```python
def optimize_image_quality(image_path):
    """ä¼˜åŒ–å›¾åƒè´¨é‡ä»¥æé«˜è¯†åˆ«å‡†ç¡®åº¦"""
    img = Image.open(image_path)
    
    # è°ƒæ•´åˆ†è¾¨ç‡
    if max(img.size) < 1024:
        # ä½åˆ†è¾¨ç‡å›¾åƒæ”¾å¤§
        scale_factor = 1024 / max(img.size)
        new_size = (int(img.size[0] * scale_factor), 
                   int(img.size[1] * scale_factor))
        img = img.resize(new_size, Image.LANCZOS)
    
    # å¢å¼ºå¯¹æ¯”åº¦
    enhancer = ImageEnhance.Contrast(img)
    img = enhancer.enhance(1.2)
    
    return img
```

### 2. æ‰¹é‡å¤„ç†ä¼˜åŒ–

```python
async def process_multiple_documents(file_paths):
    """å¼‚æ­¥æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æ¡£"""
    tasks = []
    
    for file_path in file_paths:
        task = asyncio.create_task(
            process_single_document(file_path)
        )
        tasks.append(task)
    
    results = await asyncio.gather(*tasks)
    return results
```

## ğŸ” é”™è¯¯å¤„ç†å’Œå›é€€æœºåˆ¶

```python
def robust_document_processing(file_path):
    """å¸¦æœ‰é”™è¯¯å¤„ç†çš„æ–‡æ¡£å¤„ç†"""
    
    try:
        # å°è¯•å¤šæ¨¡æ€å¤„ç†
        return process_with_multimodal_model(file_path)
    except Exception as e:
        logger.warning(f"å¤šæ¨¡æ€å¤„ç†å¤±è´¥: {e}")
        
        # å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
        try:
            return fallback_text_extraction(file_path)
        except Exception as e2:
            logger.error(f"å›é€€å¤„ç†ä¹Ÿå¤±è´¥: {e2}")
            return {"error": "æ–‡æ¡£å¤„ç†å¤±è´¥", "details": str(e2)}
```

## ğŸ“ˆ è´¨é‡è¯„ä¼°

### å¤„ç†è´¨é‡æŒ‡æ ‡

- **è¯†åˆ«å‡†ç¡®åº¦**: > 95%
- **å¤„ç†é€Ÿåº¦**: å¹³å‡ 2-5 ç§’/é¡µ
- **æ”¯æŒæ ¼å¼**: PDF, JPG, PNG, DOCX, TXT
- **æœ€å¤§æ–‡ä»¶å¤§å°**: 50MB
- **å¹¶å‘å¤„ç†**: æ”¯æŒ

### æµ‹è¯•ç”¨ä¾‹

```python
def test_multimodal_processing():
    """æµ‹è¯•å¤šæ¨¡æ€å¤„ç†åŠŸèƒ½"""
    
    test_cases = [
        "test_files/math_homework.pdf",
        "test_files/handwritten_essay.jpg", 
        "test_files/table_data.png",
        "test_files/mixed_content.docx"
    ]
    
    for test_file in test_cases:
        result = process_document(test_file)
        assert result['success'] == True
        assert len(result['content']) > 0
        print(f"âœ… {test_file} å¤„ç†æˆåŠŸ")
```

## ğŸ¯ æœªæ¥ä¼˜åŒ–æ–¹å‘

1. **æ¨¡å‹å¾®è°ƒ**: é’ˆå¯¹æ•™è‚²åœºæ™¯ä¼˜åŒ–æ¨¡å‹
2. **ç¼“å­˜æœºåˆ¶**: ç›¸ä¼¼æ–‡æ¡£ç»“æœç¼“å­˜
3. **å®æ—¶å¤„ç†**: WebSocketå®æ—¶åé¦ˆ
4. **å¤šè¯­è¨€æ”¯æŒ**: æ‰©å±•æ›´å¤šè¯­è¨€è¯†åˆ«
5. **ä¸“ä¸šé¢†åŸŸ**: æ•°å­¦å…¬å¼ã€åŒ–å­¦æ–¹ç¨‹å¼ç­‰ä¸“ä¸šå†…å®¹

## ğŸ“ é…ç½®è¯´æ˜

åœ¨ `config/ai_optimization.yaml` ä¸­é…ç½®å¤šæ¨¡æ€å¤„ç†å‚æ•°ï¼š

```yaml
multimodal_processing:
  primary_model: "google/gemini-2.5-flash"
  fallback_models: 
    - "anthropic/claude-3-haiku"
    - "openai/gpt-4-vision-preview"
  
  image_processing:
    max_resolution: 2048
    quality_enhancement: true
    contrast_adjustment: 1.2
  
  pdf_processing:
    max_pages: 20
    image_dpi: 300
    compression_quality: 85
  
  performance:
    timeout: 30
    max_retries: 3
    concurrent_requests: 5
```

è¿™ç§å¤šæ¨¡æ€å¤§æ¨¡å‹æ–¹æ¡ˆå½»åº•æ‘†è„±äº†ä¼ ç»ŸOCRçš„é™åˆ¶ï¼Œæä¾›äº†æ›´æ™ºèƒ½ã€æ›´å‡†ç¡®çš„æ–‡æ¡£ç†è§£èƒ½åŠ›ã€‚