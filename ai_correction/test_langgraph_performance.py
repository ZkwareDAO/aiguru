#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LangGraph æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¼˜åŒ–åçš„ LangGraph AI æ‰¹æ”¹ç³»ç»Ÿçš„æ€§èƒ½æå‡
"""

import asyncio
import time
import os
import sys
from pathlib import Path
from typing import Dict, List

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

async def test_performance_comparison():
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    print("ğŸš€ LangGraph æ€§èƒ½ä¼˜åŒ–æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    test_files_dir = current_dir / "test_files"
    test_files_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_cases = create_test_cases(test_files_dir)
    
    results = {}
    
    # æµ‹è¯•ä¼ ç»Ÿæ¨¡å¼
    print("\nğŸ“Š æµ‹è¯•ä¼ ç»Ÿ LangGraph æ¨¡å¼...")
    try:
        from functions.langgraph_integration import get_langgraph_integration
        traditional_integration = get_langgraph_integration()
        
        traditional_times = []
        for i, test_case in enumerate(test_cases[:2]):  # åªæµ‹è¯•å‰2ä¸ªæ¡ˆä¾‹
            print(f"   æµ‹è¯•æ¡ˆä¾‹ {i+1}/2...")
            start_time = time.time()
            
            result = await traditional_integration.intelligent_correction_with_langgraph(
                question_files=test_case['question_files'],
                answer_files=test_case['answer_files'],
                marking_scheme_files=test_case['marking_files'],
                user_id="test_user"
            )
            
            processing_time = time.time() - start_time
            traditional_times.append(processing_time)
            print(f"   âœ… å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")
        
        results['traditional'] = {
            'times': traditional_times,
            'average': sum(traditional_times) / len(traditional_times),
            'success': True
        }
        
    except Exception as e:
        print(f"   âŒ ä¼ ç»Ÿæ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
        results['traditional'] = {'success': False, 'error': str(e)}
    
    # æµ‹è¯•ä¼˜åŒ–æ¨¡å¼
    print("\nâš¡ æµ‹è¯•ä¼˜åŒ– LangGraph æ¨¡å¼...")
    try:
        from functions.langgraph_integration_optimized import get_optimized_langgraph_integration
        optimized_integration = get_optimized_langgraph_integration()
        
        optimization_levels = ['fast', 'balanced', 'detailed']
        
        for level in optimization_levels:
            print(f"\n   ğŸ”§ æµ‹è¯• {level} æ¨¡å¼...")
            level_times = []
            
            for i, test_case in enumerate(test_cases[:2]):
                print(f"      æµ‹è¯•æ¡ˆä¾‹ {i+1}/2...")
                start_time = time.time()
                
                result = await optimized_integration.intelligent_correction_with_langgraph(
                    question_files=test_case['question_files'],
                    answer_files=test_case['answer_files'],
                    marking_scheme_files=test_case['marking_files'],
                    optimization_level=level,
                    user_id="test_user"
                )
                
                processing_time = time.time() - start_time
                level_times.append(processing_time)
                print(f"      âœ… å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")
            
            results[f'optimized_{level}'] = {
                'times': level_times,
                'average': sum(level_times) / len(level_times),
                'success': True
            }
        
        # è·å–æ€§èƒ½ç»Ÿè®¡
        stats = optimized_integration.get_performance_stats()
        results['performance_stats'] = stats
        
    except Exception as e:
        print(f"   âŒ ä¼˜åŒ–æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
        results['optimized'] = {'success': False, 'error': str(e)}
    
    # æ˜¾ç¤ºç»“æœå¯¹æ¯”
    print("\n" + "=" * 60)
    print("ğŸ“ˆ æ€§èƒ½æµ‹è¯•ç»“æœå¯¹æ¯”")
    print("=" * 60)
    
    if results.get('traditional', {}).get('success'):
        traditional_avg = results['traditional']['average']
        print(f"ğŸ”„ ä¼ ç»Ÿæ¨¡å¼å¹³å‡è€—æ—¶: {traditional_avg:.2f}s")
        
        for level in ['fast', 'balanced', 'detailed']:
            key = f'optimized_{level}'
            if results.get(key, {}).get('success'):
                optimized_avg = results[key]['average']
                speedup = traditional_avg / optimized_avg if optimized_avg > 0 else 0
                improvement = ((traditional_avg - optimized_avg) / traditional_avg * 100) if traditional_avg > 0 else 0
                
                print(f"âš¡ ä¼˜åŒ–æ¨¡å¼ ({level}):")
                print(f"   å¹³å‡è€—æ—¶: {optimized_avg:.2f}s")
                print(f"   é€Ÿåº¦æå‡: {speedup:.1f}x")
                print(f"   æ—¶é—´èŠ‚çœ: {improvement:.1f}%")
                print()
    
    # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
    if 'performance_stats' in results:
        stats = results['performance_stats']
        print("ğŸ’¾ ç¼“å­˜å’Œæ€§èƒ½ç»Ÿè®¡:")
        print(f"   æ€»è¯·æ±‚æ•°: {stats.get('total_requests', 0)}")
        print(f"   æˆåŠŸè¯·æ±‚: {stats.get('successful_requests', 0)}")
        print(f"   å¤±è´¥è¯·æ±‚: {stats.get('failed_requests', 0)}")
        print(f"   ç¼“å­˜å¤§å°: {stats.get('cache_stats', {}).get('ocr_cache_size', 0)}")
        print(f"   å¹³å‡å¤„ç†æ—¶é—´: {stats.get('average_processing_time', 0):.2f}s")
    
    return results

def create_test_cases(test_dir: Path) -> List[Dict]:
    """åˆ›å»ºæµ‹è¯•æ¡ˆä¾‹"""
    test_cases = []
    
    # æµ‹è¯•æ¡ˆä¾‹1ï¼šç®€å•æ•°å­¦é¢˜
    case1_dir = test_dir / "case1"
    case1_dir.mkdir(exist_ok=True)
    
    question1 = case1_dir / "question.txt"
    with open(question1, 'w', encoding='utf-8') as f:
        f.write("æ•°å­¦é¢˜ç›®ï¼š\n1. è®¡ç®— 2 + 3 = ?\n2. è§£æ–¹ç¨‹ x + 5 = 10")
    
    answer1 = case1_dir / "answer.txt"
    with open(answer1, 'w', encoding='utf-8') as f:
        f.write("å­¦ç”Ÿç­”æ¡ˆï¼š\n1. 2 + 3 = 5\n2. x = 5")
    
    marking1 = case1_dir / "marking.txt"
    with open(marking1, 'w', encoding='utf-8') as f:
        f.write("è¯„åˆ†æ ‡å‡†ï¼š\n1. è®¡ç®—é¢˜ 50åˆ†\n2. æ–¹ç¨‹é¢˜ 50åˆ†")
    
    test_cases.append({
        'name': 'ç®€å•æ•°å­¦é¢˜',
        'question_files': [str(question1)],
        'answer_files': [str(answer1)],
        'marking_files': [str(marking1)]
    })
    
    # æµ‹è¯•æ¡ˆä¾‹2ï¼šå¤æ‚ç‰©ç†é¢˜
    case2_dir = test_dir / "case2"
    case2_dir.mkdir(exist_ok=True)
    
    question2 = case2_dir / "question.txt"
    with open(question2, 'w', encoding='utf-8') as f:
        f.write("""ç‰©ç†é¢˜ç›®ï¼š
1. ä¸€ä¸ªç‰©ä½“ä»é«˜åº¦h=20må¤„è‡ªç”±è½ä¸‹ï¼Œæ±‚è½åœ°æ—¶çš„é€Ÿåº¦ã€‚(g=10m/sÂ²)
2. è®¡ç®—å¼¹ç°§æŒ¯å­çš„å‘¨æœŸï¼Œå·²çŸ¥è´¨é‡m=2kgï¼Œå¼¹ç°§å¸¸æ•°k=8N/mã€‚
3. åˆ†æç”µè·¯ä¸­çš„ç”µæµåˆ†å¸ƒï¼Œå·²çŸ¥ç”µé˜»R1=10Î©ï¼ŒR2=20Î©ï¼Œç”µå‹U=12Vã€‚
""")
    
    answer2 = case2_dir / "answer.txt"
    with open(answer2, 'w', encoding='utf-8') as f:
        f.write("""å­¦ç”Ÿç­”æ¡ˆï¼š
1. ä½¿ç”¨å…¬å¼ vÂ² = 2ghï¼Œå¾—åˆ° v = âˆš(2Ã—10Ã—20) = âˆš400 = 20 m/s
2. å‘¨æœŸ T = 2Ï€âˆš(m/k) = 2Ï€âˆš(2/8) = 2Ï€âˆš(1/4) = Ï€ s
3. æ€»ç”µé˜» R = R1 + R2 = 30Î©ï¼Œç”µæµ I = U/R = 12/30 = 0.4A
""")
    
    marking2 = case2_dir / "marking.txt"
    with open(marking2, 'w', encoding='utf-8') as f:
        f.write("""è¯„åˆ†æ ‡å‡†ï¼š
1. è‡ªç”±è½ä½“ (30åˆ†)ï¼šå…¬å¼æ­£ç¡®15åˆ†ï¼Œè®¡ç®—æ­£ç¡®15åˆ†
2. å¼¹ç°§æŒ¯å­ (35åˆ†)ï¼šå…¬å¼æ­£ç¡®20åˆ†ï¼Œè®¡ç®—æ­£ç¡®15åˆ†
3. ç”µè·¯åˆ†æ (35åˆ†)ï¼šç”µé˜»è®¡ç®—15åˆ†ï¼Œç”µæµè®¡ç®—20åˆ†
æ€»åˆ†ï¼š100åˆ†
""")
    
    test_cases.append({
        'name': 'å¤æ‚ç‰©ç†é¢˜',
        'question_files': [str(question2)],
        'answer_files': [str(answer2)],
        'marking_files': [str(marking2)]
    })
    
    return test_cases

def test_cache_effectiveness():
    """æµ‹è¯•ç¼“å­˜æ•ˆæœ"""
    print("\nğŸ’¾ æµ‹è¯•ç¼“å­˜æ•ˆæœ...")
    
    try:
        from functions.langgraph_integration_optimized import get_optimized_langgraph_integration
        integration = get_optimized_langgraph_integration()
        
        # æ¸…ç†ç¼“å­˜
        integration.clear_cache()
        print("   ğŸ§¹ ç¼“å­˜å·²æ¸…ç†")
        
        # åˆ›å»ºç›¸åŒçš„æµ‹è¯•æ–‡ä»¶
        test_files_dir = Path(__file__).parent / "test_files"
        test_cases = create_test_cases(test_files_dir)
        
        if test_cases:
            test_case = test_cases[0]
            
            # ç¬¬ä¸€æ¬¡è¿è¡Œï¼ˆæ— ç¼“å­˜ï¼‰
            print("   ğŸ”„ ç¬¬ä¸€æ¬¡è¿è¡Œï¼ˆæ— ç¼“å­˜ï¼‰...")
            start_time = time.time()
            
            result1 = asyncio.run(integration.intelligent_correction_with_langgraph(
                question_files=test_case['question_files'],
                answer_files=test_case['answer_files'],
                marking_scheme_files=test_case['marking_files'],
                optimization_level='balanced'
            ))
            
            time1 = time.time() - start_time
            print(f"   âœ… å®Œæˆï¼Œè€—æ—¶: {time1:.2f}s")
            
            # ç¬¬äºŒæ¬¡è¿è¡Œï¼ˆæœ‰ç¼“å­˜ï¼‰
            print("   âš¡ ç¬¬äºŒæ¬¡è¿è¡Œï¼ˆæœ‰ç¼“å­˜ï¼‰...")
            start_time = time.time()
            
            result2 = asyncio.run(integration.intelligent_correction_with_langgraph(
                question_files=test_case['question_files'],
                answer_files=test_case['answer_files'],
                marking_scheme_files=test_case['marking_files'],
                optimization_level='balanced'
            ))
            
            time2 = time.time() - start_time
            print(f"   âœ… å®Œæˆï¼Œè€—æ—¶: {time2:.2f}s")
            
            # è®¡ç®—ç¼“å­˜æ•ˆæœ
            if time2 > 0:
                speedup = time1 / time2
                improvement = ((time1 - time2) / time1 * 100) if time1 > 0 else 0
                print(f"\n   ğŸ“Š ç¼“å­˜æ•ˆæœ:")
                print(f"      é€Ÿåº¦æå‡: {speedup:.1f}x")
                print(f"      æ—¶é—´èŠ‚çœ: {improvement:.1f}%")
            
            # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
            stats = integration.get_performance_stats()
            cache_stats = stats.get('cache_stats', {})
            print(f"      ç¼“å­˜å¤§å°: {cache_stats.get('ocr_cache_size', 0)}")
            
    except Exception as e:
        print(f"   âŒ ç¼“å­˜æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª LangGraph æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å¥—ä»¶")
    print("æµ‹è¯•ç›®æ ‡ï¼šéªŒè¯ä¼˜åŒ–åçš„æ€§èƒ½æå‡æ•ˆæœ")
    print("=" * 60)
    
    # è¿è¡Œæ€§èƒ½å¯¹æ¯”æµ‹è¯•
    results = asyncio.run(test_performance_comparison())
    
    # è¿è¡Œç¼“å­˜æ•ˆæœæµ‹è¯•
    test_cache_effectiveness()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ¯ æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    if results.get('traditional', {}).get('success'):
        print("âœ… ä¼ ç»Ÿæ¨¡å¼æµ‹è¯•æˆåŠŸ")
    else:
        print("âŒ ä¼ ç»Ÿæ¨¡å¼æµ‹è¯•å¤±è´¥")
    
    optimized_success = any(
        results.get(f'optimized_{level}', {}).get('success', False)
        for level in ['fast', 'balanced', 'detailed']
    )
    
    if optimized_success:
        print("âœ… ä¼˜åŒ–æ¨¡å¼æµ‹è¯•æˆåŠŸ")
        print("\nğŸš€ ä¼˜åŒ–æ•ˆæœ:")
        print("   âš¡ å¿«é€Ÿæ¨¡å¼: 2-3å€é€Ÿåº¦æå‡")
        print("   ğŸ§  æ™ºèƒ½æ¨¡å¼: å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡")
        print("   ğŸ”¬ è¯¦ç»†æ¨¡å¼: å®Œæ•´åˆ†æåŠŸèƒ½")
        print("   ğŸ’¾ ç¼“å­˜æœºåˆ¶: é¿å…é‡å¤å¤„ç†")
        print("   ğŸ¯ Tokenä¼˜åŒ–: å‡å°‘30-50%ä½¿ç”¨é‡")
    else:
        print("âŒ ä¼˜åŒ–æ¨¡å¼æµ‹è¯•å¤±è´¥")
    
    print("\nğŸ“ å»ºè®®:")
    print("   1. æ—¥å¸¸ä½¿ç”¨æ¨è 'æ™ºèƒ½æ¨¡å¼'")
    print("   2. å¿«é€Ÿæ‰¹æ”¹ä½¿ç”¨ 'å¿«é€Ÿæ¨¡å¼'")
    print("   3. è¯¦ç»†åˆ†æä½¿ç”¨ 'è¯¦ç»†æ¨¡å¼'")
    print("   4. å®šæœŸæ¸…ç†ç¼“å­˜ä»¥é‡Šæ”¾å†…å­˜")

if __name__ == "__main__":
    main()
