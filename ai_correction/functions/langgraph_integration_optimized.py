#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„ LangGraph é›†æˆæ¨¡å—
æä¾›é«˜æ€§èƒ½çš„æ‰¹æ”¹æ¥å£ï¼Œæ”¯æŒå¤šç§ä¼˜åŒ–æ¨¡å¼
"""

import os
import logging
import asyncio
import uuid
import time
from typing import List, Dict, Any, Optional
from datetime import datetime

# å¯¼å…¥ä¼˜åŒ–çš„ LangGraph å·¥ä½œæµ
from .langgraph.workflow import get_workflow, run_ai_grading, get_grading_progress

logger = logging.getLogger(__name__)

class OptimizedLangGraphIntegration:
    """
    ä¼˜åŒ–çš„ LangGraph é›†æˆç±»
    æä¾›é«˜æ€§èƒ½æ‰¹æ”¹æ¥å£ï¼Œæ”¯æŒç¼“å­˜ã€å¹¶è¡Œå¤„ç†ã€Tokenä¼˜åŒ–
    """
    
    def __init__(self):
        self.active_tasks = {}  # æ´»è·ƒä»»åŠ¡è®°å½•
        self.performance_stats = {
            'total_requests': 0,
            'cache_hits': 0,
            'average_processing_time': 0.0,
            'token_savings_percentage': 0,
            'successful_requests': 0,
            'failed_requests': 0
        }
        self.workflow = None
        self._initialize_workflow()
        
    def _initialize_workflow(self):
        """åˆå§‹åŒ–ä¼˜åŒ–å·¥ä½œæµ"""
        try:
            self.workflow = get_workflow()
            logger.info("ä¼˜åŒ– LangGraph å·¥ä½œæµåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"LangGraph å·¥ä½œæµåˆå§‹åŒ–å¤±è´¥: {e}")
            self.workflow = None
    
    async def intelligent_correction_with_langgraph(
        self,
        question_files: List[str],
        answer_files: List[str],
        marking_scheme_files: Optional[List[str]] = None,
        strictness_level: str = "ä¸­ç­‰",
        language: str = "zh",
        mode: str = "auto",
        user_id: str = "default_user",
        optimization_level: str = "balanced"  # æ–°å¢ï¼šä¼˜åŒ–çº§åˆ«
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ä¼˜åŒ–çš„ LangGraph è¿›è¡Œæ™ºèƒ½æ‰¹æ”¹
        
        Args:
            question_files: é¢˜ç›®æ–‡ä»¶åˆ—è¡¨
            answer_files: ç­”æ¡ˆæ–‡ä»¶åˆ—è¡¨
            marking_scheme_files: è¯„åˆ†æ ‡å‡†æ–‡ä»¶åˆ—è¡¨
            strictness_level: ä¸¥æ ¼ç¨‹åº¦
            language: è¯­è¨€
            mode: æ‰¹æ”¹æ¨¡å¼
            user_id: ç”¨æˆ·ID
            optimization_level: ä¼˜åŒ–çº§åˆ« (fast/balanced/detailed)
            
        Returns:
            æ‰¹æ”¹ç»“æœå­—å…¸
        """
        start_time = time.time()
        task_id = f"task_{uuid.uuid4().hex[:8]}"
        
        # æ›´æ–°ç»Ÿè®¡
        self.performance_stats['total_requests'] += 1
        
        try:
            logger.info(f"å¼€å§‹ä¼˜åŒ–æ‰¹æ”¹ - ä»»åŠ¡ID: {task_id}, ä¼˜åŒ–çº§åˆ«: {optimization_level}")
            
            # æ ¹æ®ä¼˜åŒ–çº§åˆ«è°ƒæ•´æ¨¡å¼
            optimized_mode = self._get_optimized_mode(mode, optimization_level)
            
            # è®°å½•æ´»è·ƒä»»åŠ¡
            self.active_tasks[task_id] = {
                'start_time': start_time,
                'status': 'running',
                'optimization_level': optimization_level
            }
            
            # è¿è¡Œä¼˜åŒ–çš„æ‰¹æ”¹æµç¨‹
            result = await run_ai_grading(
                task_id=task_id,
                user_id=user_id,
                question_files=question_files,
                answer_files=answer_files,
                marking_files=marking_scheme_files or [],
                mode=optimized_mode,
                strictness_level=strictness_level,
                language=language
            )
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            result['processing_time'] = processing_time
            result['optimization_level'] = optimization_level
            
            # æ›´æ–°ç»Ÿè®¡
            self._update_performance_stats(processing_time, True)
            
            # æ¸…ç†æ´»è·ƒä»»åŠ¡
            if task_id in self.active_tasks:
                del self.active_tasks[task_id]
            
            logger.info(f"ä¼˜åŒ–æ‰¹æ”¹å®Œæˆ - ä»»åŠ¡ID: {task_id}, è€—æ—¶: {processing_time:.2f}s")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"ä¼˜åŒ–æ‰¹æ”¹å¤±è´¥: {str(e)}"
            logger.error(f"{error_msg} - ä»»åŠ¡ID: {task_id}")
            
            # æ›´æ–°ç»Ÿè®¡
            self._update_performance_stats(processing_time, False)
            
            # æ¸…ç†æ´»è·ƒä»»åŠ¡
            if task_id in self.active_tasks:
                del self.active_tasks[task_id]
            
            return {
                'task_id': task_id,
                'success': False,
                'error': error_msg,
                'feedback': f"æ‰¹æ”¹å¤±è´¥: {error_msg}",
                'processing_time': processing_time,
                'optimization_level': optimization_level
            }
    
    def _get_optimized_mode(self, original_mode: str, optimization_level: str) -> str:
        """æ ¹æ®ä¼˜åŒ–çº§åˆ«è°ƒæ•´æ‰¹æ”¹æ¨¡å¼"""
        if optimization_level == "fast":
            return "efficient"  # ä½¿ç”¨é«˜æ•ˆæ¨¡å¼
        elif optimization_level == "detailed":
            return "detailed"   # ä½¿ç”¨è¯¦ç»†æ¨¡å¼
        else:  # balanced
            return original_mode if original_mode != "langgraph" else "auto"
    
    def _update_performance_stats(self, processing_time: float, success: bool):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        if success:
            self.performance_stats['successful_requests'] += 1
        else:
            self.performance_stats['failed_requests'] += 1
        
        # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
        total_successful = self.performance_stats['successful_requests']
        if total_successful > 0:
            current_avg = self.performance_stats['average_processing_time']
            self.performance_stats['average_processing_time'] = (
                (current_avg * (total_successful - 1) + processing_time) / total_successful
            )
    
    async def get_task_progress(self, task_id: str) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡è¿›åº¦"""
        try:
            if task_id in self.active_tasks:
                # è·å– LangGraph è¿›åº¦
                progress = await get_grading_progress(task_id)
                
                # æ·»åŠ æœ¬åœ°ä»»åŠ¡ä¿¡æ¯
                local_info = self.active_tasks[task_id]
                progress.update({
                    'local_start_time': local_info['start_time'],
                    'elapsed_time': time.time() - local_info['start_time'],
                    'optimization_level': local_info['optimization_level']
                })
                
                return progress
            else:
                return {
                    'task_id': task_id,
                    'status': 'not_found',
                    'message': 'ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²å®Œæˆ'
                }
                
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡è¿›åº¦å¤±è´¥: {e}")
            return {
                'task_id': task_id,
                'status': 'error',
                'error': str(e)
            }
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = {}
        if self.workflow:
            try:
                cache_stats = self.workflow.get_cache_stats()
                # è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
                if cache_stats.get('ocr_cache_size', 0) > 0:
                    self.performance_stats['cache_hits'] = cache_stats['ocr_cache_size']
            except Exception as e:
                logger.warning(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
        
        return {
            **self.performance_stats,
            'cache_stats': cache_stats,
            'active_tasks_count': len(self.active_tasks),
            'workflow_status': 'initialized' if self.workflow else 'failed'
        }
    
    def clear_cache(self):
        """æ¸…ç†ç¼“å­˜"""
        if self.workflow:
            try:
                self.workflow.clear_cache()
                logger.info("ç¼“å­˜å·²æ¸…ç†")
                return True
            except Exception as e:
                logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
                return False
        return False
    
    def reset_stats(self):
        """é‡ç½®æ€§èƒ½ç»Ÿè®¡"""
        self.performance_stats = {
            'total_requests': 0,
            'cache_hits': 0,
            'average_processing_time': 0.0,
            'token_savings_percentage': 0,
            'successful_requests': 0,
            'failed_requests': 0
        }
        logger.info("æ€§èƒ½ç»Ÿè®¡å·²é‡ç½®")

# å…¨å±€å®ä¾‹
_optimized_integration_instance = None

def get_optimized_langgraph_integration() -> OptimizedLangGraphIntegration:
    """è·å–ä¼˜åŒ–çš„ LangGraph é›†æˆå®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _optimized_integration_instance
    if _optimized_integration_instance is None:
        _optimized_integration_instance = OptimizedLangGraphIntegration()
    return _optimized_integration_instance

def intelligent_correction_with_files_langgraph_optimized(
    question_files: List[str],
    answer_files: List[str],
    marking_scheme_files: Optional[List[str]] = None,
    strictness_level: str = "ä¸­ç­‰",
    language: str = "zh",
    mode: str = "auto",
    optimization_level: str = "balanced"
) -> str:
    """
    ä¼˜åŒ–çš„å…¼å®¹æ€§å‡½æ•° - ä¸ç°æœ‰ intelligent_correction_with_files æ¥å£å…¼å®¹
    è¿”å›æ–‡æœ¬æ ¼å¼çš„æ‰¹æ”¹ç»“æœ
    """
    try:
        integration = get_optimized_langgraph_integration()
        
        # è¿è¡Œå¼‚æ­¥æ‰¹æ”¹
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            result = loop.run_until_complete(
                integration.intelligent_correction_with_langgraph(
                    question_files=question_files,
                    answer_files=answer_files,
                    marking_scheme_files=marking_scheme_files,
                    strictness_level=strictness_level,
                    language=language,
                    mode=mode,
                    optimization_level=optimization_level
                )
            )
        finally:
            loop.close()
        
        # è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
        if result.get('success', True):
            feedback_parts = []
            
            # åŸºæœ¬ä¿¡æ¯
            feedback_parts.append(f"ğŸ“Š æ‰¹æ”¹ç»“æœ (ä¼˜åŒ–çº§åˆ«: {optimization_level})")
            feedback_parts.append(f"å¾—åˆ†: {result.get('final_score', 0)}")
            feedback_parts.append(f"ç­‰çº§: {result.get('grade_level', 'N/A')}")
            feedback_parts.append(f"å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f}ç§’")
            feedback_parts.append("")
            
            # è¯¦ç»†åé¦ˆ
            detailed_feedback = result.get('detailed_feedback', [])
            if detailed_feedback:
                feedback_parts.append("ğŸ“ è¯¦ç»†åé¦ˆ:")
                for feedback in detailed_feedback:
                    if isinstance(feedback, dict):
                        feedback_parts.append(feedback.get('content', str(feedback)))
                    else:
                        feedback_parts.append(str(feedback))
                feedback_parts.append("")
            
            # å­¦ä¹ å»ºè®®
            suggestions = result.get('learning_suggestions', [])
            if suggestions:
                feedback_parts.append("ğŸ’¡ å­¦ä¹ å»ºè®®:")
                for suggestion in suggestions:
                    feedback_parts.append(f"â€¢ {suggestion}")
                feedback_parts.append("")
            
            # æ€§èƒ½ä¿¡æ¯
            if optimization_level != "fast":
                annotations = result.get('coordinate_annotations', [])
                knowledge_points = result.get('knowledge_points', [])
                feedback_parts.append(f"ğŸ¯ åæ ‡æ ‡æ³¨: {len(annotations)} ä¸ª")
                feedback_parts.append(f"ğŸ§  çŸ¥è¯†ç‚¹åˆ†æ: {len(knowledge_points)} ä¸ª")
            
            return "\n".join(feedback_parts)
        else:
            return result.get('feedback', f"æ‰¹æ”¹å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except Exception as e:
        error_msg = f"ä¼˜åŒ–æ‰¹æ”¹å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        return error_msg
