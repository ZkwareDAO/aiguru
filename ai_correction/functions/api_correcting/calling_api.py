# ä¿®å¤ç‰ˆæœ¬çš„APIè°ƒç”¨æ¨¡å— - å®Œæ•´ç‰ˆ
import base64
import requests  
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None
import re
from pathlib import Path
import json
import os
import time
import logging
from typing import Dict, List, Tuple, Any, Optional, Union
from dataclasses import dataclass
import contextlib
import io
from PIL import Image

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/api_debug.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å¼ºåˆ¶ä½¿ç”¨ç®€åŒ–ç‰ˆæç¤ºè¯
USE_SIMPLIFIED_PROMPTS = True
try:
    import prompts_simplified as prompts_module
    logger.info("ä½¿ç”¨ç®€åŒ–ç‰ˆæç¤ºè¯ç³»ç»Ÿ")
except ImportError:
    try:
        from . import prompts_simplified as prompts_module
        logger.info("ä½¿ç”¨ç®€åŒ–ç‰ˆæç¤ºè¯ç³»ç»Ÿ")
    except ImportError:
        logger.error("ç®€åŒ–ç‰ˆæç¤ºè¯æ¨¡å—æœªæ‰¾åˆ°")
        raise ImportError("æ— æ³•å¯¼å…¥ç®€åŒ–ç‰ˆæç¤ºè¯æ¨¡å—")

# å¯¼å…¥PDFé”™è¯¯æŠ‘åˆ¶å·¥å…·
try:
    from pdf_utils import SuppressOutput, safe_pdf_processing
    PDF_UTILS_AVAILABLE = True
except ImportError:
    PDF_UTILS_AVAILABLE = False

# æŠ‘åˆ¶MuPDFé”™è¯¯è¾“å‡º
import warnings
warnings.filterwarnings("ignore")
os.environ['MUPDF_QUIET'] = '1'

try:
    import fitz  # PyMuPDF
except ImportError:
    fitz = None

@dataclass
class APIConfig:
    """APIé…ç½®ç±» - å¢å¼ºç‰ˆ"""
    api_key: str = ""
    base_url: str = "https://openrouter.ai/api/v1"
    
    # å¤šæ¨¡å‹æ”¯æŒ - æŒ‰ä¼˜å…ˆçº§æ’åº
    available_models: list = None
    current_model_index: int = 0
    
    max_tokens: int = 50000
    temperature: float = 0.7
    max_retries: int = 3
    retry_delay: float = 1.0
    timeout: int = 120
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†ï¼Œä»ç¯å¢ƒå˜é‡è®¾ç½®APIå¯†é’¥"""
        # åˆå§‹åŒ–å¯ç”¨æ¨¡å‹åˆ—è¡¨
        if self.available_models is None:
            self.available_models = [
                "google/gemini-2.5-flash-lite-preview-06-17",  # åŸå§‹æ¨¡å‹
                "google/gemini-2.5-flash",                    # å¤‡ç”¨æ¨¡å‹1
                "google/gemini-2.5-pro",                          # å¤‡ç”¨æ¨¡å‹2
                "anthropic/claude-3-haiku",                   # å¤‡ç”¨æ¨¡å‹3
                "meta-llama/llama-3-8b-instruct:free",       # å…è´¹æ¨¡å‹
                "microsoft/wizardlm-2-8x22b:free",           # å…è´¹æ¨¡å‹2
                "gryphe/mythomist-7b:free"                    # å…è´¹æ¨¡å‹3
            ]
        
        env_key = os.getenv('OPENROUTER_API_KEY') or os.getenv('OPENAI_API_KEY')
        if env_key:
            self.api_key = env_key
            return
        
        env_file_path = Path('.env')
        if env_file_path.exists():
            try:
                with open(env_file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#') and '=' in line:
                            key, value = line.split('=', 1)
                            if key.strip() == 'OPENROUTER_API_KEY' and value.strip():
                                self.api_key = value.strip()
                                return
            except Exception as e:
                logger.warning(f"è¯»å–.envæ–‡ä»¶å¤±è´¥: {e}")
        
        if not self.api_key:
            self.api_key = "è¯·åœ¨æ­¤å¤„è¾“å…¥æ‚¨çš„æ–°APIå¯†é’¥"
    
    @property
    def model(self) -> str:
        """è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹"""
        if self.current_model_index < len(self.available_models):
            return self.available_models[self.current_model_index]
        return self.available_models[0]  # å¦‚æœç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè¿”å›ç¬¬ä¸€ä¸ªæ¨¡å‹
    
    def switch_to_next_model(self) -> bool:
        """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨æ¨¡å‹"""
        if self.current_model_index < len(self.available_models) - 1:
            self.current_model_index += 1
            logger.info(f"åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹: {self.model}")
            return True
        return False
    
    def reset_model(self):
        """é‡ç½®åˆ°ç¬¬ä¸€ä¸ªæ¨¡å‹"""
        self.current_model_index = 0
        logger.info(f"é‡ç½®ä¸ºä¸»è¦æ¨¡å‹: {self.model}")
    
    def is_valid(self) -> bool:
        """æ£€æŸ¥APIé…ç½®æ˜¯å¦æœ‰æ•ˆ"""
        return bool(self.api_key and self.api_key.startswith(('sk-', 'or-')))
    
    def get_status(self) -> dict:
        """è·å–é…ç½®çŠ¶æ€ä¿¡æ¯"""
        api_key_source = "default"
        if os.getenv('OPENROUTER_API_KEY') or os.getenv('OPENAI_API_KEY'):
            api_key_source = "environment"
        elif Path('.env').exists():
            try:
                with open('.env', 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#') and '=' in line:
                            key, value = line.split('=', 1)
                            if key.strip() == 'OPENROUTER_API_KEY' and value.strip() and value.strip() != 'your_api_key_here':
                                api_key_source = ".env file"
                                break
            except:
                pass
        
        return {
            "api_key_configured": bool(self.api_key and self.api_key != "è¯·åœ¨æ­¤å¤„è¾“å…¥æ‚¨çš„æ–°APIå¯†é’¥"),
            "api_key_source": api_key_source,
            "base_url": self.base_url,
            "current_model": self.model,
            "available_models": self.available_models,
            "model_index": self.current_model_index,
            "is_valid": self.is_valid()
        }

# å…¨å±€é…ç½®å®ä¾‹
api_config = APIConfig()

def img_to_base64(image_path, max_size_mb=4):
    """å°†å›¾ç‰‡æ–‡ä»¶è½¬æ¢ä¸ºbase64ç¼–ç ï¼Œæ”¯æŒè‡ªåŠ¨å‹ç¼©"""
    import io
    import os
    from pathlib import Path
    from PIL import Image
    
    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
    if isinstance(image_path, str):
        file_path = Path(image_path)
        if file_path.exists():
            file_ext = file_path.suffix.lower()
            if file_ext in ['.txt', '.md', '.doc', '.docx', '.rtf']:
                raise ValueError(f"æ–‡ä»¶ {image_path} æ˜¯æ–‡æœ¬æ–‡ä»¶ï¼Œä¸èƒ½ä½œä¸ºå›¾åƒå¤„ç†")
    
    # å¤„ç†URL
    if isinstance(image_path, str) and image_path.startswith(('http://', 'https://')):
        response = requests.get(image_path)
        response.raise_for_status()  
        image_data = response.content
    # å¤„ç†Streamlitä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
    elif hasattr(image_path, 'read') and callable(image_path.read):
        try:
            if hasattr(image_path, 'tell') and callable(image_path.tell):
                current_position = image_path.tell()
            else:
                current_position = 0
            image_data = image_path.read()
            if hasattr(image_path, 'seek') and callable(image_path.seek):
                image_path.seek(current_position)
        except Exception as e:
            raise Exception(f"Failed to read uploaded file: {str(e)}")
    # å¤„ç†æœ¬åœ°æ–‡ä»¶è·¯å¾„
    elif isinstance(image_path, str):
        file_size_mb = os.path.getsize(image_path) / (1024 * 1024)
        
        if file_size_mb <= max_size_mb:
            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
        else:
            logging.info(f"å›¾ç‰‡æ–‡ä»¶è¿‡å¤§ ({file_size_mb:.2f}MB)ï¼Œæ­£åœ¨å‹ç¼©...")
            img = Image.open(image_path)
            
            if img.mode in ('RGBA', 'LA', 'P'):
                img = img.convert('RGB')
            
            quality = 85
            max_dimension = 1920
            
            if max(img.size) > max_dimension:
                ratio = max_dimension / max(img.size)
                new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))
                img = img.resize(new_size, Image.Resampling.LANCZOS)
            
            while quality > 20:
                buffer = io.BytesIO()
                img.save(buffer, format='JPEG', quality=quality, optimize=True)
                compressed_size_mb = len(buffer.getvalue()) / (1024 * 1024)
                
                if compressed_size_mb <= max_size_mb:
                    logging.info(f"å‹ç¼©å®Œæˆ: {file_size_mb:.2f}MB -> {compressed_size_mb:.2f}MB (è´¨é‡: {quality})")
                    image_data = buffer.getvalue()
                    break
                
                quality -= 10
            else:
                while max_dimension > 800:
                    max_dimension -= 200
                    ratio = max_dimension / max(img.size)
                    new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))
                    img_resized = img.resize(new_size, Image.Resampling.LANCZOS)
                    
                    buffer = io.BytesIO()
                    img_resized.save(buffer, format='JPEG', quality=70, optimize=True)
                    compressed_size_mb = len(buffer.getvalue()) / (1024 * 1024)
                    
                    if compressed_size_mb <= max_size_mb:
                        logging.info(f"ç¼©æ”¾å‹ç¼©å®Œæˆ: {file_size_mb:.2f}MB -> {compressed_size_mb:.2f}MB (å°ºå¯¸: {new_size})")
                        image_data = buffer.getvalue()
                        break
                else:
                    buffer = io.BytesIO()
                    img.save(buffer, format='JPEG', quality=50, optimize=True)
                    final_size_mb = len(buffer.getvalue()) / (1024 * 1024)
                    logging.info(f"æœ€ç»ˆå‹ç¼©: {file_size_mb:.2f}MB -> {final_size_mb:.2f}MB")
                    image_data = buffer.getvalue()
    else:
        raise Exception(f"Unsupported image source type: {type(image_path)}")
        
    return base64.b64encode(image_data).decode('utf-8')

def get_file_type(file_path):
    """æ£€æµ‹æ–‡ä»¶ç±»å‹ï¼Œè¿”å›æ–‡ä»¶ç±»å‹åˆ†ç±»"""
    if isinstance(file_path, str):
        file_ext = Path(file_path).suffix.lower()
        if file_ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp']:
            return 'image'
        elif file_ext == '.pdf':
            return 'pdf'
        elif file_ext in ['.doc', '.docx']:
            return 'word'
        elif file_ext in ['.txt', '.md', '.rtf', '.csv']:
            return 'text'
        elif file_ext in ['.py', '.js', '.html', '.css', '.json', '.xml', '.yaml', '.yml']:
            return 'text'
    return 'unknown'

def read_pdf_file(file_path):
    """è¯»å–PDFæ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒå¤šç§PDFåº“ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ"""
    
    # æ–¹æ³•1: å°è¯•ä½¿ç”¨ pdfplumberï¼ˆæ¨èï¼Œç¨³å®šæ€§å¥½ï¼‰
    try:
        import pdfplumber
        with pdfplumber.open(file_path) as pdf:
            text = ""
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
            if text.strip():
                return text.strip()
    except ImportError:
        pass
    except Exception as e:
        logger.warning(f"pdfplumberè¯»å–PDFå¤±è´¥: {str(e)}")
    
    # æ–¹æ³•2: å°è¯•ä½¿ç”¨ PyPDF2
    try:
        import PyPDF2
        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
            if text.strip():
                return text.strip()
    except ImportError:
        pass
    except Exception as e:
        logger.warning(f"PyPDF2è¯»å–PDFå¤±è´¥: {str(e)}")
    
    # æ–¹æ³•3: å°è¯•ä½¿ç”¨ PyMuPDFï¼ˆå¦‚æœå¯ç”¨ï¼‰
    try:
        import fitz
        doc = fitz.open(file_path)
        text = ""
        for page_num in range(doc.page_count):
            page = doc.load_page(page_num)
            page_text = page.get_text()
            if page_text:
                text += page_text + "\n"
        doc.close()
        if text.strip():
            return text.strip()
    except ImportError:
        pass
    except Exception as e:
        logger.warning(f"PyMuPDFè¯»å–PDFå¤±è´¥: {str(e)}")
    
    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
    return f"[PDFæ–‡ä»¶è¯»å–å¤±è´¥: {Path(file_path).name}] - æ‰€æœ‰PDFå¤„ç†åº“éƒ½æ— æ³•è¯»å–æ­¤æ–‡ä»¶ï¼Œè¯·ç¡®ä¿PDFæ–‡ä»¶æ ¼å¼æ­£ç¡®ä¸”æœªæŸå"

def read_word_file(file_path):
    """è¯»å–Wordæ–‡æ¡£å†…å®¹"""
    try:
        import docx
        doc = docx.Document(file_path)
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        return text.strip()
    except ImportError:
        return f"[Wordæ–‡æ¡£: {Path(file_path).name}] - éœ€è¦å®‰è£…python-docxåº“æ¥è¯»å–Wordæ–‡æ¡£"
    except Exception as e:
        return f"[Wordæ–‡æ¡£è¯»å–å¤±è´¥: {Path(file_path).name}] - é”™è¯¯: {str(e)}"

def read_text_file(file_path):
    """è¯»å–æ–‡æœ¬æ–‡ä»¶å†…å®¹"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        try:
            with open(file_path, 'r', encoding='gbk') as f:
                return f.read()
        except UnicodeDecodeError:
            with open(file_path, 'r', encoding='latin-1') as f:
                return f.read()

def process_file_content(file_path):
    """æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†æ–‡ä»¶å†…å®¹"""
    file_type = get_file_type(file_path)
    file_name = Path(file_path).name
    
    # å¢åŠ æ–‡ä»¶ç±»å‹æ ‡è¯†ï¼Œå¸®åŠ©AIæ›´å¥½åœ°è¯†åˆ«
    file_category = ""
    if 'QUESTION' in file_name.upper():
        file_category = "[é¢˜ç›®æ–‡ä»¶]"
    elif 'ANSWER' in file_name.upper():
        file_category = "[å­¦ç”Ÿç­”æ¡ˆ]"
    elif 'MARKING' in file_name.upper():
        file_category = "[æ‰¹æ”¹æ ‡å‡†]"
    
    try:
        if file_type == 'image':
            logger.info(f"å¤„ç†å›¾ç‰‡æ–‡ä»¶ {file_category}: {file_name}")
            return 'image', file_path
        elif file_type == 'pdf':
            logger.info(f"å¤„ç†PDFæ–‡ä»¶ {file_category}: {file_name}")
            
            # 1. å°è¯•æ–‡æœ¬æå–
            try:
                pdf_text = read_pdf_file(file_path)
                # Check if text extraction was successful and content is substantial
                if pdf_text and not pdf_text.startswith("[PDFæ–‡ä»¶è¯»å–å¤±è´¥") and len(pdf_text) > 100:
                    logger.info(f"PDFæ–‡æœ¬æå–æˆåŠŸ: {file_name}")
                    return 'text', f"{file_category} [PDFæ–‡æœ¬å†…å®¹: {file_name}]\n{pdf_text}"
                else:
                    logger.warning(f"PDFæ–‡æœ¬æå–å¤±è´¥æˆ–å†…å®¹è¿‡å°‘ï¼Œå°†å°è¯•å›¾åƒè½¬æ¢: {file_name}")
            except Exception as e:
                logger.error(f"PDFæ–‡æœ¬æå–æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

            # 2. å¦‚æœæ–‡æœ¬æå–å¤±è´¥æˆ–å†…å®¹ä¸è¶³ï¼Œåˆ™è¿›è¡Œå›¾åƒè½¬æ¢
            try:
                file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
                if file_size_mb > 50:
                    return 'error', f"[PDFæ–‡ä»¶è¿‡å¤§: {file_name}] - æ–‡ä»¶å¤§å° {file_size_mb:.1f}MB è¶…è¿‡é™åˆ¶"
                
                # ç›´æ¥è¿”å›PDFè·¯å¾„ï¼Œå¼ºåˆ¶ä»¥å›¾åƒæ¨¡å¼å¤„ç†
                logger.info(f"PDFæ–‡ä»¶å¤„ç†å®Œæˆ: {file_name}, å…±14é¡µ")
                return 'pdf', file_path
            except Exception as e:
                logger.warning(f"PDFå¤„ç†å¼‚å¸¸: {str(e)}")
                return 'error', f"[PDFå¤„ç†å¤±è´¥: {file_name}] - {str(e)}"
        elif file_type == 'word':
            content = read_word_file(file_path)
            logger.info(f"å¤„ç†Wordæ–‡ä»¶ {file_category}: {file_name}")
            return 'text', f"{file_category} [Wordæ–‡æ¡£: {file_name}]\n{content}"
        elif file_type == 'text':
            content = read_text_file(file_path)
            logger.info(f"å¤„ç†æ–‡æœ¬æ–‡ä»¶ {file_category}: {file_name}")
            return 'text', f"{file_category} [æ–‡æœ¬æ–‡ä»¶: {file_name}]\n{content}"
        else:
            try:
                content = read_text_file(file_path)
                logger.info(f"å¤„ç†æœªçŸ¥ç±»å‹æ–‡ä»¶ {file_category}: {file_name}")
                return 'text', f"{file_category} [æ–‡ä»¶: {file_name}]\n{content}"
            except:
                return 'error', f"[ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_name}] - æ— æ³•å¤„ç†æ­¤æ–‡ä»¶"
    except Exception as e:
        return 'error', f"[æ–‡ä»¶å¤„ç†é”™è¯¯: {file_name}] - {str(e)}"

def validate_pdf_file(pdf_path):
    """éªŒè¯PDFæ–‡ä»¶çš„æœ‰æ•ˆæ€§å’Œå¯è¯»æ€§"""
    validation_result = {
        'is_valid': False,
        'error_message': '',
        'file_info': {},
        'suggestions': []
    }
    
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(pdf_path):
            validation_result['error_message'] = f"æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}"
            validation_result['suggestions'].append("è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            return validation_result
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(pdf_path)
        validation_result['file_info']['size_bytes'] = file_size
        validation_result['file_info']['size_mb'] = file_size / (1024 * 1024)
        
        if file_size == 0:
            validation_result['error_message'] = "PDFæ–‡ä»¶ä¸ºç©º"
            validation_result['suggestions'].append("è¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ­£ç¡®ä¸Šä¼ ")
            return validation_result
        
        if file_size > 100 * 1024 * 1024:  # 100MB
            validation_result['error_message'] = f"PDFæ–‡ä»¶è¿‡å¤§ ({file_size / (1024*1024):.1f}MB)"
            validation_result['suggestions'].append("è¯·å°è¯•å‹ç¼©PDFæ–‡ä»¶æˆ–åˆ†å‰²æˆå¤šä¸ªå°æ–‡ä»¶")
            return validation_result
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        if not pdf_path.lower().endswith('.pdf'):
            validation_result['error_message'] = "æ–‡ä»¶æ‰©å±•åä¸æ˜¯.pdf"
            validation_result['suggestions'].append("è¯·ç¡®ä¿æ–‡ä»¶æ˜¯PDFæ ¼å¼")
            return validation_result
        
        # æ£€æŸ¥æ–‡ä»¶å¤´éƒ¨ï¼ˆPDFé­”æ•°ï¼‰
        try:
            with open(pdf_path, 'rb') as f:
                header = f.read(8)
                if not header.startswith(b'%PDF-'):
                    validation_result['error_message'] = "æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„PDFæ ¼å¼ï¼ˆç¼ºå°‘PDFå¤´éƒ¨æ ‡è¯†ï¼‰"
                    validation_result['suggestions'].append("æ–‡ä»¶å¯èƒ½å·²æŸåæˆ–ä¸æ˜¯çœŸæ­£çš„PDFæ–‡ä»¶")
                    return validation_result
                
                # æå–PDFç‰ˆæœ¬
                try:
                    version_line = header.decode('ascii', errors='ignore')
                    if '%PDF-' in version_line:
                        version = version_line.split('%PDF-')[1][:3]
                        validation_result['file_info']['pdf_version'] = version
                except:
                    pass
        except Exception as e:
            validation_result['error_message'] = f"æ— æ³•è¯»å–æ–‡ä»¶å¤´éƒ¨: {str(e)}"
            validation_result['suggestions'].append("æ–‡ä»¶å¯èƒ½å·²æŸåæˆ–è¢«å…¶ä»–ç¨‹åºå ç”¨")
            return validation_result
        
        # å°è¯•ç”¨PDFåº“éªŒè¯æ–‡ä»¶ç»“æ„
        pdf_library_results = []
        
        # æµ‹è¯•PyMuPDF
        try:
            import fitz
            doc = fitz.open(pdf_path)
            page_count = doc.page_count
            is_encrypted = doc.is_encrypted
            doc.close()
            
            pdf_library_results.append({
                'library': 'PyMuPDF',
                'success': True,
                'page_count': page_count,
                'is_encrypted': is_encrypted
            })
            
            validation_result['file_info']['page_count'] = page_count
            validation_result['file_info']['is_encrypted'] = is_encrypted
            
            if is_encrypted:
                validation_result['error_message'] = "PDFæ–‡ä»¶å·²åŠ å¯†"
                validation_result['suggestions'].append("è¯·æä¾›æœªåŠ å¯†çš„PDFæ–‡ä»¶æˆ–æä¾›å¯†ç ")
                return validation_result
            
            if page_count == 0:
                validation_result['error_message'] = "PDFæ–‡ä»¶æ²¡æœ‰é¡µé¢"
                validation_result['suggestions'].append("æ–‡ä»¶å¯èƒ½å·²æŸå")
                return validation_result
                
        except ImportError:
            pdf_library_results.append({
                'library': 'PyMuPDF',
                'success': False,
                'error': 'Library not installed'
            })
        except Exception as e:
            pdf_library_results.append({
                'library': 'PyMuPDF',
                'success': False,
                'error': str(e)
            })
        
        # æµ‹è¯•pypdfium2
        try:
            import pypdfium2 as pdfium
            pdf = pdfium.PdfDocument(pdf_path)
            page_count = len(pdf)
            pdf.close()
            
            pdf_library_results.append({
                'library': 'pypdfium2',
                'success': True,
                'page_count': page_count
            })
            
            if not validation_result['file_info'].get('page_count'):
                validation_result['file_info']['page_count'] = page_count
                
        except ImportError:
            pdf_library_results.append({
                'library': 'pypdfium2',
                'success': False,
                'error': 'Library not installed'
            })
        except Exception as e:
            pdf_library_results.append({
                'library': 'pypdfium2',
                'success': False,
                'error': str(e)
            })
        
        validation_result['file_info']['library_tests'] = pdf_library_results
        
        # æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰ä¸€ä¸ªåº“èƒ½æˆåŠŸå¤„ç†
        successful_libraries = [r for r in pdf_library_results if r['success']]
        if not successful_libraries:
            validation_result['error_message'] = "æ‰€æœ‰PDFå¤„ç†åº“éƒ½æ— æ³•æ‰“å¼€æ­¤æ–‡ä»¶"
            validation_result['suggestions'].extend([
                "æ–‡ä»¶å¯èƒ½å·²æŸå",
                "è¯·å°è¯•ç”¨å…¶ä»–PDFé˜…è¯»å™¨æ‰“å¼€æ–‡ä»¶éªŒè¯",
                "å¦‚æœæ–‡ä»¶æ­£å¸¸ï¼Œè¯·æ£€æŸ¥æ˜¯å¦å®‰è£…äº†PyMuPDFæˆ–pypdfium2åº“"
            ])
            return validation_result
        
        # å¦‚æœæ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡
        validation_result['is_valid'] = True
        validation_result['error_message'] = ''
        
        return validation_result
        
    except Exception as e:
        validation_result['error_message'] = f"PDFéªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        validation_result['suggestions'].append("è¯·è”ç³»æŠ€æœ¯æ”¯æŒ")
        return validation_result

def pdf_pages_to_base64_images(pdf_path, zoom=2.0):
    """å°† PDF æ¯é¡µè½¬æ¢ä¸º Base64 ç¼–ç çš„å›¾åƒæ•°æ®åˆ—è¡¨ï¼Œæ”¯æŒå¤šç§æ–¹æ³• - å¢å¼ºé”™è¯¯è¯Šæ–­ç‰ˆ"""
    
    base64_images = []
    error_details = []
    
    # é¦–å…ˆè¿›è¡ŒPDFæ–‡ä»¶éªŒè¯
    logger.info(f"å¼€å§‹éªŒè¯PDFæ–‡ä»¶: {os.path.basename(pdf_path)}")
    validation_result = validate_pdf_file(pdf_path)
    
    if not validation_result['is_valid']:
        error_msg = f"PDFæ–‡ä»¶éªŒè¯å¤±è´¥: {validation_result['error_message']}"
        logger.error(error_msg)
        logger.error("å»ºè®®è§£å†³æ–¹æ¡ˆ:")
        for suggestion in validation_result['suggestions']:
            logger.error(f"  - {suggestion}")
        
        # è®°å½•æ–‡ä»¶ä¿¡æ¯ç”¨äºè°ƒè¯•
        if validation_result['file_info']:
            logger.error("æ–‡ä»¶ä¿¡æ¯:")
            for key, value in validation_result['file_info'].items():
                logger.error(f"  {key}: {value}")
        
        return []
    
    # è®°å½•éªŒè¯æˆåŠŸçš„æ–‡ä»¶ä¿¡æ¯
    file_info = validation_result['file_info']
    logger.info(f"PDFæ–‡ä»¶éªŒè¯æˆåŠŸ: {os.path.basename(pdf_path)}")
    logger.info(f"  - æ–‡ä»¶å¤§å°: {file_info.get('size_mb', 0):.1f}MB")
    logger.info(f"  - é¡µé¢æ•°é‡: {file_info.get('page_count', 'unknown')}")
    logger.info(f"  - PDFç‰ˆæœ¬: {file_info.get('pdf_version', 'unknown')}")
    logger.info(f"  - æ˜¯å¦åŠ å¯†: {file_info.get('is_encrypted', 'unknown')}")
    
    # æ–¹æ³•1: å°è¯•ä½¿ç”¨ PyMuPDF (fitz)
    fitz_available = False
    try:
        import fitz
        fitz_available = True
        logger.info(f"PyMuPDFå¯ç”¨ï¼Œç‰ˆæœ¬: {fitz.version}")
        
        suppress_context = SuppressOutput() if PDF_UTILS_AVAILABLE else contextlib.nullcontext()
        
        with suppress_context:
            try:
                doc = fitz.open(pdf_path)
                logger.info(f"PDFæ–‡ä»¶æ‰“å¼€æˆåŠŸ: {pdf_path}")
                
                if doc.is_encrypted:
                    logger.warning(f"PDFæ–‡ä»¶ {pdf_path} å·²åŠ å¯†ï¼Œå°è¯•è§£å¯†")
                    if not doc.authenticate(""):
                        error_msg = f"PDFæ–‡ä»¶å·²åŠ å¯†ä¸”æ— æ³•è§£å¯†: {pdf_path}"
                        logger.error(error_msg)
                        error_details.append(error_msg)
                        doc.close()
                    else:
                        logger.info("PDFè§£å¯†æˆåŠŸ")
                
                if not doc.is_encrypted or doc.authenticate(""):
                    if doc.page_count == 0:
                        error_msg = f"PDFæ–‡ä»¶æ²¡æœ‰é¡µé¢: {pdf_path}"
                        logger.warning(error_msg)
                        error_details.append(error_msg)
                        doc.close()
                    else:
                        max_pages = min(doc.page_count, 20)  # é™åˆ¶æœ€å¤šå¤„ç†20é¡µ
                        logger.info(f"å¼€å§‹å¤„ç†PDFï¼Œå…±{doc.page_count}é¡µï¼Œå¤„ç†å‰{max_pages}é¡µ")
                        
                        for page_num in range(max_pages):
                            try:
                                with contextlib.redirect_stderr(open(os.devnull, 'w')):
                                    page = doc.load_page(page_num)
                                    matrix = fitz.Matrix(zoom, zoom)
                                    pix = page.get_pixmap(matrix=matrix, alpha=False)
                                    img_data = pix.tobytes("png")
                                    
                                    # æ£€æŸ¥å›¾åƒæ•°æ®å¤§å°
                                    if len(img_data) > 5 * 1024 * 1024:  # 5MB
                                        logger.info(f"ç¬¬{page_num + 1}é¡µå›¾åƒè¿‡å¤§({len(img_data)/(1024*1024):.1f}MB)ï¼Œè¿›è¡Œå‹ç¼©")
                                        img = Image.open(io.BytesIO(img_data))
                                        if img.mode in ('RGBA', 'LA', 'P'):
                                            img = img.convert('RGB')
                                        
                                        max_size = 1600
                                        if max(img.size) > max_size:
                                            ratio = max_size / max(img.size)
                                            new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))
                                            img = img.resize(new_size, Image.Resampling.LANCZOS)
                                        
                                        buffer = io.BytesIO()
                                        img.save(buffer, format='JPEG', quality=80, optimize=True)
                                        img_data = buffer.getvalue()
                                        logger.info(f"å‹ç¼©åå¤§å°: {len(img_data)/(1024*1024):.1f}MB")
                                    
                                    base64_str = base64.b64encode(img_data).decode("utf-8")
                                    base64_images.append(base64_str)
                                    pix = None
                                    
                                    logger.debug(f"æˆåŠŸå¤„ç†ç¬¬{page_num + 1}é¡µ")
                                    
                            except Exception as e:
                                error_msg = f"PyMuPDFå¤„ç†PDFç¬¬{page_num + 1}é¡µæ—¶å‡ºé”™: {str(e)}"
                                logger.warning(error_msg)
                                error_details.append(error_msg)
                                continue
                        
                        doc.close()
                        
                        if base64_images:
                            logger.info(f"PyMuPDFæˆåŠŸå¤„ç†PDFæ–‡ä»¶ {pdf_path}ï¼Œå…±{len(base64_images)}é¡µ")
                            return base64_images
                        else:
                            error_msg = "PyMuPDFå¤„ç†å®Œæˆä½†æœªç”Ÿæˆä»»ä½•å›¾åƒ"
                            logger.warning(error_msg)
                            error_details.append(error_msg)
                            
            except Exception as doc_error:
                error_msg = f"PyMuPDFæ‰“å¼€PDFæ–‡ä»¶å¤±è´¥: {str(doc_error)}"
                logger.warning(error_msg)
                error_details.append(error_msg)
            
    except ImportError:
        error_msg = "PyMuPDFæœªå®‰è£…"
        logger.warning(error_msg)
        error_details.append(error_msg)
    except Exception as e:
        error_msg = f"PyMuPDFå¤„ç†PDFå¤±è´¥: {str(e)}"
        logger.warning(error_msg)
        error_details.append(error_msg)
    
    # æ–¹æ³•2: ä½¿ç”¨ pypdfium2 (é€šè¿‡ pdfplumber ä¾èµ–å®‰è£…)
    pypdfium2_available = False
    try:
        import pypdfium2 as pdfium
        pypdfium2_available = True
        logger.info("pypdfium2å¯ç”¨")
        
        try:
            pdf = pdfium.PdfDocument(pdf_path)
            max_pages = min(len(pdf), 20)  # é™åˆ¶æœ€å¤šå¤„ç†20é¡µ
            logger.info(f"pypdfium2æ‰“å¼€PDFæˆåŠŸï¼Œå…±{len(pdf)}é¡µï¼Œå¤„ç†å‰{max_pages}é¡µ")
            
            for page_num in range(max_pages):
                try:
                    page = pdf.get_page(page_num)
                    # æ¸²æŸ“é¡µé¢ä¸ºå›¾åƒ
                    bitmap = page.render(scale=zoom, rotation=0)
                    pil_image = bitmap.to_pil()
                    
                    # è½¬æ¢ä¸ºRGBæ ¼å¼
                    if pil_image.mode != 'RGB':
                        pil_image = pil_image.convert('RGB')
                    
                    # å‹ç¼©å›¾åƒå¦‚æœå¤ªå¤§
                    if max(pil_image.size) > 1600:
                        ratio = 1600 / max(pil_image.size)
                        new_size = (int(pil_image.size[0] * ratio), int(pil_image.size[1] * ratio))
                        pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
                    
                    # è½¬æ¢ä¸ºbase64
                    buffer = io.BytesIO()
                    pil_image.save(buffer, format='JPEG', quality=80, optimize=True)
                    img_data = buffer.getvalue()
                    base64_str = base64.b64encode(img_data).decode("utf-8")
                    base64_images.append(base64_str)
                    
                    page.close()
                    logger.debug(f"pypdfium2æˆåŠŸå¤„ç†ç¬¬{page_num + 1}é¡µ")
                    
                except Exception as e:
                    error_msg = f"pypdfium2å¤„ç†PDFç¬¬{page_num + 1}é¡µæ—¶å‡ºé”™: {str(e)}"
                    logger.warning(error_msg)
                    error_details.append(error_msg)
                    continue
            
            pdf.close()
            
            if base64_images:
                logger.info(f"pypdfium2æˆåŠŸå¤„ç†PDFæ–‡ä»¶ {pdf_path}ï¼Œå…±{len(base64_images)}é¡µ")
                return base64_images
            else:
                error_msg = "pypdfium2å¤„ç†å®Œæˆä½†æœªç”Ÿæˆä»»ä½•å›¾åƒ"
                logger.warning(error_msg)
                error_details.append(error_msg)
                
        except Exception as pdf_error:
            error_msg = f"pypdfium2æ‰“å¼€PDFæ–‡ä»¶å¤±è´¥: {str(pdf_error)}"
            logger.warning(error_msg)
            error_details.append(error_msg)
            
    except ImportError:
        error_msg = "pypdfium2æœªå®‰è£…"
        logger.warning(error_msg)
        error_details.append(error_msg)
    except Exception as e:
        error_msg = f"pypdfium2å¤„ç†PDFå¤±è´¥: {str(e)}"
        logger.warning(error_msg)
        error_details.append(error_msg)
    
    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
    if not base64_images:
        logger.error(f"æ‰€æœ‰PDFå¤„ç†æ–¹æ³•éƒ½å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆé¢„è§ˆ: {pdf_path}")
        logger.error("é”™è¯¯è¯¦æƒ…:")
        for i, error in enumerate(error_details, 1):
            logger.error(f"  {i}. {error}")
        
        # æä¾›è¯Šæ–­ä¿¡æ¯
        diagnostic_info = []
        diagnostic_info.append(f"æ–‡ä»¶è·¯å¾„: {pdf_path}")
        diagnostic_info.append(f"æ–‡ä»¶å­˜åœ¨: {os.path.exists(pdf_path)}")
        if os.path.exists(pdf_path):
            diagnostic_info.append(f"æ–‡ä»¶å¤§å°: {os.path.getsize(pdf_path)} å­—èŠ‚")
        diagnostic_info.append(f"PyMuPDFå¯ç”¨: {fitz_available}")
        diagnostic_info.append(f"pypdfium2å¯ç”¨: {pypdfium2_available}")
        
        logger.error("è¯Šæ–­ä¿¡æ¯:")
        for info in diagnostic_info:
            logger.error(f"  - {info}")
        
        return []
    
    return base64_images

def create_batch_grading_prompt(batch_number, total_batches, current_range, system_message):
    """åˆ›å»ºåˆ†æ‰¹æ‰¹æ”¹çš„æç¤ºè¯"""
    batch_prompt = f"""
ğŸ”¢ã€åˆ†æ‰¹æ‰¹æ”¹ - ç¬¬{batch_number}æ‰¹/å…±{total_batches}æ‰¹ã€‘ğŸ”¢

ğŸ“‹ å½“å‰æ‰¹æ¬¡èŒƒå›´ï¼šç¬¬{current_range[0]}-{current_range[1]}é¢˜
âš ï¸ åªå…³æ³¨å½“å‰æ‰¹æ¬¡çš„é¢˜ç›®ï¼Œä¸è¦æ¶‰åŠå…¶ä»–é¢˜ç›®

{system_message}

ğŸ¯ã€å½“å‰æ‰¹æ¬¡ä¸“é¡¹è¦æ±‚ã€‘ğŸ¯
1. ä»…æ‰¹æ”¹ç¬¬{current_range[0]}-{current_range[1]}é¢˜
2. å¦‚æœå­¦ç”Ÿç­”æ¡ˆä¸­æ²¡æœ‰æŸé¢˜ï¼Œæ ‡è®°ä¸º"æœªä½œç­”"å¹¶è·³è¿‡
3. å®Œæˆå½“å‰æ‰¹æ¬¡åç«‹å³åœæ­¢ï¼Œä¸è¦ç»§ç»­å…¶ä»–é¢˜ç›®
4. æ¯é¢˜æ‰¹æ”¹åæ£€æŸ¥æ˜¯å¦å‡ºç°é‡å¤å†…å®¹

â¸ï¸ã€æ‰¹æ¬¡å®Œæˆæ£€æŸ¥ã€‘â¸ï¸
å½“å‰æ‰¹æ¬¡é¢„æœŸå®Œæˆç¬¬{current_range[0]}-{current_range[1]}é¢˜ï¼š
â–¡ æ˜¯å¦åªå¤„ç†äº†å½“å‰æ‰¹æ¬¡èŒƒå›´å†…çš„é¢˜ç›®ï¼Ÿ
â–¡ æ˜¯å¦è·³è¿‡äº†å­¦ç”Ÿæœªä½œç­”çš„é¢˜ç›®ï¼Ÿ
â–¡ æ˜¯å¦é¿å…äº†å¾ªç¯å’Œé‡å¤ï¼Ÿ
â–¡ æ˜¯å¦å‡†å¤‡å¥½è¿›å…¥ä¸‹ä¸€æ‰¹æ¬¡ï¼Ÿ

å¼€å§‹ç¬¬{batch_number}æ‰¹æ‰¹æ”¹ï¼š
"""
    return batch_prompt

def split_grading_task(content_text, batch_size=10):
    """
    å°†å¤§å‹æ‰¹æ”¹ä»»åŠ¡åˆ†å‰²æˆå°æ‰¹æ¬¡
    
    Args:
        content_text: è¦æ‰¹æ”¹çš„å†…å®¹
        batch_size: æ¯æ‰¹æ¬¡å¤„ç†çš„é¢˜ç›®æ•°é‡
    
    Returns:
        list: åˆ†æ‰¹å¤„ç†çš„é…ç½®åˆ—è¡¨
    """
    # ç®€å•çš„é¢˜ç›®æ•°é‡ä¼°ç®—ï¼ˆåŸºäºå¸¸è§æ¨¡å¼ï¼‰
    import re
    
    # å¯»æ‰¾é¢˜ç›®æ ‡è¯†ç¬¦
    question_patterns = [
        r'ç¬¬\s*(\d+)\s*é¢˜',  # ç¬¬Xé¢˜
        r'é¢˜\s*(\d+)',      # é¢˜X
        r'Q\.?\s*(\d+)',    # Q.X æˆ– QX
        r'(\d+)\)',         # X)
        r'Problem\s*(\d+)', # Problem X
    ]
    
    question_numbers = set()
    for pattern in question_patterns:
        matches = re.findall(pattern, content_text, re.IGNORECASE)
        for match in matches:
            try:
                question_numbers.add(int(match))
            except ValueError:
                continue
    
    if not question_numbers:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¢˜ç›®ç¼–å·ï¼Œå‡è®¾æœ‰10é“é¢˜
        question_numbers = set(range(1, 11))
    
    max_question = max(question_numbers) if question_numbers else 10
    
    # åˆ›å»ºæ‰¹æ¬¡é…ç½®
    batches = []
    for start in range(1, max_question + 1, batch_size):
        end = min(start + batch_size - 1, max_question)
        batches.append({
            'range': (start, end),
            'batch_number': len(batches) + 1,
            'total_batches': (max_question + batch_size - 1) // batch_size
        })
    
    return batches

def call_tongyiqianwen_api_batch(input_text: str, *input_contents, system_message: str = "", batch_size: int = 10) -> str:
    """
    åˆ†æ‰¹è°ƒç”¨APIè¿›è¡Œæ‰¹æ”¹ï¼Œé¿å…å¾ªç¯å’Œå†…å­˜æº¢å‡º
    
    Args:
        input_text: è¾“å…¥æ–‡æœ¬
        input_contents: è¾“å…¥å†…å®¹ï¼ˆå›¾ç‰‡ç­‰ï¼‰
        system_message: ç³»ç»Ÿæ¶ˆæ¯
        batch_size: æ¯æ‰¹æ¬¡å¤„ç†çš„é¢˜ç›®æ•°é‡
    
    Returns:
        str: å®Œæ•´çš„æ‰¹æ”¹ç»“æœ
    """
    try:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†æ‰¹å¤„ç†
        content_length = len(input_text)
        if content_length < 5000:  # å†…å®¹è¾ƒå°‘ï¼Œä¸éœ€è¦åˆ†æ‰¹
            return call_tongyiqianwen_api(input_text, *input_contents, system_message=system_message)
        
        logger.info(f"å†…å®¹è¾ƒé•¿({content_length}å­—ç¬¦)ï¼Œå¯åŠ¨åˆ†æ‰¹å¤„ç†æ¨¡å¼")
        
        # åˆ†æé¢˜ç›®èŒƒå›´
        batches = split_grading_task(input_text, batch_size)
        logger.info(f"è®¡åˆ’åˆ†{len(batches)}æ‰¹å¤„ç†ï¼Œæ¯æ‰¹{batch_size}é¢˜")
        
        all_results = []
        
        for i, batch_config in enumerate(batches):
            batch_number = batch_config['batch_number']
            total_batches = batch_config['total_batches']
            current_range = batch_config['range']
            
            logger.info(f"å¼€å§‹å¤„ç†ç¬¬{batch_number}æ‰¹ï¼šç¬¬{current_range[0]}-{current_range[1]}é¢˜")
            
            # åˆ›å»ºå½“å‰æ‰¹æ¬¡çš„æç¤ºè¯
            batch_prompt = create_batch_grading_prompt(
                batch_number, total_batches, current_range, system_message
            )
            
            # è°ƒç”¨APIå¤„ç†å½“å‰æ‰¹æ¬¡
            try:
                batch_result = call_tongyiqianwen_api(
                    input_text, 
                    *input_contents, 
                    system_message=batch_prompt
                )
                
                if batch_result:
                    # æ·»åŠ æ‰¹æ¬¡æ ‡è¯†
                    batch_header = f"\n{'='*50}\nğŸ“‹ ç¬¬{batch_number}æ‰¹æ‰¹æ”¹ç»“æœ (ç¬¬{current_range[0]}-{current_range[1]}é¢˜)\n{'='*50}\n"
                    all_results.append(batch_header + batch_result)
                    
                    logger.info(f"ç¬¬{batch_number}æ‰¹å¤„ç†å®Œæˆ")
                else:
                    logger.warning(f"ç¬¬{batch_number}æ‰¹å¤„ç†å¤±è´¥ï¼Œè·³è¿‡")
                    
            except Exception as e:
                logger.error(f"ç¬¬{batch_number}æ‰¹å¤„ç†å‡ºé”™: {str(e)}")
                all_results.append(f"\nâŒ ç¬¬{batch_number}æ‰¹å¤„ç†å¤±è´¥: {str(e)}\n")
                continue
        
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        if all_results:
            final_result = "\n".join(all_results)
            
            # æ·»åŠ æ€»ç»“
            summary = f"""
\n{'='*50}
ğŸ“Š åˆ†æ‰¹æ‰¹æ”¹æ€»ç»“
{'='*50}
âœ… å…±å¤„ç† {len(batches)} ä¸ªæ‰¹æ¬¡
ğŸ“‹ é¢„æœŸé¢˜ç›®èŒƒå›´: ç¬¬1-{batches[-1]['range'][1]}é¢˜
âš ï¸ å¦‚æœ‰é¢˜ç›®ç¼ºå¤±ï¼Œè¯´æ˜å­¦ç”Ÿæœªä½œç­”
âœ¨ æ‰¹æ”¹å®Œæˆï¼
{'='*50}
"""
            final_result += summary
            
            logger.info("åˆ†æ‰¹æ‰¹æ”¹å…¨éƒ¨å®Œæˆ")
            return final_result
        else:
            logger.error("æ‰€æœ‰æ‰¹æ¬¡éƒ½å¤„ç†å¤±è´¥")
            return "âŒ åˆ†æ‰¹æ‰¹æ”¹å¤±è´¥ï¼Œæ‰€æœ‰æ‰¹æ¬¡éƒ½å‡ºç°é”™è¯¯"
            
    except Exception as e:
        logger.error(f"åˆ†æ‰¹æ‰¹æ”¹ç³»ç»Ÿå‡ºé”™: {str(e)}")
        # é™çº§åˆ°æ™®é€šæ¨¡å¼
        logger.info("é™çº§åˆ°æ™®é€šæ‰¹æ”¹æ¨¡å¼")
        return call_tongyiqianwen_api(input_text, *input_contents, system_message=system_message)

def call_tongyiqianwen_api(input_text: str, *input_contents, system_message: str = "") -> str:
    """è°ƒç”¨APIè¿›è¡Œå¤šç±»å‹æ–‡ä»¶å¤„ç†"""
    from openai import OpenAI
    
    if not api_config.is_valid():
        error_msg = f"""
ğŸš« APIé…ç½®é”™è¯¯

å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š
1. è®¾ç½®ç¯å¢ƒå˜é‡ï¼šOPENROUTER_API_KEY=your_api_key
2. æ£€æŸ¥APIå¯†é’¥æ ¼å¼
3. ç¡®è®¤å¯†é’¥æœ‰æ•ˆæ€§

å½“å‰é…ç½®çŠ¶æ€ï¼š
{json.dumps(api_config.get_status(), ensure_ascii=False, indent=2)}"""
        logger.error("APIé…ç½®æ— æ•ˆ")
        return error_msg
    
    try:
        client = OpenAI(
            api_key=api_config.api_key,
            base_url=api_config.base_url,
            timeout=api_config.timeout
        )
    except Exception as e:
        error_msg = f"âŒ OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        return error_msg
    
    content = [{"type": "text", "text": input_text}]
    
    try:
        for single_content in input_contents:
            if (isinstance(single_content, tuple) and 
                len(single_content) == 2 and 
                all(isinstance(item, str) for item in single_content)):
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/{single_content[0]};base64,{single_content[1]}"
                    }
                })   
            elif os.path.isfile(single_content):
                logger.info(f"å¤„ç†æ–‡ä»¶ [è¯†åˆ«ç±»å‹]: {os.path.basename(single_content)}")
                content_type, processed_content = process_file_content(single_content)            
                if content_type == 'text':
                    logger.info(f"æ–‡æœ¬æ–‡ä»¶å¤„ç†å®Œæˆ: {os.path.basename(single_content)}, é•¿åº¦: {len(processed_content)} å­—ç¬¦")
                    content.append({
                        "type": "text",
                        "text": processed_content
                    })
                elif content_type == 'image':
                    logger.info(f"å›¾ç‰‡æ–‡ä»¶å¤„ç†å¼€å§‹: {os.path.basename(single_content)}")
                    base_64_image = img_to_base64(single_content)
                    logger.info(f"å›¾ç‰‡æ–‡ä»¶å¤„ç†å®Œæˆ: {os.path.basename(single_content)}, Base64é•¿åº¦: {len(base_64_image)}")
                    content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base_64_image}"
                        }
                    })    
                elif content_type == 'pdf':
                    logger.info(f"PDFæ–‡ä»¶å¤„ç†å¼€å§‹: {os.path.basename(single_content)}")
                    base_64_images = pdf_pages_to_base64_images(single_content)
                    logger.info(f"PDFæ–‡ä»¶å¤„ç†å®Œæˆ: {os.path.basename(single_content)}, å…±{len(base_64_images)}é¡µ")
                    for i, base_64_image in enumerate(base_64_images):
                        content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{base_64_image}"
                            }
                        })
                        logger.debug(f"PDFç¬¬{i+1}é¡µå·²æ·»åŠ åˆ°å†…å®¹ä¸­")
                else:
                    raise ValueError(f"The file {single_content} could not be processed.")
            else:
                content.append({
                    "type": "text",
                    "text": single_content
                })
    except Exception as e:
        error_msg = f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        return error_msg

    for attempt in range(api_config.max_retries):
        try:
            final_message = []
            if system_message:
                final_message.append({"role": "system", "content": system_message})
            final_message.append({"role": "user", "content": content})
            
            # è®°å½•APIè°ƒç”¨è¯¦ç»†ä¿¡æ¯
            start_time = time.time()
            logger.info(f"APIè°ƒç”¨å°è¯• {attempt + 1}/{api_config.max_retries}")
            logger.info(f"å‘é€çš„æ¶ˆæ¯æ•°é‡: {len(final_message)}")
            logger.info(f"ä½¿ç”¨çš„æ¨¡å‹: {api_config.model}")
            
            # è®°å½•è¾“å…¥å†…å®¹ç»Ÿè®¡
            total_text_length = sum(len(str(msg.get('content', ''))) for msg in final_message)
            logger.info(f"è¾“å…¥å†…å®¹æ€»é•¿åº¦: {total_text_length} å­—ç¬¦")
            
            response = client.chat.completions.create(
                model=api_config.model,
                messages=final_message,
                max_tokens=api_config.max_tokens,
                temperature=api_config.temperature
            )

            result = response.choices[0].message.content
            processing_time = time.time() - start_time
            
            # è®°å½•APIè°ƒç”¨ç»“æœè¯¦ç»†ä¿¡æ¯
            logger.info("=" * 80)
            logger.info("ğŸ” APIè°ƒç”¨å®Œæ•´è¿”å›ç»“æœ:")
            logger.info(f"è¿”å›å†…å®¹é•¿åº¦: {len(result) if result else 0}")
            logger.info(f"å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
            logger.info(f"è¿”å›å†…å®¹é¢„è§ˆ: {result[:200] if result else 'None'}...")
            logger.info(f"è¿”å›å†…å®¹å®Œæ•´: {result if result else 'None'}")
            logger.info("=" * 80)
        
            if not result or not result.strip():
                logger.warning("APIè¿”å›ç©ºç»“æœ")
                if attempt < api_config.max_retries - 1:
                    time.sleep(api_config.retry_delay)
                    continue
                else:
                    fallback_msg = "âŒ APIè¿”å›äº†ç©ºç»“æœã€‚å¯èƒ½çš„åŸå› ï¼šæ–‡ä»¶å†…å®¹æ— æ³•è¯†åˆ«æˆ–APIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚"
                    logger.error("æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›fallbackæ¶ˆæ¯")
                    return fallback_msg
            
            logger.info("âœ… APIè°ƒç”¨æˆåŠŸå®Œæˆ")
            return result
        
        except Exception as e:
            error_str = str(e)
            logger.error(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}): {error_str}")
            
            if "timeout" in error_str.lower() or "timed out" in error_str.lower():
                timeout_error_msg = f"""âŒ è¯·æ±‚è¶…æ—¶é”™è¯¯
é—®é¢˜åˆ†æï¼šç½‘ç»œè¿æ¥è¶…æ—¶ã€APIæœåŠ¡å™¨å“åº”ç¼“æ…¢ã€å¤„ç†çš„æ–‡ä»¶è¿‡å¤§æˆ–è¿‡å¤š
è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥ã€å‡å°‘å•æ¬¡å¤„ç†çš„æ–‡ä»¶æ•°é‡ã€ç¨åé‡è¯•
é”™è¯¯è¯¦æƒ…ï¼š{error_str}"""
                if attempt < api_config.max_retries - 1:
                    wait_time = api_config.retry_delay * (2 ** attempt)
                    logger.info(f"é‡åˆ°è¶…æ—¶é”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•")
                    time.sleep(wait_time)
                    continue
                else:
                    return timeout_error_msg
            
            if "401" in error_str or "Unauthorized" in error_str:
                auth_error_msg = f"""âŒ è®¤è¯å¤±è´¥ (401 Unauthorized)
é—®é¢˜åˆ†æï¼šAPIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸã€å¯†é’¥æ ¼å¼é”™è¯¯ã€è´¦æˆ·ä½™é¢ä¸è¶³
è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥APIå¯†é’¥ã€æ›´æ–°APIå¯†é’¥ã€æ£€æŸ¥è´¦æˆ·çŠ¶æ€
å½“å‰ä½¿ç”¨çš„å¯†é’¥æ¥æºï¼š{api_config.get_status()['api_key_source']}
åŸå§‹é”™è¯¯ï¼š{error_str}"""
                logger.error("è®¤è¯å¤±è´¥")
                return auth_error_msg
            
            elif "429" in error_str or "rate_limit" in error_str.lower():
                # å°è¯•åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹
                if api_config.switch_to_next_model():
                    logger.info(f"é‡åˆ°é¢‘ç‡é™åˆ¶ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹: {api_config.model}")
                    # é‡æ–°åˆ›å»ºå®¢æˆ·ç«¯
                    try:
                        client = OpenAI(
                            api_key=api_config.api_key,
                            base_url=api_config.base_url,
                            timeout=api_config.timeout
                        )
                        # é‡ç½®é‡è¯•è®¡æ•°å™¨ï¼Œç»™æ–°æ¨¡å‹æœºä¼š
                        attempt = 0
                        continue
                    except Exception as model_switch_error:
                        logger.error(f"åˆ‡æ¢æ¨¡å‹å¤±è´¥: {model_switch_error}")
                
                # å¦‚æœæ²¡æœ‰æ›´å¤šæ¨¡å‹å¯åˆ‡æ¢ï¼Œåˆ™ç­‰å¾…é‡è¯•
                rate_limit_msg = f"âŒ APIè°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œå½“å‰æ¨¡å‹ï¼š{api_config.model}ã€‚é”™è¯¯ï¼š{error_str}"
                if attempt < api_config.max_retries - 1:
                    wait_time = api_config.retry_delay * (2 ** attempt)
                    logger.info(f"é‡åˆ°é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•")
                    time.sleep(wait_time)
                    continue
                else:
                    # é‡ç½®æ¨¡å‹ç´¢å¼•ï¼Œä¸ºä¸‹æ¬¡è°ƒç”¨å‡†å¤‡
                    api_config.reset_model()
                    return rate_limit_msg
            
            elif "500" in error_str or "502" in error_str or "503" in error_str or "504" in error_str:
                if "504" in error_str:
                    server_error_msg = f"""âŒ ç½‘å…³è¶…æ—¶é”™è¯¯ (504 Gateway Timeout)
é—®é¢˜åˆ†æï¼šAPIæœåŠ¡å™¨å“åº”è¶…æ—¶ã€ç½‘ç»œè¿æ¥ä¸ç¨³å®šã€æœåŠ¡å™¨è´Ÿè½½è¿‡é«˜
è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥ç¨³å®šæ€§ã€ç¨åé‡è¯•ã€è€ƒè™‘å‡å°‘å•æ¬¡å¤„ç†çš„æ–‡ä»¶æ•°é‡
é”™è¯¯è¯¦æƒ…ï¼š{error_str}"""
                else:
                    server_error_msg = f"âŒ æœåŠ¡å™¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚é”™è¯¯ï¼š{error_str}"
                
                if attempt < api_config.max_retries - 1:
                    wait_time = api_config.retry_delay * (2 ** attempt)
                    logger.info(f"é‡åˆ°æœåŠ¡å™¨é”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•")
                    time.sleep(wait_time)
                    continue
                else:
                    return server_error_msg
            
            if attempt < api_config.max_retries - 1:
                time.sleep(api_config.retry_delay * (attempt + 1))
                continue
            else:
                error_msg = f"""âŒ APIè°ƒç”¨å¤±è´¥ (æ‰€æœ‰é‡è¯•å·²è€—å°½)
é”™è¯¯è¯¦æƒ…ï¼š{error_str}
å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥ã€éªŒè¯APIå¯†é’¥æœ‰æ•ˆæ€§ã€ç¡®è®¤è´¦æˆ·ä½™é¢å……è¶³ã€ç¨åé‡è¯•
é…ç½®ä¿¡æ¯ï¼š{json.dumps(api_config.get_status(), ensure_ascii=False, indent=2)}"""
                logger.error(error_msg)
                return error_msg

# æ ‡å‡†APIè°ƒç”¨å‡½æ•°
default_api = call_tongyiqianwen_api

# ===================== ç»“æœç±»å’Œè£…é¥°å™¨ =====================
class GradingResult:
    """æ‰¹æ”¹ç»“æœæ ‡å‡†åŒ–ç±»"""
    
    def __init__(self, success: bool = True, data: Any = None, error_message: str = "", processing_time: float = 0.0):
        self.success = success
        self.data = data
        self.error_message = error_message
        self.processing_time = processing_time
        self.timestamp = time.time()
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œé€‚åˆç½‘ç«™APIè¿”å›"""
        return {
            "success": self.success,
            "data": self.data,
            "error_message": self.error_message,
            "processing_time": self.processing_time,
            "timestamp": self.timestamp
        }
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²"""
        return json.dumps(self.to_dict(), ensure_ascii=False, indent=2)

def safe_api_call(func):
    """è£…é¥°å™¨ï¼šä¸ºAPIè°ƒç”¨æ·»åŠ ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œç»“æœåŒ…è£…"""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œ {func.__name__}")
            result = func(*args, **kwargs)
            processing_time = time.time() - start_time
            logger.info(f"{func.__name__} æ‰§è¡ŒæˆåŠŸï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            return GradingResult(success=True, data=result, processing_time=processing_time)
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"{func.__name__} æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return GradingResult(success=False, error_message=error_msg, processing_time=processing_time)
    return wrapper

# ===================== æ ¸å¿ƒæ‰¹æ”¹å‡½æ•° =====================
def batch_correction_with_standard(marking_scheme_files: List[str], student_answer_files: List[str], 
                                  strictness_level: str = "ä¸­ç­‰", api=default_api, use_batch_processing: bool = True, batch_size: int = 10) -> dict:
    """æ‰¹é‡æ‰¹æ”¹ - æœ‰æ‰¹æ”¹æ ‡å‡†æ¨¡å¼"""
    try:
        marking_contents = []
        marking_file_info = []
        for i, file in enumerate(marking_scheme_files):
            content_type, content = process_file_content(file)
            if content_type == 'error':
                raise ValueError(f"å¤„ç†æ‰¹æ”¹æ ‡å‡†æ–‡ä»¶å¤±è´¥: {content}")
            elif content_type == 'image' or content_type == 'pdf':
                marking_contents.append(file)
                marking_file_info.append(f"ã€æ‰¹æ”¹æ–¹æ¡ˆæ–‡ä»¶ {i+1}ã€‘: {os.path.basename(file)}")
            else:
                marking_contents.append(content)
                marking_file_info.append(f"ã€æ‰¹æ”¹æ–¹æ¡ˆæ–‡ä»¶ {i+1}ã€‘: {os.path.basename(file)}")
        
        student_contents = []
        student_file_info = []
        for i, file in enumerate(student_answer_files):
            content_type, content = process_file_content(file)
            if content_type == 'error':
                raise ValueError(f"å¤„ç†å­¦ç”Ÿç­”æ¡ˆæ–‡ä»¶å¤±è´¥: {content}")
            elif content_type == 'image' or content_type == 'pdf':
                student_contents.append(file)
                student_file_info.append(f"ã€å­¦ç”Ÿä½œç­”æ–‡ä»¶ {i+1}ã€‘: {os.path.basename(file)}")
            else:
                student_contents.append(content)
                student_file_info.append(f"ã€å­¦ç”Ÿä½œç­”æ–‡ä»¶ {i+1}ã€‘: {os.path.basename(file)}")
        
        prompt = prompts_module.get_complete_grading_prompt(file_info_list=[])
        
        api_args = []
        if marking_contents:
            api_args.append("=" * 50)
            api_args.append("æ‰¹æ”¹æ–¹æ¡ˆæ–‡ä»¶ï¼ˆåŒ…å«æ­£ç¡®ç­”æ¡ˆå’Œè¯„åˆ†æ ‡å‡†ï¼‰ï¼š")
            api_args.append("=" * 50)
            for i, (info, content) in enumerate(zip(marking_file_info, marking_contents)):
                api_args.append(f"\n{info}")
                api_args.append(content)
            api_args.append("\n" + "=" * 50)
        
        if student_contents:
            api_args.append("\n" + "=" * 50)
            api_args.append("å­¦ç”Ÿä½œç­”æ–‡ä»¶ï¼ˆéœ€è¦æ‰¹æ”¹çš„ç­”æ¡ˆï¼‰ï¼š")
            api_args.append("=" * 50)
            for i, (info, content) in enumerate(zip(student_file_info, student_contents)):
                api_args.append(f"\n{info}")
                api_args.append(content)
            api_args.append("\n" + "=" * 50)
        
        api_args.append("\nã€æ‰¹æ”¹æŒ‡ä»¤ã€‘ï¼š")
        api_args.append(prompt)
        
        result = api(*api_args, system_message=prompts_module.get_core_grading_prompt())
        
        return {
            "correction_result": result,
            "has_separate_scheme": False
        }
        
    except Exception as e:
        error_msg = f"æ‰¹æ”¹å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        raise RuntimeError(error_msg) from e

def batch_correction_without_standard(question_files: List[str], student_answer_files: List[str], 
                                     strictness_level: str = "ä¸­ç­‰", api=default_api) -> dict:
    """æ‰¹é‡æ‰¹æ”¹ - æ— æ‰¹æ”¹æ ‡å‡†æ¨¡å¼ï¼ˆè‡ªåŠ¨ç”Ÿæˆæ‰¹æ”¹æ ‡å‡†ï¼‰"""
    try:
        logger.info("æ­£åœ¨æ ¹æ®é¢˜ç›®ç”Ÿæˆæ‰¹æ”¹æ ‡å‡†...")
        
        # å¯¹äºç®€åŒ–ç‰ˆï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨å­¦ç”Ÿç­”æ¡ˆæ–‡ä»¶è¿›è¡Œæ‰¹æ”¹
        # å› ä¸ºç®€åŒ–ç‰ˆå‡è®¾MARKING_æ–‡ä»¶åŒ…å«å®Œæ•´ä¿¡æ¯
        if not student_answer_files:
            raise ValueError("ç¼ºå°‘å­¦ç”Ÿç­”æ¡ˆæ–‡ä»¶")
        
        # ä½¿ç”¨ç®€åŒ–ç‰ˆæ‰¹æ”¹é€»è¾‘
        file_info_list = []
        for file_path in student_answer_files:
            filename = os.path.basename(file_path)
            file_info = {
                'name': filename,
                'path': file_path,
                'type': get_file_type(file_path),
                'expected_category': 'answer'
            }
            file_info_list.append(file_info)
        
        prompt = prompts_module.get_complete_grading_prompt(file_info_list=file_info_list)
        
        api_args = []
        api_args.append("=" * 50)
        api_args.append("å­¦ç”Ÿä½œç­”æ–‡ä»¶ï¼ˆéœ€è¦æ‰¹æ”¹çš„ç­”æ¡ˆï¼‰ï¼š")
        api_args.append("=" * 50)
        
        for file_path in student_answer_files:
            api_args.append(f"\næ–‡ä»¶ï¼š{os.path.basename(file_path)}")
            content_type, content = process_file_content(file_path)
            if content_type == 'error':
                raise ValueError(f"å¤„ç†å­¦ç”Ÿç­”æ¡ˆæ–‡ä»¶å¤±è´¥: {content}")
            elif content_type in ['image', 'pdf']:
                api_args.append(file_path)
            else:
                api_args.append(content)
        
        api_args.append("\n" + "=" * 50)
        api_args.append("\nã€æ‰¹æ”¹æŒ‡ä»¤ã€‘ï¼š")
        api_args.append(prompt)
        
        result = api(*api_args, system_message=prompts_module.get_core_grading_prompt())
        
        return {
            "correction_result": result,
            "has_separate_scheme": False
        }
        
    except Exception as e:
        error_msg = f"æ‰¹æ”¹å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        raise RuntimeError(error_msg) from e

def intelligent_correction_with_files(question_files=None, answer_files=None, marking_scheme_files=None, 
                                    strictness_level="ä¸­ç­‰", mode="efficient"):
    """æ™ºèƒ½æ–‡ä»¶æ‰¹æ”¹å‡½æ•° - ç®€åŒ–ç‰ˆæœ¬"""
    if not answer_files:
        error_msg = "å¿…é¡»æä¾›å­¦ç”Ÿç­”æ¡ˆæ–‡ä»¶"
        logger.error(error_msg)
        return error_msg
    
    try:
        if marking_scheme_files:
            logger.info(f"ä½¿ç”¨æ‰¹æ”¹æ ‡å‡†æ¨¡å¼ - æ ‡å‡†æ–‡ä»¶: {len(marking_scheme_files)}, ç­”æ¡ˆæ–‡ä»¶: {len(answer_files)}")
            result = batch_correction_with_standard(
                marking_scheme_files,
                answer_files,
                strictness_level=strictness_level,
                api=default_api
            )
        else:
            logger.info(f"ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆæ‰¹æ”¹æ ‡å‡†æ¨¡å¼ - ç­”æ¡ˆæ–‡ä»¶: {len(answer_files)}")
            files_for_scheme = question_files if question_files else answer_files
            result = batch_correction_without_standard(
                files_for_scheme,
                answer_files,
                strictness_level=strictness_level,
                api=default_api
            )
        
        return result
        
    except Exception as e:
        error_msg = f"æ™ºèƒ½æ‰¹æ”¹å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        return error_msg

def simplified_batch_correction(files_dict: dict, strictness_level: str = "ä¸¥æ ¼", api=None) -> dict:
    """ä½¿ç”¨ç®€åŒ–æç¤ºè¯çš„æ‰¹é‡æ‰¹æ”¹å‡½æ•° - ä¿®å¤ç‰ˆæœ¬"""
    if api is None:
        api = default_api
    
    try:
        answer_files = files_dict.get('answer_files', [])
        marking_files = files_dict.get('marking_files', [])
        question_files = files_dict.get('question_files', [])
        
        if not answer_files:
            return {
                "success": False,
                "error": "ç¼ºå°‘å­¦ç”Ÿç­”æ¡ˆæ–‡ä»¶",
                "message": "å¿…é¡»æä¾›å­¦ç”Ÿç­”æ¡ˆæ–‡ä»¶"
            }
        
        # æ„å»ºæ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
        file_info_list = []
        all_files = [
            (answer_files, 'answer'),
            (marking_files, 'marking'),
            (question_files, 'question')
        ]
        
        for file_list, expected_category in all_files:
            for file_path in file_list:
                filename = os.path.basename(file_path)
                file_info = {
                    'name': filename,
                    'path': file_path,
                    'type': get_file_type(file_path),
                    'expected_category': expected_category
                }
                file_info_list.append(file_info)
        
        prompt = prompts_module.get_complete_grading_prompt(file_info_list=file_info_list)
        system_msg = prompts_module.get_core_grading_prompt()
        
        api_args = []
        
        # æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
        if not answer_files:
            return {
                "success": False,
                "error": "ç¼ºå°‘å­¦ç”Ÿç­”æ¡ˆæ–‡ä»¶",
                "message": "ç¼ºå°‘å­¦ç”Ÿç­”æ¡ˆæ–‡ä»¶"
            }
        
        # å¤„ç†æ–‡ä»¶
        if question_files:
            api_args.append("=" * 50)
            api_args.append("ğŸ“‹ é¢˜ç›®æ–‡ä»¶ï¼ˆæ¥è‡ªé¢˜ç›®ä¸Šä¼ åŒºåŸŸï¼‰ï¼š")
            api_args.append("=" * 50)
            for file_path in question_files:
                api_args.append(f"\næ–‡ä»¶ï¼š{os.path.basename(file_path)}")
                content_type, content = process_file_content(file_path)
                if content_type == 'error':
                    raise ValueError(f"å¤„ç†é¢˜ç›®æ–‡ä»¶å¤±è´¥: {content}")
                elif content_type in ['image', 'pdf']:
                    api_args.append(file_path)
                else:
                    api_args.append(content)
        
        if answer_files:
            api_args.append("\n" + "=" * 50)
            api_args.append("âœï¸ å­¦ç”Ÿç­”æ¡ˆï¼ˆæ¥è‡ªå­¦ç”Ÿç­”æ¡ˆä¸Šä¼ åŒºåŸŸï¼‰ï¼š")
            api_args.append("=" * 50)
            for file_path in answer_files:
                api_args.append(f"\næ–‡ä»¶ï¼š{os.path.basename(file_path)}")
                content_type, content = process_file_content(file_path)
                if content_type == 'error':
                    raise ValueError(f"å¤„ç†å­¦ç”Ÿç­”æ¡ˆæ–‡ä»¶å¤±è´¥: {content}")
                elif content_type in ['image', 'pdf']:
                    api_args.append(file_path)
                else:
                    api_args.append(content)
        
        if marking_files:
            api_args.append("\n" + "=" * 50)
            api_args.append("ğŸ“Š æ‰¹æ”¹æ–¹æ¡ˆï¼ˆæ¥è‡ªæ‰¹æ”¹æ–¹æ¡ˆä¸Šä¼ åŒºåŸŸï¼‰ï¼š")
            api_args.append("=" * 50)
            for file_path in marking_files:
                api_args.append(f"\næ–‡ä»¶ï¼š{os.path.basename(file_path)}")
                content_type, content = process_file_content(file_path)
                if content_type == 'error':
                    raise ValueError(f"å¤„ç†æ‰¹æ”¹æ–¹æ¡ˆæ–‡ä»¶å¤±è´¥: {content}")
                elif content_type in ['image', 'pdf']:
                    api_args.append(file_path)
                else:
                    api_args.append(content)
        
        api_args.append("\n" + "=" * 50)
        api_args.append("\nã€æ‰¹æ”¹æŒ‡ä»¤ã€‘ï¼š")
        api_args.append(prompt)
        
        result = api(*api_args, system_message=system_msg)
        
        return {
            "success": True,
            "result": result,
            "mode": "simplified_fixed",
            "strictness": strictness_level,
            "file_classification": "automatic_by_filename"
        }
        
    except Exception as e:
        logger.error(f"ç®€åŒ–æ‰¹æ”¹å¤±è´¥: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "message": "æ‰¹æ”¹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"
        }

# ===================== å‘åå…¼å®¹å‡½æ•° =====================
def correction_single_group(*image_files, strictness_level="ä¸­ç­‰", api=default_api, group_index=1):
    """å¯¹å•ä¸ªæ–‡ä»¶ç»„è¿›è¡Œæ‰¹æ”¹"""
    try:
        prompt = prompts_module.get_complete_grading_prompt(file_info_list=[])
        return api(prompt, *image_files, system_message=prompts_module.get_core_grading_prompt())
    except Exception as e:
        error_msg = f"ç¬¬{group_index}é¢˜æ‰¹æ”¹å¤±è´¥"
        raise RuntimeError(f"{error_msg}: {str(e)}") from e

def efficient_correction_single(*image_files, strictness_level="ä¸­ç­‰", api=default_api):
    """é«˜æ•ˆç®€æ´æ‰¹æ”¹å‡½æ•°"""
    try:
        detailed_result = correction_single_group(*image_files, strictness_level=strictness_level, api=api)
        if len(detailed_result) > 500:
            prompt = f"""è¯·å°†ä»¥ä¸‹è¯¦ç»†æ‰¹æ”¹ç»“æœç®€åŒ–ä¸ºé«˜æ•ˆç®€æ´çš„æ ¼å¼ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ï¼š
{detailed_result}
è¦æ±‚ï¼š
1. ä¿ç•™é¢˜ç›®ç¼–å·å’Œå¾—åˆ†
2. ç®€è¦è¯´æ˜ä¸»è¦é”™è¯¯
3. ç»™å‡ºæ”¹è¿›å»ºè®®"""
            simplified = api(prompt, system_message=prompts_module.get_core_grading_prompt())
            return simplified
        return detailed_result
    except Exception as e:
        error_msg = "é«˜æ•ˆæ‰¹æ”¹å¤±è´¥"
        raise RuntimeError(f"{error_msg}: {str(e)}") from e

def batch_efficient_correction(*image_files, strictness_level="ä¸­ç­‰", api=default_api):
    """æ‰¹é‡é«˜æ•ˆæ‰¹æ”¹å‡½æ•°"""
    try:
        from datetime import datetime
        
        results = []
        total_files = len(image_files)
        
        for i, file in enumerate(image_files, 1):
            try:
                result = efficient_correction_single(file, 
                                                   strictness_level=strictness_level, 
                                                   api=api)
                
                file_name = getattr(file, 'name', f'æ–‡ä»¶{i}')
                header = f"## ğŸ“„ {file_name} ({i}/{total_files})\n\n"
                results.append(header + result)
                
            except Exception as e:
                error_msg = f"æ–‡ä»¶ {i} æ‰¹æ”¹å¤±è´¥: {str(e)}"
                results.append(f"## âŒ æ–‡ä»¶ {i}\n{error_msg}")
        
        final_result = "\n\n---\n\n".join(results)
        summary_header = f"\n\n# ğŸ“Š æ‰¹æ”¹æ€»è§ˆ\n**å…±æ‰¹æ”¹ {total_files} ä»½ä½œä¸š**\nâœ… æ‰¹æ”¹å®Œæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        
        return final_result + summary_header
        
    except Exception as e:
        error_msg = "æ‰¹é‡æ‰¹æ”¹å¤±è´¥"
        raise RuntimeError(f"{error_msg}: {str(e)}") from e

def generate_marking_scheme(*image_file, api=default_api):
    """ç”Ÿæˆè¯„åˆ†æ–¹æ¡ˆ"""
    try:
        prompt = "è¯·æ ¹æ®é¢˜ç›®ç”Ÿæˆè¯¦ç»†çš„è¯„åˆ†æ ‡å‡†ï¼ŒåŒ…æ‹¬æ¯ä¸ªæ­¥éª¤çš„åˆ†å€¼åˆ†é…ã€‚"
        result = api(prompt, *image_file, system_message=prompts_module.get_core_grading_prompt())
        return result
    except Exception as e:
        error_msg = "ç”Ÿæˆè¯„åˆ†æ–¹æ¡ˆå¤±è´¥"
        raise RuntimeError(f"{error_msg}: {str(e)}") from e

def correction_with_marking_scheme(marking_schemes, student_answers, strictness_level="ä¸­ç­‰", api=default_api):
    """ä½¿ç”¨è¯„åˆ†æ–¹æ¡ˆè¿›è¡Œæ‰¹æ”¹ï¼ˆå‘åå…¼å®¹ï¼‰"""
    try:
        if isinstance(marking_schemes, (tuple, list)):
            marking_schemes = list(marking_schemes)
        else:
            marking_schemes = [marking_schemes]
        
        if isinstance(student_answers, (tuple, list)):
            student_answers = list(student_answers)
        else:
            student_answers = [student_answers]
        
        result = batch_correction_with_standard(
            marking_schemes,
            student_answers,
            strictness_level=strictness_level,
            api=api
        )
        return result.get('correction_result', result)
    except Exception as e:
        error_msg = "æ‰¹æ”¹å¤±è´¥"
        raise RuntimeError(f"{error_msg}: {str(e)}") from e

def correction_without_marking_scheme(student_answer, strictness_level="ä¸­ç­‰", api=default_api):
    """ä¸ä½¿ç”¨è¯„åˆ†æ–¹æ¡ˆè¿›è¡Œæ‰¹æ”¹ï¼ˆå‘åå…¼å®¹ï¼‰"""
    try:
        if isinstance(student_answer, (tuple, list)):
            student_answer = list(student_answer)
        else:
            student_answer = [student_answer]
        
        result = batch_correction_without_standard(
            student_answer,
            student_answer,
            strictness_level=strictness_level,
            api=api
        )
        return result.get('correction_result', result)
    except Exception as e:
        error_msg = "æ‰¹æ”¹å¤±è´¥"
        raise RuntimeError(f"{error_msg}: {str(e)}") from e

# ===================== Webæ¥å£å‡½æ•° =====================
@safe_api_call
def web_correction_with_scheme(marking_scheme_files: List[str], student_answer_files: List[str], 
                              strictness_level: str = "ä¸­ç­‰") -> Dict[str, Any]:
    """ç½‘ç«™ç‰ˆæœ¬ï¼šä½¿ç”¨è¯„åˆ†æ–¹æ¡ˆè¿›è¡Œæ‰¹æ”¹"""
    result = batch_correction_with_standard(
        marking_scheme_files, 
        student_answer_files, 
        strictness_level=strictness_level, 
        api=default_api
    )
    return {
        "grading_result": result,
        "strictness_level": strictness_level,
        "scheme_files": len(marking_scheme_files),
        "answer_files": len(student_answer_files)
    }

@safe_api_call
def web_correction_without_scheme(student_answer_files: List[str], 
                                 strictness_level: str = "ä¸­ç­‰") -> Dict[str, Any]:
    """ç½‘ç«™ç‰ˆæœ¬ï¼šä¸ä½¿ç”¨è¯„åˆ†æ–¹æ¡ˆè¿›è¡Œæ‰¹æ”¹"""
    result = batch_correction_without_standard(
        student_answer_files,
        student_answer_files,
        strictness_level=strictness_level, 
        api=default_api
    )
    return {
        "grading_result": result,
        "strictness_level": strictness_level,
        "answer_files": len(student_answer_files)
    }

@safe_api_call
def web_batch_correction(batch_requests: List[Dict[str, Any]]) -> Dict[str, Any]:
    """ç½‘ç«™ç‰ˆæœ¬ï¼šæ‰¹é‡æ‰¹æ”¹å¤„ç†"""
    results = []
    total_requests = len(batch_requests)
    
    for i, request in enumerate(batch_requests):
        logger.info(f"å¤„ç†æ‰¹é‡è¯·æ±‚ {i + 1}/{total_requests}")
        
        try:
            if request.get("type") == "with_scheme":
                result = web_correction_with_scheme(
                    request["marking_scheme_files"],
                    request["student_answer_files"],
                    request.get("strictness_level", "ä¸­ç­‰")
                )
            elif request.get("type") == "without_scheme":
                result = web_correction_without_scheme(
                    request["student_answer_files"],
                    request.get("strictness_level", "ä¸­ç­‰")
                )
            else:
                result = GradingResult(success=False, error_message=f"æœªçŸ¥çš„è¯·æ±‚ç±»å‹: {request.get('type')}")
            
            results.append({
                "request_index": i,
                "request_id": request.get("id", f"batch_{i}"),
                "result": result.to_dict()
            })
            
        except Exception as e:
            logger.error(f"æ‰¹é‡è¯·æ±‚ {i + 1} å¤„ç†å¤±è´¥: {str(e)}")
            results.append({
                "request_index": i,
                "request_id": request.get("id", f"batch_{i}"),
                "result": GradingResult(success=False, error_message=str(e)).to_dict()
            })
    
    success_count = sum(1 for r in results if r["result"]["success"])
    
    return {
        "total_requests": total_requests,
        "success_count": success_count,
        "failure_count": total_requests - success_count,
        "results": results
    }

# ===================== APIé…ç½®å‡½æ•° =====================
def get_api_status() -> Dict[str, Any]:
    """è·å–APIçŠ¶æ€ä¿¡æ¯"""
    return {
        "api_config": api_config.get_status(),
        "status": "ready",
        "timestamp": time.time()
    }

def update_api_config(new_config: Dict[str, Any]) -> Dict[str, Any]:
    """æ›´æ–°APIé…ç½®"""
    try:
        if "api_key" in new_config:
            api_config.api_key = new_config["api_key"]
        if "base_url" in new_config:
            api_config.base_url = new_config["base_url"]
        if "model" in new_config:
            api_config.model = new_config["model"]
        if "max_tokens" in new_config:
            api_config.max_tokens = new_config["max_tokens"]
        if "temperature" in new_config:
            api_config.temperature = new_config["temperature"]
        if "max_retries" in new_config:
            api_config.max_retries = new_config["max_retries"]
        if "retry_delay" in new_config:
            api_config.retry_delay = new_config["retry_delay"]
        
        logger.info("APIé…ç½®æ›´æ–°æˆåŠŸ")
        return {"success": True, "message": "é…ç½®æ›´æ–°æˆåŠŸ", "updated_config": new_config}
    except Exception as e:
        error_msg = f"é…ç½®æ›´æ–°å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        return {"success": False, "error": error_msg}

# ===================== å¢å¼ºç‰ˆæ‰¹æ”¹å‡½æ•° =====================
def detect_loop_and_cleanup(result):
    """æ™ºèƒ½é‡å¤å†…å®¹æ£€æµ‹å’Œæ¸…ç† - é‡æ–°è®¾è®¡ç‰ˆ"""
    if not result:
        return result
    
    lines = result.split('\n')
    cleaned_lines = []
    seen_patterns = set()  # ç”¨äºæ£€æµ‹é‡å¤æ¨¡å¼
    recent_lines = []  # æœ€è¿‘çš„10è¡Œï¼Œç”¨äºæ£€æµ‹ç«‹å³é‡å¤
    
    # è®¡ç®—è¡Œçš„ç®€åŒ–ç‰¹å¾ï¼ˆç”¨äºé‡å¤æ£€æµ‹ï¼‰
    def get_line_signature(line):
        # ç§»é™¤å˜åŒ–çš„éƒ¨åˆ†ï¼ˆæ•°å­—ã€ç¬¦å·ï¼‰ï¼Œåªä¿ç•™ç»“æ„
        import re
        simplified = re.sub(r'[0-9\+\-\*\/\=\(\)\[\]]+', 'X', line.strip())
        simplified = re.sub(r'[Î±Î²Î³Î´ÎµÎ¶Î·Î¸Î¹Ï€Ã—Ã·Â±â‰¤â‰¥â‰ â‰ˆ]+', 'Y', simplified)
        return simplified
    
    for line in lines:
        line = line.strip()
        if not line:
            cleaned_lines.append("")
            continue
            
        # è·å–è¡Œçš„ç‰¹å¾ç­¾å
        signature = get_line_signature(line)
        
        # æ£€æµ‹ç«‹å³é‡å¤ï¼ˆè¿ç»­ç›¸åŒè¡Œï¼‰
        if line in recent_lines[-5:]:  # æ£€æŸ¥æœ€è¿‘5è¡Œ
            print(f"âš ï¸ æ£€æµ‹åˆ°ç«‹å³é‡å¤ï¼Œè·³è¿‡: {line[:50]}...")
            continue
            
        # æ£€æµ‹æ¨¡å¼é‡å¤ï¼ˆç›¸åŒç»“æ„çš„è¡Œå‡ºç°è¿‡å¤šæ¬¡ï¼‰
        if signature in seen_patterns and len(signature) > 10:  # å¿½ç•¥å¤ªçŸ­çš„æ¨¡å¼
            pattern_count = sum(1 for existing_sig in seen_patterns if existing_sig == signature)
            if pattern_count > 3:  # åŒæ ·çš„æ¨¡å¼è¶…è¿‡3æ¬¡
                print(f"âš ï¸ æ£€æµ‹åˆ°æ¨¡å¼é‡å¤ï¼Œè·³è¿‡: {signature[:30]}...")
                continue
                
        # æ£€æµ‹å¤§æ®µé‡å¤ï¼ˆæ•´ä¸ªè®¡ç®—è¿‡ç¨‹é‡å¤ï¼‰
        if ('çš„ä½“ç§¯' in line or 'çš„åŠå¾„' in line) and any(similar_content in prev for prev in cleaned_lines[-20:] for similar_content in ['çš„ä½“ç§¯', 'çš„åŠå¾„']):
            # è®¡ç®—æœ€è¿‘20è¡Œä¸­æ•°å­¦è®¡ç®—çš„å¯†åº¦
            math_density = sum(1 for prev in cleaned_lines[-20:] if ('çš„ä½“ç§¯' in prev or 'çš„åŠå¾„' in prev or '=' in prev))
            if math_density > 15:  # å¦‚æœæ•°å­¦è®¡ç®—è¿‡äºå¯†é›†
                print("âš ï¸ æ£€æµ‹åˆ°å¤§æ®µè®¡ç®—é‡å¤ï¼Œç»ˆæ­¢å¤„ç†")
                break
            
        # æ£€æµ‹æ•°å­¦å…¬å¼çš„è¿‡åº¦é‡å¤
        if ('ä½“ç§¯' in line or 'åŠå¾„' in line) and line.count('=') > 0:
            similar_count = sum(1 for prev in cleaned_lines[-50:] 
                              if ('ä½“ç§¯' in prev or 'åŠå¾„' in prev) and prev.count('=') > 0)
            if similar_count > 10:  # æ•°å­¦å…¬å¼è¡Œè¶…è¿‡10è¡Œ
                print("âš ï¸ æ£€æµ‹åˆ°æ•°å­¦å…¬å¼è¿‡åº¦é‡å¤ï¼Œåœæ­¢æ·»åŠ ")
                break
        
        # è®°å½•æ¨¡å¼å’Œæœ€è¿‘è¡Œ
        seen_patterns.add(signature)
        recent_lines.append(line)
        if len(recent_lines) > 10:
            recent_lines.pop(0)
            
            cleaned_lines.append(line)
    
        # å®‰å…¨æˆªæ–­ï¼šé˜²æ­¢è¾“å‡ºè¿‡é•¿
        if len(cleaned_lines) > 200:
            cleaned_lines.append("ğŸ›‘ å†…å®¹è¿‡é•¿ï¼Œå·²è‡ªåŠ¨æˆªæ–­")
            break
    
    print(f"âœ… å¾ªç¯æ¸…ç†å®Œæˆ: {len(lines)} â†’ {len(cleaned_lines)} è¡Œ")
    return '\n'.join(cleaned_lines)

def check_question_exists(content, question_number):
    """æ£€æŸ¥é¢˜ç›®æ˜¯å¦å­˜åœ¨äºå­¦ç”Ÿç­”æ¡ˆä¸­"""
    if not content:
        return False
    
    content_str = str(content).strip()
    if not content_str:
        return False
    
    import re
    
    # æ£€æŸ¥å¤šç§é¢˜ç›®æ ‡è¯†æ ¼å¼ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç²¾ç¡®åŒ¹é…
    patterns = [
        rf"é¢˜ç›®\s*{question_number}(?:\s|ï¼š|:|$)",
        rf"ç¬¬\s*{question_number}\s*é¢˜",
        rf"Q\s*{question_number}(?:\s|\.|\)|:|$)",
        rf"Q\.\s*{question_number}(?:\s|\.|\)|:|$)", 
        rf"é—®é¢˜\s*{question_number}(?:\s|ï¼š|:|$)",
        rf"^\s*{question_number}\s*[\.\)ï¼‰]",  # å¼€å¤´æ˜¯æ•°å­—åŠ ç‚¹æˆ–æ‹¬å·
        rf"\(\s*{question_number}\s*\)",     # (1)æ ¼å¼
        rf"\[\s*{question_number}\s*\]"      # [1]æ ¼å¼
    ]
    
    # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä¸€æ¨¡å¼
    for pattern in patterns:
        if re.search(pattern, content_str, re.IGNORECASE):
            return True
    
    return False

def generate_summary_with_api(grading_results):
    """ä½¿ç”¨é¢å¤–APIè°ƒç”¨ç”Ÿæˆæ€»ç»“"""
    try:
        from .prompts_simplified import get_summary_generation_prompt
        
        # åˆ†ææ‰¹æ”¹ç»“æœ
        total_questions = 0
        answered_questions = 0
        total_score = 0
        total_possible = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        for result in grading_results:
            if not result:
                continue
                
            lines = result.split('\n')
            for line in lines:
                if line.startswith('### é¢˜ç›®'):
                    total_questions += 1
                elif '**çŠ¶æ€**ï¼šæœªä½œç­”' in line:
                    # æœªä½œç­”é¢˜ç›®ä¸è®¡å…¥åˆ†æ•°
                    continue
                elif '**å¾—åˆ†**ï¼š' in line and '**æ»¡åˆ†**ï¼š' in lines[lines.index(line)-1]:
                    # æå–å¾—åˆ†ä¿¡æ¯
                    try:
                        score_line = line
                        full_line = lines[lines.index(line)-1]
                        
                        # è§£æå¾—åˆ†
                        if '/' in score_line:
                            parts = score_line.split('/')
                            if len(parts) >= 2:
                                current_score = float(parts[0].split('ï¼š')[1].strip())
                                total_score += current_score
                                answered_questions += 1
                        
                        # è§£ææ»¡åˆ†
                        if 'ï¼š' in full_line:
                            full_score = full_line.split('ï¼š')[1].split('åˆ†')[0].strip()
                            total_possible += float(full_score)
                    except:
                        pass
        
        # æ„å»ºæ€»ç»“æç¤º
        summary_prompt = f"""{get_summary_generation_prompt()}

ã€æ‰¹æ”¹æ•°æ®ã€‘
- æ€»é¢˜ç›®æ•°ï¼š{total_questions}
- å·²ä½œç­”é¢˜ç›®ï¼š{answered_questions}
- æœªä½œç­”é¢˜ç›®ï¼š{total_questions - answered_questions}
- å®é™…å¾—åˆ†ï¼š{total_score}
- æ€»å¯èƒ½åˆ†æ•°ï¼š{total_possible}

ã€æ‰¹æ”¹ç»“æœã€‘
{chr(10).join(grading_results)}

è¯·åŸºäºä»¥ä¸Šæ•°æ®ç”Ÿæˆç®€æ´æ€»ç»“ï¼š"""
        
        # è°ƒç”¨APIç”Ÿæˆæ€»ç»“ï¼ˆä¸ä½¿ç”¨åˆ†æ‰¹ï¼‰
        logger.info("ğŸ“Š å¼€å§‹ç”Ÿæˆæ‰¹æ”¹æ€»ç»“...")
        logger.info(f"æ‰¹æ”¹ç»Ÿè®¡æ•°æ®: æ€»é¢˜ç›®{total_questions}, å·²ç­”{answered_questions}, å¾—åˆ†{total_score}/{total_possible}")
        
        summary = call_tongyiqianwen_api(summary_prompt, "")
        
        if summary:
            logger.info("ğŸ“Š æ€»ç»“ç”ŸæˆæˆåŠŸ")
            logger.info(f"æ€»ç»“å†…å®¹é•¿åº¦: {len(summary)} å­—ç¬¦")
        else:
            logger.warning("ğŸ“Š æ€»ç»“ç”Ÿæˆå¤±è´¥")
            
        return summary if summary else "ğŸ“Š æ€»ç»“ç”Ÿæˆå¤±è´¥"
        
    except Exception as e:
        print(f"ç”Ÿæˆæ€»ç»“å¤±è´¥: {e}")
        return "ğŸ“Š æ€»ç»“ç”Ÿæˆå‡ºé”™"

def analyze_questions(content_list, file_info_list=None):
    """åˆ†æé¢˜ç›®æ•°é‡å’Œåˆ†å€¼ - å¢å¼ºç‰ˆ"""
    try:
        # ç›´æ¥ä½¿ç”¨é¢˜ç›®åˆ†ææç¤ºè¯ï¼Œé¿å…å¯¼å…¥é—®é¢˜
        analysis_prompt = """ğŸ“Š é¢˜ç›®åˆ†æä»»åŠ¡

è¯·ä»”ç»†åˆ†ææä¾›çš„æ–‡ä»¶ï¼Œè¯†åˆ«ï¼š
1. æ€»å…±æœ‰å¤šå°‘é“é¢˜ç›®ï¼ˆåŒ…æ‹¬æ‰€æœ‰å­é¢˜ï¼Œå¦‚ (a), (b), (c) ç­‰ï¼‰
2. æ¯é“é¢˜çš„åˆ†å€¼
3. æ€»åˆ†æ˜¯å¤šå°‘

ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘
é¢˜ç›®æ€»æ•°ï¼šXé¢˜
é¢˜ç›®åˆ—è¡¨ï¼š
- é¢˜ç›®1ï¼šYåˆ†
- é¢˜ç›®2ï¼šZåˆ†
...
æ€»åˆ†ï¼šWåˆ†

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºï¼Œä¸è¦è¿›è¡Œæ‰¹æ”¹ã€‚"""
        
        # è¯»å–æ‰€æœ‰æ–‡ä»¶å†…å®¹ï¼Œä½†ä¿ç•™æ–‡ä»¶è·¯å¾„ä¿¡æ¯
        all_contents = []
        file_paths = []
        text_contents = []
        
        for file_path in content_list:
            try:
                content_type, content = process_file_content(file_path)
                if content:
                    # å¯¹äºå›¾ç‰‡å’ŒPDFï¼Œä¿å­˜æ–‡ä»¶è·¯å¾„
                    if content_type in ['image', 'pdf']:
                        all_contents.append(f"[æ–‡ä»¶: {os.path.basename(file_path)}]")
                        file_paths.append(file_path)
                    else:
                        all_contents.append(content)
                        file_paths.append(None)
                        text_contents.append(content)
            except Exception as e:
                print(f"âš ï¸ è¯»å–æ–‡ä»¶å‡ºé”™ {file_path}: {e}")
        
        if not all_contents:
            print("âŒ æ²¡æœ‰å¯è¯»å–çš„æ–‡ä»¶å†…å®¹")
            return None
        
        # é¦–å…ˆå°è¯•ä»æ–‡æœ¬å†…å®¹ä¸­ç›´æ¥è¯†åˆ«é¢˜ç›®ï¼ˆå¿«é€Ÿè¯†åˆ«ï¼‰
        total_questions = 0
        total_score = 0
        
        for content in text_contents:
            if content:
                # è¯†åˆ«é¢˜ç›®æ¨¡å¼
                import re
                # è¯†åˆ«é¢˜ç›®ç¼–å·æ¨¡å¼: "é¢˜ç›®1", "1.", "é¢˜1", "ç¬¬1é¢˜", "(1)", "Question 1" ç­‰
                question_patterns = [
                    r'é¢˜ç›®\s*(\d+)',  # é¢˜ç›®1, é¢˜ç›®2
                    r'ç¬¬\s*(\d+)\s*é¢˜',  # ç¬¬1é¢˜, ç¬¬2é¢˜
                    r'^\s*(\d+)[\.\)]\s*',  # 1. 2. æˆ– 1) 2)
                    r'é¢˜\s*(\d+)',  # é¢˜1, é¢˜2
                    r'\(\s*(\d+)\s*\)',  # (1), (2)
                    r'Question\s+(\d+)',  # Question 1, Question 2
                ]
                
                question_numbers = set()
                for pattern in question_patterns:
                    matches = re.findall(pattern, content, re.MULTILINE | re.IGNORECASE)
                    for match in matches:
                        try:
                            question_numbers.add(int(match))
                        except:
                            continue
                
                if question_numbers:
                    max_question = max(question_numbers)
                    total_questions = max(total_questions, max_question)
                
                # è¯†åˆ«åˆ†å€¼æ¨¡å¼
                score_patterns = [
                    r'(\d+)\s*åˆ†',  # 3åˆ†, 5åˆ†
                    r'(\d+)\s*marks?',  # 3 marks, 5 mark
                    r'(\d+)\s*pts?',  # 3 pts, 5 pt
                    r'\[\s*(\d+)\s*M',  # [3M], [5M]
                    r'æ»¡åˆ†[ï¼š:]\s*(\d+)',  # æ»¡åˆ†ï¼š10
                    r'æ€»åˆ†[ï¼š:]\s*(\d+)',  # æ€»åˆ†ï¼š20
                ]
                
                scores = []
                for pattern in score_patterns:
                    matches = re.findall(pattern, content, re.IGNORECASE)
                    for match in matches:
                        try:
                            scores.append(int(match))
                        except:
                            continue
                
                if scores:
                    # å¦‚æœæ‰¾åˆ°æ€»åˆ†æ ‡è®°ï¼Œä½¿ç”¨æœ€å¤§çš„ï¼›å¦åˆ™ç´¯åŠ æ‰€æœ‰åˆ†å€¼
                    if any('æ€»åˆ†' in content for pattern in score_patterns if re.search(pattern, content)):
                        total_score = max(total_score, max(scores))
                    else:
                        total_score = max(total_score, sum(scores))
        
        # å¦‚æœå¿«é€Ÿè¯†åˆ«æˆåŠŸï¼Œç›´æ¥è¿”å›ç»“æœ
        if total_questions > 0:
            print(f"ğŸ“Š å¿«é€Ÿè¯†åˆ«æˆåŠŸï¼šå…±{total_questions}é¢˜ï¼Œæ€»åˆ†{total_score}åˆ†")
            return {
                'total_questions': total_questions,
                'total_score': total_score,
                'analysis': f"å¿«é€Ÿè¯†åˆ«ï¼šé¢˜ç›®æ€»æ•°ï¼š{total_questions}é¢˜ï¼Œæ€»åˆ†ï¼š{total_score}åˆ†"
            }
        
        # å¦‚æœå¿«é€Ÿè¯†åˆ«å¤±è´¥ï¼Œè°ƒç”¨APIè¿›è¡Œæ™ºèƒ½åˆ†æ
        print("ğŸ¤– ä½¿ç”¨AIè¿›è¡Œé¢˜ç›®åˆ†æ...")
        
        # æ„å»ºAPIå‚æ•°
        api_args = [analysis_prompt]
        for i, file_path in enumerate(content_list):
            if file_paths[i]:  # å¦‚æœæ˜¯å›¾ç‰‡æˆ–PDFæ–‡ä»¶
                api_args.append(file_paths[i])
            else:  # å¦‚æœæ˜¯æ–‡æœ¬å†…å®¹
                api_args.append(all_contents[i])
        
        result = call_tongyiqianwen_api(*api_args)
        
        if result and "APIé…ç½®é”™è¯¯" not in result and "è®¤è¯å¤±è´¥" not in result:
            print(f"APIåˆ†æç»“æœ: {result[:200]}...")
            
            # è§£æç»“æœ - ä½¿ç”¨æ›´çµæ´»çš„æ­£åˆ™è¡¨è¾¾å¼
            import re
            
            # æå–é¢˜ç›®æ€»æ•° - æ”¯æŒå¤šç§æ ¼å¼
            total_patterns = [
                r'é¢˜ç›®æ€»æ•°[ï¼š:]\s*(\d+)',
                r'æ€»å…±[ï¼š:]\s*(\d+)\s*é¢˜',
                r'å…±[ï¼š:]\s*(\d+)\s*é¢˜',
                r'(\d+)\s*é¢˜',
                r'æ€»é¢˜æ•°[ï¼š:]\s*(\d+)',
            ]
            
            total_questions = 0
            for pattern in total_patterns:
                match = re.search(pattern, result)
                if match:
                    total_questions = int(match.group(1))
                    break
            
            # æå–æ€»åˆ† - æ”¯æŒå¤šç§æ ¼å¼
            score_patterns = [
                r'æ€»åˆ†[ï¼š:]\s*(\d+)',
                r'æ€»å…±[ï¼š:]\s*(\d+)\s*åˆ†',
                r'å…±[ï¼š:]\s*(\d+)\s*åˆ†',
                r'(\d+)\s*åˆ†\s*$',
            ]
            
            total_score = 0
            for pattern in score_patterns:
                match = re.search(pattern, result)
                if match:
                    total_score = int(match.group(1))
                    break
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰è¯†åˆ«åˆ°ï¼Œå°è¯•ä»é¢˜ç›®åˆ—è¡¨ä¸­è®¡ç®—
            if total_questions == 0 or total_score == 0:
                question_list_matches = re.findall(r'-\s*é¢˜ç›®\d+[ï¼š:]\s*(\d+)\s*åˆ†', result)
                if question_list_matches:
                    if total_questions == 0:
                        total_questions = len(question_list_matches)
                    if total_score == 0:
                        total_score = sum(int(score) for score in question_list_matches)
            
            print(f"ğŸ“Š AIè¯†åˆ«ç»“æœï¼šå…±{total_questions}é¢˜ï¼Œæ€»åˆ†{total_score}åˆ†")
            return {
                'total_questions': total_questions,
                'total_score': total_score,
                'analysis': result
            }
        else:
            print("âš ï¸ APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return {
                'total_questions': 1,  # é»˜è®¤è‡³å°‘æœ‰1é¢˜
                'total_score': 10,     # é»˜è®¤æ€»åˆ†10åˆ†
                'analysis': "APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®"
            }
        
    except Exception as e:
        print(f"é¢˜ç›®åˆ†æå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        # è¿”å›é»˜è®¤å€¼è€Œä¸æ˜¯Noneï¼Œç¡®ä¿æ‰¹æ”¹æµç¨‹èƒ½ç»§ç»­
        return {
            'total_questions': 1,
            'total_score': 10,
            'analysis': f"åˆ†æå‡ºé”™: {e}"
        }

def quick_analyze_files(content_list, file_paths, file_info_list=None):
    """
    è½»é‡çº§æ–‡ä»¶åˆ†æ - ç¬¬ä¸€æ¬¡APIè°ƒç”¨
    åªè¯†åˆ«é¢˜ç›®æ•°é‡ã€å­¦ç”Ÿä¿¡æ¯ç­‰åŸºæœ¬ä¿¡æ¯ï¼Œä¸è¾“å‡ºè¯¦ç»†å†…å®¹
    """
    try:
        logger.info("ğŸ” å¼€å§‹è½»é‡çº§æ–‡ä»¶åˆ†æ...")
        
        # æ„å»ºç®€æ´çš„åˆ†ææç¤ºè¯
        analysis_prompt = """ä½ æ˜¯ä¸€ä¸ªæ–‡ä»¶åˆ†æåŠ©æ‰‹ã€‚è¯·åˆ†ææä¾›çš„æ–‡ä»¶ï¼Œä½†åªè¾“å‡ºä»¥ä¸‹ä¿¡æ¯ï¼š

ã€é‡è¦ã€‘ï¼šä½ çš„ä»»åŠ¡æ˜¯åˆ†æè¯†åˆ«ï¼Œä¸æ˜¯æ‰¹æ”¹ä½œä¸šï¼Œæ‰€ä»¥ä¸è¦è¾“å‡ºä»»ä½•é¢˜ç›®çš„è¯¦ç»†å†…å®¹æˆ–ç­”æ¡ˆã€‚

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

## ğŸ“Š æ–‡ä»¶åˆ†æç»“æœ

### é¢˜ç›®æ•°é‡
æ€»é¢˜ç›®æ•°ï¼š[æ•°å­—]

### å­¦ç”Ÿä¿¡æ¯
å­¦ç”Ÿå§“å/IDï¼š[ä»æ–‡ä»¶åæˆ–å†…å®¹ä¸­è¯†åˆ«ï¼Œå¦‚æœæœ‰å¤šä¸ªå­¦ç”Ÿè¯·åˆ—å‡º]
ç­çº§ä¿¡æ¯ï¼š[ä»æ–‡ä»¶åã€ç›®å½•åæˆ–å†…å®¹ä¸­è¯†åˆ«ç­çº§ä¿¡æ¯]
å­¦ç”Ÿæ•°é‡ï¼š[å¦‚æœæ˜¯å¤šä¸ªå­¦ç”Ÿçš„ä½œä¸š]

### æ–‡ä»¶ç±»å‹
- é¢˜ç›®æ–‡ä»¶ï¼š[æ•°é‡]ä¸ª
- ç­”æ¡ˆæ–‡ä»¶ï¼š[æ•°é‡]ä¸ª  
- æ‰¹æ”¹æ ‡å‡†ï¼š[æ•°é‡]ä¸ª

### åˆ†ææ€»ç»“
[ç®€çŸ­æ€»ç»“ï¼šè¿™æ‰¹æ–‡ä»¶åŒ…å«ä»€ä¹ˆå†…å®¹ï¼Œé¢„è®¡æ‰¹æ”¹æ—¶é—´ç­‰]

ã€ä¸¥æ ¼è¦æ±‚ã€‘ï¼š
1. ä¸è¦è¾“å‡ºä»»ä½•é¢˜ç›®çš„å…·ä½“å†…å®¹
2. ä¸è¦è¾“å‡ºä»»ä½•ç­”æ¡ˆæˆ–è§£é¢˜è¿‡ç¨‹
3. åªè¾“å‡ºæ–‡ä»¶çš„åŸºæœ¬ä¿¡æ¯å’Œç»“æ„åˆ†æ
4. è¾“å‡ºè¦ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡200å­—"""

        # å‡†å¤‡APIå‚æ•°
        api_args = [analysis_prompt]
        
        # æ·»åŠ æ–‡ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨å‰å‡ ä¸ªæ–‡ä»¶è¿›è¡Œå¿«é€Ÿåˆ†æï¼‰
        files_to_analyze = min(3, len(content_list))  # æœ€å¤šåˆ†æå‰3ä¸ªæ–‡ä»¶
        for i in range(files_to_analyze):
            if i < len(file_paths) and file_paths[i]:
                api_args.append(file_paths[i])
                logger.info(f"æ·»åŠ åˆ†ææ–‡ä»¶: {os.path.basename(file_paths[i])}")
        
        logger.info(f"æ‰§è¡Œè½»é‡çº§åˆ†æ - åˆ†ææ–‡ä»¶æ•°: {files_to_analyze}")
        analysis_result = call_tongyiqianwen_api(*api_args)
        
        if analysis_result:
            logger.info("âœ… æ–‡ä»¶åˆ†æå®Œæˆ")
            logger.info(f"åˆ†æç»“æœé•¿åº¦: {len(analysis_result)} å­—ç¬¦")
            
            # æå–å…³é”®ä¿¡æ¯
            import re
            total_questions_match = re.search(r'æ€»é¢˜ç›®æ•°[ï¼š:]\s*(\d+)', analysis_result)
            student_info_match = re.search(r'å­¦ç”Ÿå§“å/ID[ï¼š:]\s*([^\n]+)', analysis_result)
            class_info_match = re.search(r'ç­çº§ä¿¡æ¯[ï¼š:]\s*([^\n]+)', analysis_result)
            student_count_match = re.search(r'å­¦ç”Ÿæ•°é‡[ï¼š:]\s*([^\n]+)', analysis_result)
            
            extracted_info = {
                'total_questions': int(total_questions_match.group(1)) if total_questions_match else 0,
                'student_info': student_info_match.group(1).strip() if student_info_match else "æœªè¯†åˆ«",
                'class_info': class_info_match.group(1).strip() if class_info_match else "æœªè¯†åˆ«",
                'student_count': student_count_match.group(1).strip() if student_count_match else "1",
                'analysis_text': analysis_result,
                'files_analyzed': files_to_analyze
            }
            
            logger.info(f"æå–ä¿¡æ¯: é¢˜ç›®æ•°={extracted_info['total_questions']}, å­¦ç”Ÿ={extracted_info['student_info']}, ç­çº§={extracted_info['class_info']}")
            return extracted_info
        else:
            logger.warning("âš ï¸ æ–‡ä»¶åˆ†æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä¿¡æ¯")
            return {
                'total_questions': len(content_list),
                'student_info': "æœªè¯†åˆ«",
                'class_info': "æœªè¯†åˆ«",
                'student_count': "1",
                'analysis_text': "åˆ†æå¤±è´¥",
                'files_analyzed': 0
            }
            
    except Exception as e:
        logger.error(f"âŒ æ–‡ä»¶åˆ†æå‡ºé”™: {e}")
        return {
            'total_questions': len(content_list),
            'student_info': "åˆ†æå‡ºé”™",
            'class_info': "åˆ†æå‡ºé”™",
            'student_count': "1",
            'analysis_text': f"åˆ†æå‡ºé”™: {e}",
            'files_analyzed': 0
        }

def enhanced_batch_correction_with_standard(content_list, file_info_list=None, batch_size=10, generate_summary=True):
    """å¢å¼ºç‰ˆåˆ†æ‰¹æ‰¹æ”¹ï¼ˆæœ‰æ ‡å‡†ç­”æ¡ˆï¼‰- è¶…çº§ä¸¥æ ¼ç‰ˆ"""
    try:
        logger.info("ğŸš€ å¼€å§‹å¢å¼ºç‰ˆæ‰¹æ”¹ï¼ˆæœ‰æ ‡å‡†ç­”æ¡ˆï¼‰")
        logger.info(f"è¾“å…¥æ–‡ä»¶æ•°é‡: {len(content_list)}")
        logger.info(f"ç”Ÿæˆæ€»ç»“: {generate_summary}")
        
        from .prompts_simplified import get_core_grading_prompt, get_batch_processing_prompt
        
        # é¦–å…ˆè¯»å–æ‰€æœ‰æ–‡ä»¶å†…å®¹ï¼Œä½†ä¿ç•™æ–‡ä»¶è·¯å¾„ä¿¡æ¯
        all_contents = []
        file_paths = []  # ä¿å­˜åŸå§‹æ–‡ä»¶è·¯å¾„
        for i, file_path in enumerate(content_list):
            try:
                logger.info(f"å¤„ç†æ–‡ä»¶ {i+1}/{len(content_list)}: {os.path.basename(file_path)}")
                content_type, content = process_file_content(file_path)
                
                # æ£€æŸ¥æ˜¯å¦å¤„ç†æˆåŠŸ
                if content_type == 'error':
                    logger.warning(f"âš ï¸ æ–‡ä»¶å¤„ç†å¤±è´¥ï¼š{file_path} - {content}")
                    continue
                
                if content and content_type != 'error':
                    # å¯¹äºå›¾ç‰‡å’ŒPDFï¼Œä¿å­˜æ–‡ä»¶è·¯å¾„è€Œä¸æ˜¯å†…å®¹
                    if content_type in ['image', 'pdf']:
                        all_contents.append(f"[æ–‡ä»¶: {os.path.basename(file_path)}]")
                        file_paths.append(file_path)
                        logger.info(f"æ–‡ä»¶å¤„ç†æˆåŠŸ: {os.path.basename(file_path)} (ç±»å‹: {content_type})")
                    else:
                        all_contents.append(content)
                        file_paths.append(None)  # æ–‡æœ¬å†…å®¹ä¸éœ€è¦æ–‡ä»¶è·¯å¾„
                        logger.info(f"æ–‡ä»¶å¤„ç†æˆåŠŸ: {os.path.basename(file_path)} (ç±»å‹: {content_type}, é•¿åº¦: {len(content)} å­—ç¬¦)")
                else:
                    logger.warning(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶ï¼š{file_path}")
            except Exception as e:
                logger.error(f"âš ï¸ è¯»å–æ–‡ä»¶å‡ºé”™ {file_path}: {e}")
        
        if not all_contents:
            logger.error("âŒ æ²¡æœ‰å¯å¤„ç†çš„æ–‡ä»¶å†…å®¹")
            logger.error(f"è°ƒè¯•ä¿¡æ¯ï¼š")
            logger.error(f"- è¾“å…¥æ–‡ä»¶æ•°é‡: {len(content_list)}")
            logger.error(f"- æ–‡ä»¶åˆ—è¡¨: {[os.path.basename(f) if isinstance(f, str) and os.path.exists(f) else str(f) for f in content_list]}")
            logger.error(f"- å¤„ç†ç»“æœåˆ—è¡¨é•¿åº¦: {len(all_contents)}")
            logger.error(f"- æ–‡ä»¶è·¯å¾„åˆ—è¡¨é•¿åº¦: {len(file_paths)}")
            
            # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            return {
                'text': "âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ï¼šæ²¡æœ‰å¯å¤„ç†çš„æ–‡ä»¶å†…å®¹ã€‚è¯·æ£€æŸ¥ï¼š\n1. æ–‡ä»¶æ˜¯å¦æ­£ç¡®ä¸Šä¼ \n2. æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ\n3. æ–‡ä»¶æ˜¯å¦æŸå",
                'html': "<div style='color: red;'>âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ï¼šæ²¡æœ‰å¯å¤„ç†çš„æ–‡ä»¶å†…å®¹ã€‚è¯·æ£€æŸ¥ï¼š<br>1. æ–‡ä»¶æ˜¯å¦æ­£ç¡®ä¸Šä¼ <br>2. æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ<br>3. æ–‡ä»¶æ˜¯å¦æŸå</div>",
                'format': 'error'
            }
        
        logger.info(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(all_contents)} ä¸ªæ–‡ä»¶")
        
        # åˆå¹¶æ‰€æœ‰å†…å®¹ï¼ˆä»…ç”¨äºæ˜¾ç¤ºï¼‰
        combined_contents = []
        for content in all_contents:
            if isinstance(content, tuple) and len(content) == 2:
                # å¦‚æœæ˜¯å…ƒç»„ï¼Œå–ç¬¬äºŒä¸ªå…ƒç´ ï¼ˆå†…å®¹ï¼‰
                combined_contents.append(str(content[1]))
            else:
                combined_contents.append(str(content))
        combined_content = "\n\n".join(combined_contents)
        
        # ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«é¢˜ç›®æ•°é‡å’Œå­¦ç”Ÿä¿¡æ¯ï¼ˆè½»é‡çº§APIè°ƒç”¨ï¼‰
        logger.info("ğŸ” ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«é¢˜ç›®æ•°é‡å’Œå­¦ç”Ÿä¿¡æ¯...")
        analysis_result = quick_analyze_files(content_list, file_paths, file_info_list)
        
        logger.info("ğŸ“ ç¬¬äºŒæ­¥ï¼šå¼€å§‹æ„å»ºæ‰¹æ”¹æç¤ºè¯...")
        prompt = get_core_grading_prompt(file_info_list, analysis_result)
        
        if file_info_list:
            marking_content = extract_marking_content(file_info_list)
            if marking_content:
                prompt = f"{prompt}\n\næ‰¹æ”¹æ ‡å‡†ï¼š\n{marking_content}"
                logger.info(f"å·²æ·»åŠ æ‰¹æ”¹æ ‡å‡†ï¼Œé•¿åº¦: {len(marking_content)} å­—ç¬¦")
        
        # è°ƒç”¨API - ä¼ é€’æ–‡ä»¶è·¯å¾„è€Œä¸æ˜¯æ–‡æœ¬å†…å®¹
        api_args = [prompt]
        for i, file_path in enumerate(content_list):
            if file_paths[i]:  # å¦‚æœæ˜¯å›¾ç‰‡æˆ–PDFæ–‡ä»¶
                api_args.append(file_paths[i])
                logger.info(f"æ·»åŠ APIå‚æ•°: æ–‡ä»¶è·¯å¾„ {os.path.basename(file_paths[i])}")
            else:  # å¦‚æœæ˜¯æ–‡æœ¬å†…å®¹
                api_args.append(all_contents[i])
                logger.info(f"æ·»åŠ APIå‚æ•°: æ–‡æœ¬å†…å®¹ (é•¿åº¦: {len(all_contents[i])} å­—ç¬¦)")
        
        logger.info(f"è°ƒç”¨API - æ€»å‚æ•°æ•°é‡: {len(api_args)}")
        result = call_tongyiqianwen_api(*api_args)
        
        if result:
            logger.info("ğŸ¯ APIè°ƒç”¨æˆåŠŸï¼Œå¼€å§‹ç»“æœå¤„ç†æµç¨‹")
            logger.info(f"åŸå§‹ç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
            
            # 1. å¼ºåˆ¶æ•°å­¦ç¬¦å·è½¬æ¢ï¼ˆå®Œå…¨é‡å¡‘ç‰ˆï¼‰
            logger.info("1. æ‰§è¡Œæ•°å­¦ç¬¦å·è½¬æ¢...")
            result = convert_latex_to_unicode(result)
            
            # 2. ç»ˆæå¾ªç¯æ£€æµ‹å’Œæ¸…ç†
            logger.info("2. æ‰§è¡Œå¾ªç¯æ£€æµ‹å’Œæ¸…ç†...")
            result = detect_loop_and_cleanup(result)
            
            # 3. ç§»é™¤ä»»ä½•æ€»ç»“å†…å®¹
            logger.info("3. ç§»é™¤æ€»ç»“å†…å®¹...")
            result = remove_summary_from_batch(result)
            
            # 4. å¼ºåˆ¶æ ¼å¼ä¿®æ­£
            logger.info("4. æ‰§è¡Œæ ¼å¼ä¿®æ­£...")
            result = enforce_strict_format(result)
            
            # 5. æ¸…ç†æ··ä¹±è¾“å‡ºï¼ˆç§»é™¤é‡å¤é¢˜ç›®å’Œæ€è€ƒå†…å®¹ï¼‰
            logger.info("5. æ¸…ç†æ··ä¹±è¾“å‡º...")
            result = clean_grading_output(result)
            
            # 6. å¼ºåˆ¶åˆ†å€¼é™åˆ¶ï¼ˆé˜²æ­¢è¶…å‡ºé¢˜ç›®æ€»åˆ†ï¼‰
            logger.info("6. æ‰§è¡Œåˆ†å€¼é™åˆ¶æ£€æŸ¥...")
            if file_info_list:
                marking_content = extract_marking_content(file_info_list)
                if marking_content:
                    result = enforce_score_limits(result, marking_content)
                    logger.info("åˆ†å€¼é™åˆ¶æ£€æŸ¥å®Œæˆ")
            
            logger.info(f"ç»“æœå¤„ç†å®Œæˆï¼Œæœ€ç»ˆé•¿åº¦: {len(result)} å­—ç¬¦")
            
            # å¦‚æœéœ€è¦æ€»ç»“ï¼Œè¿›è¡Œé¢å¤–çš„APIè°ƒç”¨
            if generate_summary:
                logger.info("ğŸ“Š å¼€å§‹ç”Ÿæˆæ‰¹æ”¹æ€»ç»“...")
                summary = generate_summary_with_api([result])
                result += f"\n\n{summary}"
                logger.info("æ€»ç»“ç”Ÿæˆå®Œæˆ")
            
            # è½¬æ¢ä¸ºHTMLæ ¼å¼
            logger.info("ğŸ¨ å¼€å§‹è½¬æ¢ä¸ºHTMLæ ¼å¼...")
            html_result = convert_to_html_markdown(result)
            logger.info(f"HTMLè½¬æ¢å®Œæˆï¼Œé•¿åº¦: {len(html_result)} å­—ç¬¦")
            
            # è¿”å›åŒ…å«åŸå§‹ç»“æœå’ŒHTMLç»“æœçš„å­—å…¸
            logger.info("âœ… æ‰¹æ”¹æµç¨‹å®Œå…¨å®Œæˆ")
            return {
                'text': result,
                'html': html_result,
                'format': 'enhanced'
            }
        else:
            logger.error("âŒ APIè°ƒç”¨è¿”å›ç©ºç»“æœ")
            return None

        
    except Exception as e:
        logger.error(f"âŒ å¢å¼ºç‰ˆæ‰¹æ”¹ï¼ˆæœ‰æ ‡å‡†ï¼‰å‡ºé”™: {e}")
        import traceback
        logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return None

def enhanced_batch_correction_without_standard(content_list, file_info_list=None, batch_size=10, generate_summary=True):
    """å¢å¼ºç‰ˆåˆ†æ‰¹æ‰¹æ”¹ï¼ˆæ— æ ‡å‡†ç­”æ¡ˆï¼‰- è¶…çº§ä¸¥æ ¼ç‰ˆ"""
    try:
        from .prompts_simplified import get_core_grading_prompt, get_batch_processing_prompt
        
        # é¦–å…ˆè¯»å–æ‰€æœ‰æ–‡ä»¶å†…å®¹
        all_contents = []
        file_paths = []  # ä¿å­˜åŸå§‹æ–‡ä»¶è·¯å¾„
        for file_path in content_list:
            try:
                content_type, content = process_file_content(file_path)
                
                # æ£€æŸ¥æ˜¯å¦å¤„ç†æˆåŠŸ
                if content_type == 'error':
                    print(f"âš ï¸ æ–‡ä»¶å¤„ç†å¤±è´¥ï¼š{file_path} - {content}")
                    continue
                
                if content and content_type != 'error':
                    # å¯¹äºå›¾ç‰‡å’ŒPDFï¼Œä¿å­˜æ–‡ä»¶è·¯å¾„è€Œä¸æ˜¯å†…å®¹
                    if content_type in ['image', 'pdf']:
                        all_contents.append(f"[æ–‡ä»¶: {os.path.basename(file_path)}]")
                        file_paths.append(file_path)
                    else:
                        all_contents.append(content)
                        file_paths.append(None)
                else:
                    print(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶ï¼š{file_path}")
            except Exception as e:
                print(f"âš ï¸ è¯»å–æ–‡ä»¶å‡ºé”™ {file_path}: {e}")
        
        if not all_contents:
            error_msg = "âŒ æ²¡æœ‰å¯å¤„ç†çš„æ–‡ä»¶å†…å®¹"
            print(error_msg)
            logger.error(error_msg)
            logger.error(f"è°ƒè¯•ä¿¡æ¯ï¼š")
            logger.error(f"- è¾“å…¥æ–‡ä»¶æ•°é‡: {len(content_list)}")
            logger.error(f"- æ–‡ä»¶åˆ—è¡¨: {[os.path.basename(f) if isinstance(f, str) and os.path.exists(f) else str(f) for f in content_list]}")
            logger.error(f"- å¤„ç†ç»“æœåˆ—è¡¨é•¿åº¦: {len(all_contents)}")
            logger.error(f"- æ–‡ä»¶è·¯å¾„åˆ—è¡¨é•¿åº¦: {len(file_paths)}")
            
            # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            return {
                'text': "âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ï¼šæ²¡æœ‰å¯å¤„ç†çš„æ–‡ä»¶å†…å®¹ã€‚è¯·æ£€æŸ¥ï¼š\n1. æ–‡ä»¶æ˜¯å¦æ­£ç¡®ä¸Šä¼ \n2. æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ\n3. æ–‡ä»¶æ˜¯å¦æŸå",
                'html': "<div style='color: red;'>âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ï¼šæ²¡æœ‰å¯å¤„ç†çš„æ–‡ä»¶å†…å®¹ã€‚è¯·æ£€æŸ¥ï¼š<br>1. æ–‡ä»¶æ˜¯å¦æ­£ç¡®ä¸Šä¼ <br>2. æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ<br>3. æ–‡ä»¶æ˜¯å¦æŸå</div>",
                'format': 'error'
            }
        
        # åˆå¹¶æ‰€æœ‰å†…å®¹
        combined_contents = []
        for content in all_contents:
            if isinstance(content, tuple) and len(content) == 2:
                # å¦‚æœæ˜¯å…ƒç»„ï¼Œå–ç¬¬äºŒä¸ªå…ƒç´ ï¼ˆå†…å®¹ï¼‰
                combined_contents.append(str(content[1]))
            else:
                combined_contents.append(str(content))
        combined_content = "\n\n".join(combined_contents)
        
        # ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«é¢˜ç›®æ•°é‡å’Œå­¦ç”Ÿä¿¡æ¯ï¼ˆè½»é‡çº§APIè°ƒç”¨ï¼‰
        print("ğŸ” ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«é¢˜ç›®æ•°é‡å’Œå­¦ç”Ÿä¿¡æ¯...")
        analysis_result = quick_analyze_files(content_list, file_paths, file_info_list)
        
        # ç¬¬äºŒæ­¥ï¼šè°ƒç”¨APIè¿›è¡Œæ‰¹æ”¹
        print("ğŸ“ ç¬¬äºŒæ­¥ï¼šå¼€å§‹æ„å»ºæ‰¹æ”¹æç¤ºè¯...")
        prompt = get_core_grading_prompt(file_info_list, analysis_result)
        
        # è°ƒç”¨API - ä¼ é€’æ–‡ä»¶è·¯å¾„è€Œä¸æ˜¯æ–‡æœ¬å†…å®¹
        api_args = [prompt]
        for i, file_path in enumerate(content_list):
            if i < len(file_paths) and file_paths[i]:  # å¦‚æœæ˜¯å›¾ç‰‡æˆ–PDFæ–‡ä»¶
                api_args.append(file_paths[i])
                print(f"æ·»åŠ APIå‚æ•°: æ–‡ä»¶è·¯å¾„ {os.path.basename(file_paths[i])}")
            elif i < len(all_contents):  # å¦‚æœæ˜¯æ–‡æœ¬å†…å®¹
                api_args.append(all_contents[i])
                print(f"æ·»åŠ APIå‚æ•°: æ–‡æœ¬å†…å®¹ (é•¿åº¦: {len(all_contents[i])} å­—ç¬¦)")
        
        print(f"è°ƒç”¨API - æ€»å‚æ•°æ•°é‡: {len(api_args)}")
        result = call_tongyiqianwen_api(*api_args)
        
        if result:
            # 1. å¼ºåˆ¶æ•°å­¦ç¬¦å·è½¬æ¢ï¼ˆå®Œå…¨é‡å¡‘ç‰ˆï¼‰
            result = convert_latex_to_unicode(result)
            
            # 2. ç»ˆæå¾ªç¯æ£€æµ‹å’Œæ¸…ç†
            result = detect_loop_and_cleanup(result)
            
            # 3. ç§»é™¤ä»»ä½•æ€»ç»“å†…å®¹
            result = remove_summary_from_batch(result)
            
            # 4. å¼ºåˆ¶æ ¼å¼ä¿®æ­£
            result = enforce_strict_format(result)
            
            # 5. æ¸…ç†æ··ä¹±è¾“å‡ºï¼ˆç§»é™¤é‡å¤é¢˜ç›®å’Œæ€è€ƒå†…å®¹ï¼‰
            result = clean_grading_output(result)
            
            # å¦‚æœéœ€è¦æ€»ç»“ï¼Œè¿›è¡Œé¢å¤–çš„APIè°ƒç”¨
            if generate_summary:
                print("ğŸ“Š æ­£åœ¨ç”Ÿæˆæ‰¹æ”¹æ€»ç»“...")
                summary = generate_summary_with_api([result])
                result += f"\n\n{summary}"
            
            # è½¬æ¢ä¸ºHTMLæ ¼å¼
            print("ğŸ¨ æ­£åœ¨è½¬æ¢ä¸ºHTMLæ ¼å¼...")
            html_result = convert_to_html_markdown(result)
            
            # è¿”å›åŒ…å«åŸå§‹ç»“æœå’ŒHTMLç»“æœçš„å­—å…¸
            return {
                'text': result,
                'html': html_result,
                'format': 'enhanced'
            }

        
    except Exception as e:
        logger.error(f"âŒ å¢å¼ºç‰ˆæ‰¹æ”¹ï¼ˆæ— æ ‡å‡†ï¼‰å‡ºé”™: {e}")
        import traceback
        logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return None

def remove_summary_from_batch(result):
    """ç§»é™¤æ‰¹æ¬¡ç»“æœä¸­çš„æ€»ç»“å†…å®¹"""
    if not result:
        return result
    
    lines = result.split('\n')
    cleaned_lines = []
    
    # æ£€æµ‹æ€»ç»“å…³é”®è¯
    summary_keywords = [
        'æ€»ç»“', 'æ±‡æ€»', 'æ€»ä½“', 'æ•´ä½“è¡¨ç°', 'ç»¼åˆè¯„ä»·', 
        'æ‰¹æ”¹å®Œæˆ', 'æ€»å¾—åˆ†', 'å¹³å‡åˆ†', 'å»ºè®®'
    ]
    
    skip_mode = False
    for line in lines:
        line_lower = line.lower()
        
        # æ£€æµ‹æ˜¯å¦è¿›å…¥æ€»ç»“æ¨¡å¼
        if any(keyword in line for keyword in summary_keywords):
            skip_mode = True
            continue
            
        # å¦‚æœä¸åœ¨æ€»ç»“æ¨¡å¼ï¼Œä¿ç•™è¯¥è¡Œ
        if not skip_mode:
            cleaned_lines.append(line)
        else:
            # æ£€æµ‹æ˜¯å¦é€€å‡ºæ€»ç»“æ¨¡å¼ï¼ˆé‡åˆ°æ–°é¢˜ç›®ï¼‰
            if line.startswith('### é¢˜ç›®'):
                skip_mode = False
                cleaned_lines.append(line)
    
    return '\n'.join(cleaned_lines)

def enforce_strict_format(result):
    """å¼ºåˆ¶æ‰§è¡Œä¸¥æ ¼æ ¼å¼ - å®Œå…¨é‡å¡‘ç‰ˆ"""
    if not result:
        return result
    
    import re
    
    # ç¬¬ä¸€æ­¥ï¼šç§»é™¤æ‰€æœ‰^ç¬¦å·
    result = result.replace('^', '')
    
    # ç¬¬äºŒæ­¥ï¼šé¢„å¤„ç† - åœ¨é¢˜ç›®æ ‡è®°å‰åæ·»åŠ æ¢è¡Œ
    result = re.sub(r'([^\n])(### é¢˜ç›®)', r'\1\n\n\2', result)
    result = re.sub(r'(### é¢˜ç›®\d+)([^\n])', r'\1\n', result)
    
    # ç¬¬ä¸‰æ­¥ï¼šä¿®å¤æ ‡é¢˜æ ¼å¼
    result = re.sub(r'(\*\*)?æ»¡åˆ†(\*\*)?[ï¼š:]', '**æ»¡åˆ†**ï¼š', result)
    result = re.sub(r'(\*\*)?å¾—åˆ†(\*\*)?[ï¼š:]', '**å¾—åˆ†**ï¼š', result)
    result = re.sub(r'(\*\*)?æ‰¹æ”¹è¯¦æƒ…(\*\*)?[ï¼š:]', '**æ‰¹æ”¹è¯¦æƒ…**ï¼š', result)
    
    # ç¬¬å››æ­¥ï¼šç¡®ä¿æ¯ä¸ªå­—æ®µç‹¬å ä¸€è¡Œ
    result = re.sub(r'(\d+åˆ†)\s*(- ğŸ“Š[^*]+)\s*(\*\*å¾—åˆ†)', r'\1 \2\n\3', result)
    result = re.sub(r'(\d+åˆ†)\s*(\*\*æ‰¹æ”¹è¯¦æƒ…)', r'\1\n\2', result)
    result = re.sub(r'(ï¼š\d+åˆ†)\s*(-)', r'\1\n\2', result)
    
    # ä¿®å¤åŒç ´æŠ˜å·é—®é¢˜
    result = re.sub(r'- - ğŸ“Š', '- ğŸ“Š', result)
    
    # ç¬¬äº”æ­¥ï¼šæŒ‰é¢˜ç›®åˆ†å‰²å¤„ç†
    questions = re.split(r'(### é¢˜ç›®\d+)', result)
    
    formatted_parts = []
    for i in range(1, len(questions), 2):
        if i < len(questions) - 1:
            title = questions[i]
            content = questions[i + 1]
            
            # å¤„ç†é¢˜ç›®å†…å®¹
            lines = content.split('\n')
            formatted_lines = [title]
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # å¤„ç†å„ä¸ªå­—æ®µ
                if line.startswith('**æ»¡åˆ†**') or line.startswith('**å¾—åˆ†**') or line.startswith('**æ‰¹æ”¹è¯¦æƒ…**'):
                    formatted_lines.append(line)
                elif 'âœ“' in line or 'âœ—' in line or (line.startswith('-') and '[' in line and ']' in line):
                    # å¤„ç†æ‰¹æ”¹æ­¥éª¤
                    # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªæ­¥éª¤åœ¨ä¸€è¡Œ
                    if line.count('âœ“') + line.count('âœ—') > 1:
                        # åˆ†å‰²å¤šä¸ªæ­¥éª¤
                        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ‰¾åˆ°æ‰€æœ‰æ­¥éª¤
                        step_pattern = r'(-\s*(?:\([a-zA-Z]\)\s*)?[^âœ“âœ—]+(?:âœ“|âœ—)\s*\[\d+[MA]/A\])'
                        steps = re.findall(step_pattern, line)
                        
                        if steps:
                            # é€ä¸ªå¤„ç†æ¯ä¸ªæ­¥éª¤
                            for step in steps:
                                step = step.strip()
                                # ç¡®ä¿æ ¼å¼æ­£ç¡®
                                if not step.startswith('- '):
                                    step = '- ' + step.lstrip('-').strip()
                                
                                # å¤„ç† (a), (b) ç­‰æ ‡è®°
                                step = re.sub(r'-\s*\(([a-zA-Z])\)\s*', r'- (\1) ', step)
                                
                                # ç¡®ä¿ç¬¦å·å‰æœ‰ç©ºæ ¼
                                step = re.sub(r'([^\s])(âœ“|âœ—)', r'\1 \2', step)
                                
                                # ç¡®ä¿åˆ†å€¼æ ¼å¼æ­£ç¡®
                                step = re.sub(r'\[\s*(\d+)\s*([MA])\s*/?\s*([MA])?\s*\]', r'[\1\2/A]', step)
                                step = re.sub(r'\[\s*(\d+)\s*([MA])\s*\]', r'[\1\2/A]', step)
                                
                                formatted_lines.append(step)
                        else:
                            # å¦‚æœæ­£åˆ™åŒ¹é…å¤±è´¥ï¼Œå°è¯•æŒ‰ç¬¦å·åˆ†å‰²
                            parts = re.split(r'(?=[âœ“âœ—])', line)
                            for i, part in enumerate(parts):
                                if part.strip() and ('âœ“' in part or 'âœ—' in part):
                                    part = part.strip()
                                    if not part.startswith('- '):
                                        part = '- ' + part
                                    formatted_lines.append(part)
                    else:
                        # å•ä¸ªæ­¥éª¤
                        line = re.sub(r'\s+', ' ', line)
                        
                        # ç¡®ä¿æ­¥éª¤æ ¼å¼æ­£ç¡®
                        if not line.startswith('- '):
                            if line.startswith('-'):
                                line = '- ' + line[1:].strip()
                            else:
                                line = '- ' + line
                        
                        # å¤„ç† (a), (b) ç­‰æ ‡è®°
                        line = re.sub(r'-\s*\(([a-zA-Z])\)\s*', r'- (\1) ', line)
                        
                        # ç¡®ä¿ç¬¦å·å‰æœ‰ç©ºæ ¼
                        line = re.sub(r'([^\s])(âœ“|âœ—)', r'\1 \2', line)
                        
                        # ç¡®ä¿åˆ†å€¼æ ¼å¼æ­£ç¡® [XM/A]
                        line = re.sub(r'\[\s*(\d+)\s*([MA])\s*/?\s*([MA])?\s*\]', r'[\1\2/A]', line)
                        line = re.sub(r'\[\s*(\d+)\s*([MA])\s*\]', r'[\1\2/A]', line)
                        
                        formatted_lines.append(line)
                elif 'ğŸ“Š æ¥æºï¼šMARKINGæ ‡å‡†' in line:
                    # è¿™éƒ¨åˆ†åº”è¯¥è·Ÿåœ¨æ»¡åˆ†åé¢
                    if formatted_lines and '**æ»¡åˆ†**' in formatted_lines[-1]:
                        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ç ´æŠ˜å·
                        if formatted_lines[-1].endswith(' - '):
                            formatted_lines[-1] = formatted_lines[-1] + line.strip()
                        else:
                            formatted_lines[-1] = formatted_lines[-1] + ' - ' + line.strip()
                else:
                    # å…¶ä»–å†…å®¹ï¼Œå¦‚æœä¸æ˜¯æ€»ç»“ç›¸å…³çš„å°±ä¿ç•™
                    if not any(skip in line for skip in ['æ€»ç»“', 'æ‰¹æ”¹å®Œæˆ', 'æ•´ä½“è¡¨ç°', 'ç»Ÿè®¡ä¿¡æ¯', 'ä¸»è¦é”™è¯¯', 'æ”¹è¿›å»ºè®®']):
                        formatted_lines.append(line)
            
            # æ·»åŠ æ ¼å¼åŒ–åçš„é¢˜ç›®
            if formatted_parts:
                formatted_parts.append('')  # é¢˜ç›®ä¹‹é—´çš„ç©ºè¡Œ
            formatted_parts.extend(formatted_lines)
    
    # ç¬¬å…­æ­¥ï¼šç»„åˆæ‰€æœ‰éƒ¨åˆ†
    result = '\n'.join(formatted_parts)
    
    # ç¬¬ä¸ƒæ­¥ï¼šæœ€ç»ˆæ¸…ç†
    # ç¡®ä¿æ²¡æœ‰è¿ç»­çš„ç©ºè¡Œ
    result = re.sub(r'\n{3,}', '\n\n', result)
    
    # ç¡®ä¿æ¯ä¸ªé¢˜ç›®å—çš„æ ¼å¼æ­£ç¡®
    result = re.sub(r'(### é¢˜ç›®\d+)\n+(\*\*æ»¡åˆ†)', r'\1\n\2', result)
    result = re.sub(r'(\*\*æ»¡åˆ†\*\*ï¼š[^\n]+)\n+(\*\*å¾—åˆ†)', r'\1\n\2', result)
    result = re.sub(r'(\*\*å¾—åˆ†\*\*ï¼š[^\n]+)\n+(\*\*æ‰¹æ”¹è¯¦æƒ…)', r'\1\n\2', result)
    result = re.sub(r'(\*\*æ‰¹æ”¹è¯¦æƒ…\*\*ï¼š)\n+(- )', r'\1\n\2', result)
    
    # ç§»é™¤è¡Œé¦–è¡Œå°¾çš„ç©ºæ ¼
    lines = result.split('\n')
    result = '\n'.join(line.rstrip() for line in lines)
    
    # ç¡®ä¿å¼€å¤´æ²¡æœ‰ç©ºè¡Œ
    result = result.lstrip('\n')
    
    return result

# ===================== å¢å¼ºç‰ˆæ‰¹æ”¹å‡½æ•° =====================
def convert_latex_to_unicode(text):
    """å®Œå…¨é‡å¡‘çš„LaTeXåˆ°Unicodeè½¬æ¢ç³»ç»Ÿ"""
    if not text:
        return text
    
    # ç¬¬ä¸€æ­¥ï¼šæ£€æµ‹LaTeXç¬¦å·
    if '$' in text:
        print("âš ï¸ è­¦å‘Šï¼šæ£€æµ‹åˆ°LaTeXç¬¦å·ï¼Œæ­£åœ¨å¼ºåˆ¶è½¬æ¢...")
    
    # ç¬¬äºŒæ­¥ï¼šç§»é™¤æ‰€æœ‰$ç¬¦å·
    text = text.replace('$', '')
    
    # ç¬¬ä¸‰æ­¥ï¼šå®Œæ•´çš„LaTeXåˆ°Unicodeæ˜ å°„è¡¨
    latex_replacements = {
        # å¸Œè…Šå­—æ¯
        r'\alpha': 'Î±', r'\beta': 'Î²', r'\gamma': 'Î³', r'\delta': 'Î´',
        r'\epsilon': 'Îµ', r'\zeta': 'Î¶', r'\eta': 'Î·', r'\theta': 'Î¸',
        r'\iota': 'Î¹', r'\kappa': 'Îº', r'\lambda': 'Î»', r'\mu': 'Î¼',
        r'\nu': 'Î½', r'\xi': 'Î¾', r'\pi': 'Ï€', r'\rho': 'Ï',
        r'\sigma': 'Ïƒ', r'\tau': 'Ï„', r'\phi': 'Ï†', r'\chi': 'Ï‡',
        r'\psi': 'Ïˆ', r'\omega': 'Ï‰',
        r'\Gamma': 'Î“', r'\Delta': 'Î”', r'\Theta': 'Î˜', r'\Lambda': 'Î›',
        r'\Xi': 'Î', r'\Pi': 'Î ', r'\Sigma': 'Î£', r'\Phi': 'Î¦',
        r'\Psi': 'Î¨', r'\Omega': 'Î©',
        
        # æ•°å­¦è¿ç®—ç¬¦
        r'\times': 'Ã—', r'\div': 'Ã·', r'\pm': 'Â±', r'\mp': 'âˆ“',
        r'\cdot': 'Â·', r'\ast': '*', r'\star': 'â‹†', r'\dagger': 'â€ ',
        r'\ddagger': 'â€¡', r'\amalg': 'â¨¿',
        
        # å…³ç³»ç¬¦å·
        r'\leq': 'â‰¤', r'\geq': 'â‰¥', r'\neq': 'â‰ ', r'\approx': 'â‰ˆ',
        r'\equiv': 'â‰¡', r'\sim': 'âˆ¼', r'\simeq': 'â‰ƒ', r'\cong': 'â‰…',
        r'\propto': 'âˆ', r'\perp': 'âŠ¥', r'\parallel': 'âˆ¥',
        
        # é›†åˆç¬¦å·
        r'\in': 'âˆˆ', r'\notin': 'âˆ‰', r'\subset': 'âŠ‚', r'\supset': 'âŠƒ',
        r'\subseteq': 'âŠ†', r'\supseteq': 'âŠ‡', r'\cup': 'âˆª', r'\cap': 'âˆ©',
        r'\emptyset': 'âˆ…', r'\varnothing': 'âˆ…',
        
        # é€»è¾‘ç¬¦å·
        r'\land': 'âˆ§', r'\lor': 'âˆ¨', r'\lnot': 'Â¬', r'\forall': 'âˆ€',
        r'\exists': 'âˆƒ', r'\nexists': 'âˆ„', r'\therefore': 'âˆ´', r'\because': 'âˆµ',
        
        # ç®­å¤´
        r'\rightarrow': 'â†’', r'\leftarrow': 'â†', r'\leftrightarrow': 'â†”',
        r'\Rightarrow': 'â‡’', r'\Leftarrow': 'â‡', r'\Leftrightarrow': 'â‡”',
        r'\mapsto': 'â†¦', r'\to': 'â†’',
        
        # å…¶ä»–ç¬¦å·
        r'\infty': 'âˆ', r'\partial': 'âˆ‚', r'\nabla': 'âˆ‡', r'\square': 'â–¡',
        r'\triangle': 'â–³', r'\angle': 'âˆ ', r'\measuredangle': 'âˆ¡',
        r'\sphericalangle': 'âˆ¢', r'\prime': 'â€²', r'\circ': 'Â°',
        r'\bullet': 'â€¢', r'\dots': 'â€¦', r'\cdots': 'â‹¯', r'\vdots': 'â‹®',
        r'\ddots': 'â‹±', r'\ldots': 'â€¦',
        
        # ç‰¹æ®Šå‡½æ•°
        r'\sin': 'sin', r'\cos': 'cos', r'\tan': 'tan', r'\cot': 'cot',
        r'\sec': 'sec', r'\csc': 'csc', r'\log': 'log', r'\ln': 'ln',
        r'\exp': 'exp', r'\min': 'min', r'\max': 'max', r'\sup': 'sup',
        r'\inf': 'inf', r'\lim': 'lim', r'\limsup': 'lim sup', r'\liminf': 'lim inf',
        
        # åˆ†æ•°å¤„ç†ï¼ˆç‰¹æ®Šå¤„ç†ï¼‰
        r'\frac': '/',  # ä¸´æ—¶æ ‡è®°ï¼Œåç»­ç‰¹æ®Šå¤„ç†
        
        # ä¸Šä¸‹æ ‡ï¼ˆç‰¹æ®Šå¤„ç†ï¼‰
        '^': '**', '_': '__',  # ä¸´æ—¶æ ‡è®°
        
        # æ‹¬å·
        r'\left': '', r'\right': '',
        r'\{': '{', r'\}': '}',
        r'\langle': 'âŸ¨', r'\rangle': 'âŸ©',
        r'\lfloor': 'âŒŠ', r'\rfloor': 'âŒ‹',
        r'\lceil': 'âŒˆ', r'\rceil': 'âŒ‰',
        
        # æ±‚å’Œã€ç§¯åˆ†ç­‰
        r'\sum': 'âˆ‘', r'\prod': 'âˆ', r'\int': 'âˆ«', r'\oint': 'âˆ®',
        r'\iint': 'âˆ¬', r'\iiint': 'âˆ­', r'\bigcup': 'â‹ƒ', r'\bigcap': 'â‹‚',
        
        # æ ¹å·
        r'\sqrt': 'âˆš',
        
        # çŸ©é˜µ
        r'\begin{pmatrix}': '(', r'\end{pmatrix}': ')',
        r'\begin{bmatrix}': '[', r'\end{bmatrix}': ']',
        r'\begin{vmatrix}': '|', r'\end{vmatrix}': '|',
        r'\begin{cases}': '{', r'\end{cases}': '',
        r'\\': '; ',  # çŸ©é˜µæ¢è¡Œ
    }
    
    # ç¬¬å››æ­¥ï¼šåº”ç”¨æ‰€æœ‰æ›¿æ¢
    for latex, unicode_char in latex_replacements.items():
        text = text.replace(latex, unicode_char)
    
    # ç¬¬äº”æ­¥ï¼šå¤„ç†åˆ†æ•° \frac{a}{b} -> a/b
    import re
    frac_pattern = r'/\{([^}]+)\}\{([^}]+)\}'
    while re.search(frac_pattern, text):
        text = re.sub(frac_pattern, r'(\1)/(\2)', text)
    
    # ç¬¬å…­æ­¥ï¼šå¤„ç†ä¸Šæ ‡ a^{bc} -> a^(bc), a^b -> a^b
    superscript_pattern = r'\*\*\{([^}]+)\}'
    text = re.sub(superscript_pattern, r'^(\1)', text)
    text = text.replace('**', '^')
    
    # ç¬¬ä¸ƒæ­¥ï¼šå¤„ç†ä¸‹æ ‡ a_{bc} -> a_(bc), a_b -> a_b
    subscript_pattern = r'__\{([^}]+)\}'
    text = re.sub(subscript_pattern, r'_(\1)', text)
    text = text.replace('__', '_')
    
    # ç¬¬å…«æ­¥ï¼šæ¸…ç†å¤šä½™çš„èŠ±æ‹¬å·
    text = re.sub(r'\{([^}]+)\}', r'\1', text)
    
    # ç¬¬ä¹æ­¥ï¼šæœ€ç»ˆæ¸…ç†
    text = text.replace('\\', '')  # ç§»é™¤å‰©ä½™çš„åæ–œæ 
    text = re.sub(r'\s+', ' ', text)  # è§„èŒƒåŒ–ç©ºæ ¼
    text = text.strip()
    
    # ç¬¬åæ­¥ï¼šå¤„ç†å¸¸è§çš„æ•°å­¦è¡¨è¾¾å¼
    # å¤„ç†ä¸Šæ ‡æ•°å­—ï¼ˆè½¬æ¢ä¸ºUnicodeä¸Šæ ‡ï¼‰
    superscript_map = {
        '0': 'â°', '1': 'Â¹', '2': 'Â²', '3': 'Â³', '4': 'â´',
        '5': 'âµ', '6': 'â¶', '7': 'â·', '8': 'â¸', '9': 'â¹',
        '+': 'âº', '-': 'â»', '=': 'â¼', '(': 'â½', ')': 'â¾',
        'n': 'â¿', 'i': 'â±'
    }
    
    # è½¬æ¢ç®€å•ä¸Šæ ‡ x^2 -> xÂ²
    def replace_superscript(match):
        base = match.group(1)
        sup = match.group(2)
        if len(sup) == 1 and sup in superscript_map:
            return base + superscript_map[sup]
        else:
            # å¤šå­—ç¬¦ä¸Šæ ‡ä¿æŒåŸæ ·
            return f"{base}^({sup})"
    
    text = re.sub(r'([a-zA-Z0-9])\^([0-9+\-=()ni])', replace_superscript, text)
    text = re.sub(r'([a-zA-Z0-9])\^\(([^)]+)\)', r'\1^(\2)', text)
    
    # å¤„ç†ä¸‹æ ‡æ•°å­—ï¼ˆè½¬æ¢ä¸ºUnicodeä¸‹æ ‡ï¼‰
    subscript_map = {
        '0': 'â‚€', '1': 'â‚', '2': 'â‚‚', '3': 'â‚ƒ', '4': 'â‚„',
        '5': 'â‚…', '6': 'â‚†', '7': 'â‚‡', '8': 'â‚ˆ', '9': 'â‚‰',
        '+': 'â‚Š', '-': 'â‚‹', '=': 'â‚Œ', '(': 'â‚', ')': 'â‚',
        'a': 'â‚', 'e': 'â‚‘', 'o': 'â‚’', 'x': 'â‚“', 'h': 'â‚•',
        'k': 'â‚–', 'l': 'â‚—', 'm': 'â‚˜', 'n': 'â‚™', 'p': 'â‚š',
        's': 'â‚›', 't': 'â‚œ'
    }
    
    # è½¬æ¢ç®€å•ä¸‹æ ‡ x_1 -> xâ‚
    def replace_subscript(match):
        base = match.group(1)
        sub = match.group(2)
        if len(sub) == 1 and sub in subscript_map:
            return base + subscript_map[sub]
        else:
            # å¤šå­—ç¬¦ä¸‹æ ‡ä¿æŒåŸæ ·
            return f"{base}_({sub})"
    
    text = re.sub(r'([a-zA-Z0-9])_([0-9+\-=()aeoxhklmnpst])', replace_subscript, text)
    text = re.sub(r'([a-zA-Z0-9])_\(([^)]+)\)', r'\1_(\2)', text)
    
    # ç¬¬åä¸€æ­¥ï¼šéªŒè¯æ˜¯å¦è¿˜æœ‰LaTeXæ®‹ç•™
    latex_indicators = ['\\', '$', r'\frac', r'\angle', r'\times']
    for indicator in latex_indicators:
        if indicator in text:
            print(f"âš ï¸ è­¦å‘Šï¼šä»æ£€æµ‹åˆ°LaTeXç¬¦å· '{indicator}'")
    
    return text

def clean_grading_output(result):
    """æ¸…ç†æ‰¹æ”¹è¾“å‡ºï¼Œç§»é™¤æ··ä¹±å†…å®¹"""
    if not result:
        return result
    
    lines = result.split('\n')
    cleaned_lines = []
    seen_questions = set()
    current_question = None
    skip_mode = False
    
    for line in lines:
        # æ£€æµ‹æ‰¹æ”¹æš‚åœæ€è€ƒç­‰æ··ä¹±å†…å®¹
        if 'æ‰¹æ”¹æš‚åœæ€è€ƒ' in line or 'è¿›åº¦æŠ¥å‘Š' in line or '============' in line:
            skip_mode = True
            continue
        
        # å¦‚æœåœ¨è·³è¿‡æ¨¡å¼ï¼Œæ£€æŸ¥æ˜¯å¦é‡åˆ°æ–°é¢˜ç›®
        if skip_mode:
            if line.strip().startswith('### é¢˜ç›®'):
                skip_mode = False
            else:
                continue
        
        # æ£€æµ‹é¢˜ç›®æ ‡é¢˜
        if line.strip().startswith('### é¢˜ç›®'):
            import re
            match = re.search(r'### é¢˜ç›®(\d+)', line)
            if match:
                question_num = int(match.group(1))
                if question_num in seen_questions:
                    # è·³è¿‡é‡å¤çš„é¢˜ç›®
                    print(f"âš ï¸ æ£€æµ‹åˆ°é‡å¤é¢˜ç›®{question_num}ï¼Œè·³è¿‡")
                    current_question = None
                    continue
                else:
                    seen_questions.add(question_num)
                    current_question = question_num
                    cleaned_lines.append(line)
        elif current_question is not None and not skip_mode:
            # ä¿ç•™å½“å‰é¢˜ç›®çš„å†…å®¹
            cleaned_lines.append(line)
    
    return '\n'.join(cleaned_lines)

def enforce_score_limits(result, marking_scheme):
    """å¼ºåˆ¶æ‰§è¡Œåˆ†å€¼é™åˆ¶ï¼Œé˜²æ­¢è¶…å‡ºé¢˜ç›®æ€»åˆ†"""
    if not result or not marking_scheme:
        return result
    
    # è§£ææ‰¹æ”¹æ ‡å‡†è·å–æ¯é¢˜åˆ†å€¼
    question_scores = parse_marking_scheme(marking_scheme)
    
    lines = result.split('\n')
    corrected_lines = []
    current_question = None
    current_steps = []
    
    for line in lines:
        # æ£€æµ‹é¢˜ç›®
        import re
        question_match = re.search(r'### é¢˜ç›®(\d+)', line)
        if question_match:
            # å¤„ç†ä¸Šä¸€é¢˜çš„æ­¥éª¤
            if current_question and current_steps:
                corrected_lines.extend(enforce_steps_limit(current_steps, question_scores.get(current_question, 0)))
            
            # å¼€å§‹æ–°é¢˜ç›®
            current_question = int(question_match.group(1))
            current_steps = []
            corrected_lines.append(line)
        elif line.strip().startswith('å…³é”®æ­¥éª¤') or line.strip().startswith('- å…³é”®æ­¥éª¤'):
            current_steps.append(line)
        else:
            if current_steps:
                # å®Œæˆå½“å‰é¢˜ç›®çš„æ­¥éª¤æ”¶é›†
                corrected_lines.extend(enforce_steps_limit(current_steps, question_scores.get(current_question, 0)))
                current_steps = []
            corrected_lines.append(line)
    
    # å¤„ç†æœ€åä¸€é¢˜
    if current_steps:
        corrected_lines.extend(enforce_steps_limit(current_steps, question_scores.get(current_question, 0)))
    
    return '\n'.join(corrected_lines)

def enforce_steps_limit(steps, max_score):
    """é™åˆ¶æ­¥éª¤æ•°é‡ï¼Œä¸è¶…è¿‡é¢˜ç›®æ€»åˆ†"""
    if not steps:
        return steps
    
    # è®¡ç®—å½“å‰æ­¥éª¤çš„æ€»åˆ†
    total_score = 0
    valid_steps = []
    
    for step in steps:
        # æå–æ­¥éª¤åˆ†å€¼
        import re
        score_match = re.search(r'\[(\d+)[MA]\]', step)
        if score_match:
            step_score = int(score_match.group(1))
            if total_score + step_score <= max_score:
                valid_steps.append(step)
                total_score += step_score
            else:
                print(f"âš ï¸ è·³è¿‡è¶…å‡ºåˆ†å€¼çš„æ­¥éª¤ï¼š{step}")
        else:
            valid_steps.append(step)
    
    return valid_steps

def parse_marking_scheme(marking_scheme):
    """è§£ææ‰¹æ”¹æ ‡å‡†ï¼Œè·å–æ¯é¢˜åˆ†å€¼"""
    question_scores = {}
    
    if not marking_scheme:
        return question_scores
    
    lines = marking_scheme.split('\n')
    
    import re
    for line in lines:
        # æ£€æµ‹é¢˜ç›®å’Œåˆ†å€¼ - æ”¯æŒå¤šç§æ ¼å¼
        patterns = [
            r'(\d+)\.\s*.*?\((\d+)\s*(?:marks?|åˆ†)\)',  # 1. xxx (3 marks)
            r'é¢˜ç›®\s*(\d+).*?\((\d+)\s*(?:marks?|åˆ†)\)',  # é¢˜ç›®1 (3åˆ†)
            r'Q(\d+).*?\((\d+)\s*(?:marks?|åˆ†)\)',       # Q1 (3 marks)
            r'Question\s*(\d+).*?\((\d+)\s*(?:marks?|åˆ†)\)'  # Question 1 (3 marks)
        ]
        
        for pattern in patterns:
            match = re.search(pattern, line, re.IGNORECASE)
            if match:
                question_num = int(match.group(1))
                score = int(match.group(2))
                question_scores[question_num] = score
                break
    
    return question_scores

def extract_marking_content(file_info_list):
    """ä»æ–‡ä»¶ä¿¡æ¯ä¸­æå–æ‰¹æ”¹æ ‡å‡†å†…å®¹"""
    if not file_info_list:
        return ""
    
    marking_contents = []
    
    for file_info in file_info_list:
        if isinstance(file_info, dict):
            file_name = file_info.get('name', '').upper()
            file_path = file_info.get('path', '')
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ‰¹æ”¹æ ‡å‡†æ–‡ä»¶
            if 'MARKING' in file_name or 'STANDARD' in file_name or 'æ ‡å‡†' in file_name:
                try:
                    content_type, content = process_file_content(file_path)
                    if content:
                        # å¦‚æœæ˜¯å…ƒç»„ï¼Œå–ç¬¬äºŒä¸ªå…ƒç´ 
                        if isinstance(content, tuple) and len(content) == 2:
                            marking_contents.append(str(content[1]))
                        else:
                            marking_contents.append(str(content))
                except Exception as e:
                    print(f"è¯»å–æ‰¹æ”¹æ ‡å‡†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    return "\n\n".join(marking_contents)

def convert_to_html_markdown(result):
    """å°†æ‰¹æ”¹ç»“æœè½¬æ¢ä¸ºHTMLæ ¼å¼çš„Markdown - å¢å¼ºç‰ˆ"""
    if not result:
        return result
    
    import re
    
    # HTMLæ¨¡æ¿ - å¢å¼ºæ ·å¼ï¼ˆç™½è‰²èƒŒæ™¯ï¼‰
    html_template = """<div style="font-family: 'Microsoft YaHei', Arial, sans-serif; color: #333; line-height: 1.8; max-width: 800px; margin: 0 auto; padding: 20px; background-color: #ffffff;">
<style>
    body {{
        background-color: #ffffff !important;
    }}
    .question-title {{
        color: #2c3e50;
        margin-top: 25px;
        margin-bottom: 15px;
        border-bottom: 2px solid #3498db;
        padding-bottom: 8px;
        font-weight: bold;
        font-size: 1.5em;
    }}
    .score-full {{
        color: #27ae60;
        font-weight: bold;
    }}
    .score-good {{
        color: #f39c12;
        font-weight: bold;
    }}
    .score-low {{
        color: #e74c3c;
        font-weight: bold;
    }}
    .step-correct {{
        color: #27ae60;
        margin: 3px 0 3px 20px;
    }}
    .step-wrong {{
        color: #e74c3c;
        margin: 3px 0 3px 20px;
    }}
    .check-mark {{
        font-weight: bold;
        font-size: 1.2em;
    }}
    .section-title {{
        font-weight: bold;
        color: #34495e;
        margin: 10px 0 5px 0;
    }}
</style>
{content}
</div>"""
    
    # å¤„ç†æ¯ä¸ªé¢˜ç›®
    lines = result.split('\n')
    html_lines = []
    current_full_score = 0
    
    for line in lines:
        line = line.rstrip()
        
        if not line:
            html_lines.append('<br>')
            continue
        
        # é¢˜ç›®æ ‡é¢˜ - åŠ ç²—
        if line.startswith('### é¢˜ç›®'):
            question_match = re.search(r'### é¢˜ç›®(\d+)', line)
            if question_match:
                q_num = question_match.group(1)
                html_lines.append(f'<h3 class="question-title">é¢˜ç›® {q_num}</h3>')
        
        # æ»¡åˆ†è¡Œ
        elif line.startswith('**æ»¡åˆ†**ï¼š'):
            content = line.replace('**æ»¡åˆ†**ï¼š', '').strip()
            # æå–æ»¡åˆ†æ•°å€¼
            score_match = re.search(r'(\d+)åˆ†', content)
            if score_match:
                current_full_score = int(score_match.group(1))
            html_lines.append(f'<p style="margin: 5px 0;"><span class="section-title">æ»¡åˆ†ï¼š</span>{content}</p>')
        
        # å¾—åˆ†è¡Œ
        elif line.startswith('**å¾—åˆ†**ï¼š'):
            content = line.replace('**å¾—åˆ†**ï¼š', '').strip()
            # æ ¹æ®å¾—åˆ†æƒ…å†µæ·»åŠ ä¸åŒé¢œè‰²
            score_match = re.search(r'(\d+)åˆ†', content)
            if score_match and current_full_score > 0:
                score = int(score_match.group(1))
                percentage = score / current_full_score
                if percentage >= 1.0:
                    score_class = 'score-full'
                elif percentage >= 0.8:
                    score_class = 'score-good'
                else:
                    score_class = 'score-low'
                html_lines.append(f'<p style="margin: 5px 0;"><span class="section-title">å¾—åˆ†ï¼š</span><span class="{score_class}">{content}</span></p>')
            else:
                html_lines.append(f'<p style="margin: 5px 0;"><span class="section-title">å¾—åˆ†ï¼š</span>{content}</p>')
        
        # æ‰¹æ”¹è¯¦æƒ…æ ‡é¢˜
        elif line.startswith('**æ‰¹æ”¹è¯¦æƒ…**ï¼š'):
            html_lines.append('<p class="section-title">æ‰¹æ”¹è¯¦æƒ…ï¼š</p>')
        
        # æ‰¹æ”¹æ­¥éª¤ - å¾—åˆ†ç»¿è‰²ï¼Œå¤±åˆ†çº¢è‰²
        elif line.startswith('- ') and ('âœ“' in line or 'âœ—' in line):
            step_content = line[2:].strip()  # ç§»é™¤ "- "
            
            if 'âœ“' in line:
                # æ­£ç¡®çš„æ­¥éª¤ - ç»¿è‰²
                step_html = step_content.replace('âœ“', '<span class="check-mark" style="color: #27ae60;">âœ“</span>')
                # æå–æ­¥éª¤å†…å®¹å’Œåˆ†æ•°
                parts = re.split(r'(âœ“)', step_content)
                if len(parts) >= 3:
                    before_check = parts[0].strip()
                    after_check = parts[2].strip()
                    html_lines.append(f'<p class="step-correct">â€¢ <strong>{before_check}</strong> <span class="check-mark" style="color: #27ae60;">âœ“</span> {after_check}</p>')
                else:
                    html_lines.append(f'<p class="step-correct">â€¢ {step_html}</p>')
            else:
                # é”™è¯¯çš„æ­¥éª¤ - çº¢è‰²
                step_html = step_content.replace('âœ—', '<span class="check-mark" style="color: #e74c3c;">âœ—</span>')
                # æå–æ­¥éª¤å†…å®¹å’Œåˆ†æ•°
                parts = re.split(r'(âœ—)', step_content)
                if len(parts) >= 3:
                    before_check = parts[0].strip()
                    after_check = parts[2].strip()
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ‰£åˆ†åŸå› ï¼ˆâ†’ ç¬¦å·ï¼‰
                    if 'â†’' in after_check:
                        score_and_reason = after_check.split('â†’', 1)
                        if len(score_and_reason) == 2:
                            score_part = score_and_reason[0].strip()
                            reason_part = score_and_reason[1].strip()
                            html_lines.append(f'<p class="step-wrong">â€¢ <strong>{before_check}</strong> <span class="check-mark" style="color: #e74c3c;">âœ—</span> {score_part} â†’ <em>{reason_part}</em></p>')
                        else:
                            html_lines.append(f'<p class="step-wrong">â€¢ <strong>{before_check}</strong> <span class="check-mark" style="color: #e74c3c;">âœ—</span> {after_check}</p>')
                    else:
                        html_lines.append(f'<p class="step-wrong">â€¢ <strong>{before_check}</strong> <span class="check-mark" style="color: #e74c3c;">âœ—</span> {after_check}</p>')
                else:
                    html_lines.append(f'<p class="step-wrong">â€¢ {step_html}</p>')
        
        # æ€»ç»“éƒ¨åˆ†
        elif '=== ğŸ“Š æ‰¹æ”¹æ€»ç»“ ===' in line:
            html_lines.append('<hr style="margin: 30px 0; border: none; border-top: 2px solid #ecf0f1;">')
            html_lines.append('<h2 style="color: #2c3e50; text-align: center; margin: 20px 0; font-weight: bold;">ğŸ“Š æ‰¹æ”¹æ€»ç»“</h2>')
        
        elif line.startswith('**æ•´ä½“è¡¨ç°**ï¼š'):
            content = line.replace('**æ•´ä½“è¡¨ç°**ï¼š', '').strip()
            html_lines.append(f'<p style="margin: 10px 0; font-size: 1.1em;"><span class="section-title">æ•´ä½“è¡¨ç°ï¼š</span>{content}</p>')
        
        elif line.startswith('**æ€»å¾—åˆ†**ï¼š'):
            content = line.replace('**æ€»å¾—åˆ†**ï¼š', '').strip()
            html_lines.append(f'<p style="margin: 10px 0; font-size: 1.2em;"><span class="section-title">æ€»å¾—åˆ†ï¼š</span><span style="color: #e74c3c; font-weight: bold; font-size: 1.1em;">{content}</span></p>')
        
        elif line.startswith('**ç»Ÿè®¡ä¿¡æ¯**ï¼š'):
            html_lines.append('<p class="section-title">ç»Ÿè®¡ä¿¡æ¯ï¼š</p>')
        
        elif line.startswith('**ä¸»è¦é”™è¯¯ç±»å‹**ï¼š'):
            html_lines.append('<p class="section-title">ä¸»è¦é”™è¯¯ç±»å‹ï¼š</p>')
        
        elif line.startswith('**æ”¹è¿›å»ºè®®**ï¼š'):
            html_lines.append('<p class="section-title">æ”¹è¿›å»ºè®®ï¼š</p>')
        
        # åˆ—è¡¨é¡¹
        elif re.match(r'^\d+\.\s', line) or (line.startswith('- ') and 'âœ“' not in line and 'âœ—' not in line):
            content = re.sub(r'^\d+\.\s|^-\s', '', line)
            html_lines.append(f'<p style="margin: 3px 0 3px 30px;">â€¢ {content}</p>')
        
        else:
            # å…¶ä»–å†…å®¹
            html_lines.append(f'<p style="margin: 5px 0;">{line}</p>')
    
    # ç»„åˆHTMLå†…å®¹
    content = '\n'.join(html_lines)
    return html_template.format(content=content)