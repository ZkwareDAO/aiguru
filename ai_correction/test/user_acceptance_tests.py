#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”¨æˆ·éªŒæ”¶æµ‹è¯•å¥—ä»¶
ç¼–å†™æ•™å¸ˆç”¨æˆ·å®Œæ•´å·¥ä½œæµç¨‹çš„éªŒæ”¶æµ‹è¯•
ç¼–å†™å­¦ç”Ÿç”¨æˆ·å®Œæ•´å·¥ä½œæµç¨‹çš„éªŒæ”¶æµ‹è¯•
ç¼–å†™ç³»ç»Ÿç®¡ç†å‘˜ç›‘æ§å’Œç»´æŠ¤çš„éªŒæ”¶æµ‹è¯•
éªŒè¯æ‰€æœ‰ç”¨æˆ·ç•Œé¢çš„å¯ç”¨æ€§å’Œå“åº”æ€§
"""

import unittest
import tempfile
import sqlite3
import json
import os
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# å¯¼å…¥æ‰€æœ‰éœ€è¦æµ‹è¯•çš„æ¨¡å—
from src.services.assignment_service import AssignmentService
from src.services.submission_service import SubmissionService
from src.services.classroom_grading_service import ClassroomGradingService
from src.models.assignment import Assignment
from src.models.submission import Submission, SubmissionStatus


class UserAcceptanceTestBase(unittest.TestCase):
    """ç”¨æˆ·éªŒæ”¶æµ‹è¯•åŸºç±»"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        # åˆ›å»ºä¸´æ—¶æ•°æ®åº“
        self.temp_db = tempfile.NamedTemporaryFile(delete=False, suffix='.db')
        self.temp_db.close()
        self.db_path = self.temp_db.name
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç›®å½•
        self.temp_dir = tempfile.mkdtemp()
        
        # åˆå§‹åŒ–æµ‹è¯•æ•°æ®åº“
        self._init_test_database()
        
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        self.assignment_service = AssignmentService(db_path=self.db_path)
        self.submission_service = SubmissionService(db_path=self.db_path)
        
        # åˆ›å»ºæ¨¡æ‹Ÿä¾èµ–
        self.mock_task_service = Mock()
        self.mock_grading_config_service = Mock()
        self.classroom_grading_service = ClassroomGradingService(
            db_path=self.db_path,
            task_service=self.mock_task_service,
            grading_config_service=self.mock_grading_config_service
        )
        
        # ç”¨æˆ·éªŒæ”¶æµ‹è¯•ç»“æœè®°å½•
        self.test_results = {
            'passed_scenarios': [],
            'failed_scenarios': [],
            'user_feedback': []
        }
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        try:
            Path(self.db_path).unlink(missing_ok=True)
        except:
            pass
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        try:
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except:
            pass
    
    def _init_test_database(self):
        """åˆå§‹åŒ–æµ‹è¯•æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # åˆ›å»ºå®Œæ•´çš„è¡¨ç»“æ„
        cursor.execute('''
            CREATE TABLE users (
                username TEXT PRIMARY KEY,
                password_hash TEXT NOT NULL,
                role TEXT NOT NULL,
                real_name TEXT,
                email TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                is_active BOOLEAN DEFAULT 1
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE classes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                description TEXT,
                teacher_username TEXT NOT NULL,
                invite_code TEXT UNIQUE NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                is_active BOOLEAN DEFAULT 1,
                FOREIGN KEY (teacher_username) REFERENCES users (username)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE class_members (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                class_id INTEGER NOT NULL,
                student_username TEXT NOT NULL,
                joined_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                is_active BOOLEAN DEFAULT 1,
                FOREIGN KEY (class_id) REFERENCES classes (id),
                FOREIGN KEY (student_username) REFERENCES users (username),
                UNIQUE(class_id, student_username)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE assignments (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                class_id INTEGER NOT NULL,
                title TEXT NOT NULL,
                description TEXT,
                question_files TEXT,
                marking_files TEXT,
                grading_config_id TEXT,
                auto_grading_enabled BOOLEAN DEFAULT 1,
                grading_template_id TEXT,
                deadline TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                is_active BOOLEAN DEFAULT 1,
                FOREIGN KEY (class_id) REFERENCES classes (id)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE submissions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                assignment_id INTEGER NOT NULL,
                student_username TEXT NOT NULL,
                answer_files TEXT,
                ai_result TEXT,
                teacher_feedback TEXT,
                status TEXT DEFAULT 'submitted',
                score REAL,
                task_id TEXT,
                grading_details TEXT,
                ai_confidence REAL,
                manual_review_required BOOLEAN DEFAULT 0,
                submitted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                graded_at TIMESTAMP,
                returned_at TIMESTAMP,
                FOREIGN KEY (assignment_id) REFERENCES assignments (id),
                FOREIGN KEY (student_username) REFERENCES users (username),
                UNIQUE(assignment_id, student_username)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE notifications (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                recipient_username TEXT NOT NULL,
                title TEXT NOT NULL,
                content TEXT NOT NULL,
                type TEXT DEFAULT 'info',
                is_read BOOLEAN DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (recipient_username) REFERENCES users (username)
            )
        ''')
        
        # æ’å…¥æµ‹è¯•ç”¨æˆ·æ•°æ®
        test_users = [
            ('teacher_alice', 'hash1', 'teacher', 'çˆ±ä¸½ä¸è€å¸ˆ', 'alice@school.edu'),
            ('teacher_bob', 'hash2', 'teacher', 'é²å‹ƒè€å¸ˆ', 'bob@school.edu'),
            ('student_charlie', 'hash3', 'student', 'æŸ¥ç†åŒå­¦', 'charlie@student.edu'),
            ('student_diana', 'hash4', 'student', 'æˆ´å®‰å¨œåŒå­¦', 'diana@student.edu'),
            ('student_eve', 'hash5', 'student', 'ä¼ŠèŠ™åŒå­¦', 'eve@student.edu'),
            ('admin_frank', 'hash6', 'admin', 'å¼—å…°å…‹ç®¡ç†å‘˜', 'frank@school.edu'),
        ]
        
        for username, password_hash, role, real_name, email in test_users:
            cursor.execute('''
                INSERT INTO users (username, password_hash, role, real_name, email)
                VALUES (?, ?, ?, ?, ?)
            ''', (username, password_hash, role, real_name, email))
        
        # åˆ›å»ºæµ‹è¯•ç­çº§
        cursor.execute('''
            INSERT INTO classes (id, name, description, teacher_username, invite_code)
            VALUES (1, 'é«˜ä¸­æ•°å­¦ç­', 'é«˜ä¸­æ•°å­¦è¯¾ç¨‹ç­çº§', 'teacher_alice', 'MATH001')
        ''')
        
        cursor.execute('''
            INSERT INTO classes (id, name, description, teacher_username, invite_code)
            VALUES (2, 'åˆä¸­è¯­æ–‡ç­', 'åˆä¸­è¯­æ–‡è¯¾ç¨‹ç­çº§', 'teacher_bob', 'CHIN001')
        ''')
        
        # æ·»åŠ ç­çº§æˆå‘˜
        students = ['student_charlie', 'student_diana', 'student_eve']
        for student in students:
            cursor.execute('''
                INSERT INTO class_members (class_id, student_username)
                VALUES (1, ?)
            ''', (student,))
            
            cursor.execute('''
                INSERT INTO class_members (class_id, student_username)
                VALUES (2, ?)
            ''', (student,))
        
        conn.commit()
        conn.close()
    
    def record_test_scenario(self, scenario_name, passed, details=None, user_feedback=None):
        """è®°å½•æµ‹è¯•åœºæ™¯ç»“æœ"""
        if passed:
            self.test_results['passed_scenarios'].append({
                'name': scenario_name,
                'details': details,
                'timestamp': datetime.now()
            })
        else:
            self.test_results['failed_scenarios'].append({
                'name': scenario_name,
                'details': details,
                'timestamp': datetime.now()
            })
        
        if user_feedback:
            self.test_results['user_feedback'].append({
                'scenario': scenario_name,
                'feedback': user_feedback,
                'timestamp': datetime.now()
            })
    
    def create_test_files(self, file_type="assignment"):
        """åˆ›å»ºæµ‹è¯•æ–‡ä»¶"""
        if file_type == "assignment":
            # åˆ›å»ºä½œä¸šé¢˜ç›®æ–‡ä»¶
            question_file = Path(self.temp_dir) / "question.txt"
            question_file.write_text("""
æ•°å­¦ä½œä¸šé¢˜ç›®ï¼š

1. è§£æ–¹ç¨‹ï¼š2x + 5 = 13
2. è®¡ç®—ï¼š(3 + 4) Ã— 2 - 1
3. æ±‚å‡½æ•° f(x) = xÂ² + 2x + 1 çš„æœ€å°å€¼

è¯·å†™å‡ºè¯¦ç»†çš„è§£é¢˜è¿‡ç¨‹ã€‚
            """.strip(), encoding='utf-8')
            
            # åˆ›å»ºæ‰¹æ”¹æ ‡å‡†æ–‡ä»¶
            rubric_file = Path(self.temp_dir) / "rubric.txt"
            rubric_file.write_text("""
æ‰¹æ”¹æ ‡å‡†ï¼š

1. è§£æ–¹ç¨‹ (30åˆ†)
   - æ­£ç¡®ç§»é¡¹ï¼š10åˆ†
   - æ­£ç¡®è®¡ç®—ï¼š10åˆ†
   - æœ€ç»ˆç­”æ¡ˆæ­£ç¡®ï¼š10åˆ†

2. è®¡ç®—é¢˜ (30åˆ†)
   - è¿ç®—é¡ºåºæ­£ç¡®ï¼š15åˆ†
   - è®¡ç®—ç»“æœæ­£ç¡®ï¼š15åˆ†

3. å‡½æ•°é¢˜ (40åˆ†)
   - é…æ–¹æ³•æˆ–æ±‚å¯¼ï¼š20åˆ†
   - æœ€å°å€¼è®¡ç®—ï¼š20åˆ†

æ€»åˆ†ï¼š100åˆ†
            """.strip(), encoding='utf-8')
            
            return [str(question_file)], [str(rubric_file)]
        
        elif file_type == "student_answer":
            # åˆ›å»ºå­¦ç”Ÿç­”æ¡ˆæ–‡ä»¶
            answer_file = Path(self.temp_dir) / "student_answer.txt"
            answer_file.write_text("""
å­¦ç”Ÿç­”æ¡ˆï¼š

1. è§£æ–¹ç¨‹ï¼š2x + 5 = 13
   2x = 13 - 5
   2x = 8
   x = 4

2. è®¡ç®—ï¼š(3 + 4) Ã— 2 - 1
   = 7 Ã— 2 - 1
   = 14 - 1
   = 13

3. æ±‚å‡½æ•° f(x) = xÂ² + 2x + 1 çš„æœ€å°å€¼
   f(x) = xÂ² + 2x + 1 = (x + 1)Â²
   å½“ x = -1 æ—¶ï¼Œf(x) å–æœ€å°å€¼ 0
            """.strip(), encoding='utf-8')
            
            return [str(answer_file)]


class TeacherWorkflowAcceptanceTests(UserAcceptanceTestBase):
    """æ•™å¸ˆç”¨æˆ·å®Œæ•´å·¥ä½œæµç¨‹éªŒæ”¶æµ‹è¯•"""
    
    def test_teacher_complete_workflow(self):
        """æµ‹è¯•æ•™å¸ˆå®Œæ•´å·¥ä½œæµç¨‹"""
        print("\nğŸ‘©â€ğŸ« æ•™å¸ˆç”¨æˆ·å®Œæ•´å·¥ä½œæµç¨‹éªŒæ”¶æµ‹è¯•")
        print("=" * 50)
        
        teacher_username = "teacher_alice"
        class_id = 1
        
        # åœºæ™¯1ï¼šæ•™å¸ˆç™»å½•å’ŒæŸ¥çœ‹ç­çº§
        print("\nğŸ“‹ åœºæ™¯1ï¼šæ•™å¸ˆç™»å½•å’ŒæŸ¥çœ‹ç­çº§")
        try:
            # æ¨¡æ‹Ÿæ•™å¸ˆæŸ¥çœ‹ç­çº§åˆ—è¡¨
            assignments = self.assignment_service.get_class_assignments(class_id)
            initial_assignment_count = len(assignments)
            
            print(f"âœ… æ•™å¸ˆæˆåŠŸæŸ¥çœ‹ç­çº§ï¼Œå½“å‰ä½œä¸šæ•°é‡: {initial_assignment_count}")
            self.record_test_scenario(
                "æ•™å¸ˆç™»å½•å’ŒæŸ¥çœ‹ç­çº§",
                True,
                f"æˆåŠŸæŸ¥çœ‹ç­çº§ï¼Œä½œä¸šæ•°é‡: {initial_assignment_count}"
            )
        except Exception as e:
            print(f"âŒ æ•™å¸ˆæŸ¥çœ‹ç­çº§å¤±è´¥: {e}")
            self.record_test_scenario("æ•™å¸ˆç™»å½•å’ŒæŸ¥çœ‹ç­çº§", False, str(e))
            return
        
        # åœºæ™¯2ï¼šåˆ›å»ºæ–°ä½œä¸š
        print("\nğŸ“ åœºæ™¯2ï¼šåˆ›å»ºæ–°ä½œä¸š")
        try:
            question_files, marking_files = self.create_test_files("assignment")
            
            assignment_id = self.assignment_service.create_assignment(
                class_id=class_id,
                title="æœŸä¸­æ•°å­¦æµ‹è¯•",
                description="æœ¬æ¬¡æµ‹è¯•æ¶µç›–æ–¹ç¨‹ã€è®¡ç®—å’Œå‡½æ•°ç­‰å†…å®¹ï¼Œè¯·è®¤çœŸä½œç­”ã€‚",
                question_files=question_files,
                marking_files=marking_files,
                auto_grading_enabled=True,
                deadline=datetime.now() + timedelta(days=7)
            )
            
            self.assertIsNotNone(assignment_id)
            print(f"âœ… æ•™å¸ˆæˆåŠŸåˆ›å»ºä½œä¸šï¼Œä½œä¸šID: {assignment_id}")
            
            # éªŒè¯ä½œä¸šåˆ›å»ºæˆåŠŸ
            assignment = self.assignment_service.get_assignment_by_id(assignment_id)
            self.assertEqual(assignment.title, "æœŸä¸­æ•°å­¦æµ‹è¯•")
            self.assertTrue(assignment.auto_grading_enabled)
            
            self.record_test_scenario(
                "åˆ›å»ºæ–°ä½œä¸š",
                True,
                f"æˆåŠŸåˆ›å»ºä½œä¸š: {assignment.title}ï¼ŒID: {assignment_id}"
            )
        except Exception as e:
            print(f"âŒ åˆ›å»ºä½œä¸šå¤±è´¥: {e}")
            self.record_test_scenario("åˆ›å»ºæ–°ä½œä¸š", False, str(e))
            return
        
        # åœºæ™¯3ï¼šæŸ¥çœ‹ä½œä¸šç»Ÿè®¡
        print("\nğŸ“Š åœºæ™¯3ï¼šæŸ¥çœ‹ä½œä¸šç»Ÿè®¡")
        try:
            stats = self.assignment_service.get_assignment_statistics(assignment_id)
            
            print(f"âœ… ä½œä¸šç»Ÿè®¡ä¿¡æ¯:")
            print(f"   - ç­çº§å­¦ç”Ÿæ€»æ•°: {stats['total_students']}")
            print(f"   - æäº¤æ•°é‡: {stats['total_submissions']}")
            print(f"   - æäº¤ç‡: {stats['submission_rate']:.1f}%")
            
            self.assertIn('total_students', stats)
            self.assertIn('total_submissions', stats)
            self.assertIn('submission_rate', stats)
            
            self.record_test_scenario(
                "æŸ¥çœ‹ä½œä¸šç»Ÿè®¡",
                True,
                f"æˆåŠŸè·å–ç»Ÿè®¡ä¿¡æ¯ï¼Œå­¦ç”Ÿæ•°: {stats['total_students']}"
            )
        except Exception as e:
            print(f"âŒ æŸ¥çœ‹ä½œä¸šç»Ÿè®¡å¤±è´¥: {e}")
            self.record_test_scenario("æŸ¥çœ‹ä½œä¸šç»Ÿè®¡", False, str(e))
        
        # åœºæ™¯4ï¼šç­‰å¾…å­¦ç”Ÿæäº¤ï¼ˆæ¨¡æ‹Ÿå­¦ç”Ÿæäº¤ï¼‰
        print("\nğŸ‘¥ åœºæ™¯4ï¼šå­¦ç”Ÿæäº¤ä½œä¸šï¼ˆæ¨¡æ‹Ÿï¼‰")
        students = ['student_charlie', 'student_diana', 'student_eve']
        submitted_students = []
        
        for student in students:
            try:
                answer_files = self.create_test_files("student_answer")
                
                success = self.submission_service.submit_assignment(
                    assignment_id=assignment_id,
                    student_username=student,
                    answer_files=answer_files
                )
                
                if success:
                    submitted_students.append(student)
                    print(f"âœ… å­¦ç”Ÿ {student} æˆåŠŸæäº¤ä½œä¸š")
                else:
                    print(f"âŒ å­¦ç”Ÿ {student} æäº¤ä½œä¸šå¤±è´¥")
            except Exception as e:
                print(f"âŒ å­¦ç”Ÿ {student} æäº¤ä½œä¸šå¼‚å¸¸: {e}")
        
        self.record_test_scenario(
            "å­¦ç”Ÿæäº¤ä½œä¸š",
            len(submitted_students) > 0,
            f"æˆåŠŸæäº¤å­¦ç”Ÿæ•°: {len(submitted_students)}/{len(students)}"
        )
        
        # åœºæ™¯5ï¼šæŸ¥çœ‹å­¦ç”Ÿæäº¤åˆ—è¡¨
        print("\nğŸ“‹ åœºæ™¯5ï¼šæŸ¥çœ‹å­¦ç”Ÿæäº¤åˆ—è¡¨")
        try:
            submissions = self.submission_service.get_assignment_submissions(assignment_id)
            
            print(f"âœ… æ•™å¸ˆæŸ¥çœ‹æäº¤åˆ—è¡¨:")
            for submission in submissions:
                print(f"   - {submission.student_username}: {submission.status.value}")
            
            self.assertEqual(len(submissions), len(submitted_students))
            
            self.record_test_scenario(
                "æŸ¥çœ‹å­¦ç”Ÿæäº¤åˆ—è¡¨",
                True,
                f"æˆåŠŸæŸ¥çœ‹ {len(submissions)} ä¸ªæäº¤"
            )
        except Exception as e:
            print(f"âŒ æŸ¥çœ‹æäº¤åˆ—è¡¨å¤±è´¥: {e}")
            self.record_test_scenario("æŸ¥çœ‹å­¦ç”Ÿæäº¤åˆ—è¡¨", False, str(e))
        
        # åœºæ™¯6ï¼šè§¦å‘è‡ªåŠ¨æ‰¹æ”¹
        print("\nğŸ¤– åœºæ™¯6ï¼šè§¦å‘è‡ªåŠ¨æ‰¹æ”¹")
        self.mock_task_service.create_task.return_value = 'batch_task_123'
        
        graded_count = 0
        for student in submitted_students:
            try:
                submission = self.submission_service.get_submission(assignment_id, student)
                
                # è§¦å‘è‡ªåŠ¨æ‰¹æ”¹
                task_id = self.classroom_grading_service.trigger_auto_grading(submission)
                
                # æ¨¡æ‹ŸAIæ‰¹æ”¹å®Œæˆ
                success = self.submission_service.update_submission_grading_result(
                    submission.id,
                    score=85.0 + (graded_count * 5),  # ä¸åŒå­¦ç”Ÿä¸åŒåˆ†æ•°
                    feedback=f"AIæ‰¹æ”¹ï¼š{student}çš„ä½œä¸šå®Œæˆè´¨é‡è‰¯å¥½ï¼Œé€»è¾‘æ¸…æ™°ã€‚",
                    confidence=0.9,
                    criteria_scores={'è§£æ–¹ç¨‹': 28, 'è®¡ç®—é¢˜': 30, 'å‡½æ•°é¢˜': 35},
                    suggestions=['ç»§ç»­ä¿æŒ', 'æ³¨æ„è®¡ç®—ç»†èŠ‚'],
                    task_id=task_id
                )
                
                if success:
                    graded_count += 1
                    print(f"âœ… {student} è‡ªåŠ¨æ‰¹æ”¹å®Œæˆï¼Œåˆ†æ•°: {85.0 + ((graded_count-1) * 5)}")
                
            except Exception as e:
                print(f"âŒ {student} è‡ªåŠ¨æ‰¹æ”¹å¤±è´¥: {e}")
        
        self.record_test_scenario(
            "è§¦å‘è‡ªåŠ¨æ‰¹æ”¹",
            graded_count > 0,
            f"æˆåŠŸæ‰¹æ”¹ {graded_count}/{len(submitted_students)} ä¸ªæäº¤"
        )
        
        # åœºæ™¯7ï¼šæ•™å¸ˆå®¡æ ¸å’Œä¿®æ”¹æ‰¹æ”¹ç»“æœ
        print("\nâœï¸ åœºæ™¯7ï¼šæ•™å¸ˆå®¡æ ¸å’Œä¿®æ”¹æ‰¹æ”¹ç»“æœ")
        reviewed_count = 0
        
        for student in submitted_students[:2]:  # åªå®¡æ ¸å‰ä¸¤ä¸ªå­¦ç”Ÿ
            try:
                submission = self.submission_service.get_submission(assignment_id, student)
                
                # æ•™å¸ˆä¿®æ”¹åé¦ˆå’Œåˆ†æ•°
                success = self.submission_service.update_submission_feedback(
                    submission.id,
                    teacher_feedback=f"æ•™å¸ˆåé¦ˆï¼š{student}çš„ä½œä¸šå®Œæˆå¾—å¾ˆå¥½ï¼è§£é¢˜æ€è·¯æ¸…æ™°ï¼Œè®¡ç®—å‡†ç¡®ã€‚å»ºè®®åœ¨å‡½æ•°é¢˜éƒ¨åˆ†å¤šåŠ ç»ƒä¹ ã€‚",
                    score=submission.score + 2  # æ•™å¸ˆç»™äºˆé¢å¤–2åˆ†
                )
                
                if success:
                    reviewed_count += 1
                    print(f"âœ… æ•™å¸ˆå®Œæˆ {student} çš„å®¡æ ¸ï¼Œè°ƒæ•´ååˆ†æ•°: {submission.score + 2}")
                
            except Exception as e:
                print(f"âŒ æ•™å¸ˆå®¡æ ¸ {student} å¤±è´¥: {e}")
        
        self.record_test_scenario(
            "æ•™å¸ˆå®¡æ ¸å’Œä¿®æ”¹æ‰¹æ”¹ç»“æœ",
            reviewed_count > 0,
            f"æˆåŠŸå®¡æ ¸ {reviewed_count} ä¸ªæäº¤"
        )
        
        # åœºæ™¯8ï¼šæŸ¥çœ‹æœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š
        print("\nğŸ“ˆ åœºæ™¯8ï¼šæŸ¥çœ‹æœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š")
        try:
            final_stats = self.assignment_service.get_assignment_statistics(assignment_id)
            submission_stats = self.submission_service.get_submission_statistics(assignment_id=assignment_id)
            
            print(f"âœ… æœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š:")
            print(f"   - æäº¤ç‡: {final_stats['submission_rate']:.1f}%")
            print(f"   - å¹³å‡åˆ†: {submission_stats.get('average_score', 0):.1f}")
            print(f"   - AIæ‰¹æ”¹æ•°: {submission_stats.get('ai_graded_submissions', 0)}")
            print(f"   - æ•™å¸ˆå®¡æ ¸æ•°: {submission_stats.get('teacher_reviewed_submissions', 0)}")
            
            self.record_test_scenario(
                "æŸ¥çœ‹æœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š",
                True,
                f"æäº¤ç‡: {final_stats['submission_rate']:.1f}%, å¹³å‡åˆ†: {submission_stats.get('average_score', 0):.1f}"
            )
        except Exception as e:
            print(f"âŒ æŸ¥çœ‹æœ€ç»ˆç»Ÿè®¡å¤±è´¥: {e}")
            self.record_test_scenario("æŸ¥çœ‹æœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š", False, str(e))
        
        # è¾“å‡ºæ•™å¸ˆå·¥ä½œæµç¨‹æµ‹è¯•æ€»ç»“
        print(f"\nğŸ“‹ æ•™å¸ˆå·¥ä½œæµç¨‹æµ‹è¯•æ€»ç»“:")
        print(f"âœ… é€šè¿‡åœºæ™¯: {len(self.test_results['passed_scenarios'])}")
        print(f"âŒ å¤±è´¥åœºæ™¯: {len(self.test_results['failed_scenarios'])}")
        
        # éªŒè¯å…³é”®åœºæ™¯éƒ½é€šè¿‡
        passed_scenario_names = [s['name'] for s in self.test_results['passed_scenarios']]
        critical_scenarios = ["åˆ›å»ºæ–°ä½œä¸š", "æŸ¥çœ‹å­¦ç”Ÿæäº¤åˆ—è¡¨", "è§¦å‘è‡ªåŠ¨æ‰¹æ”¹"]
        
        for scenario in critical_scenarios:
            self.assertIn(scenario, passed_scenario_names, f"å…³é”®åœºæ™¯ '{scenario}' å¿…é¡»é€šè¿‡")
        
        print("ğŸ‰ æ•™å¸ˆç”¨æˆ·å®Œæ•´å·¥ä½œæµç¨‹éªŒæ”¶æµ‹è¯•é€šè¿‡ï¼")
    
    def test_teacher_advanced_features(self):
        """æµ‹è¯•æ•™å¸ˆé«˜çº§åŠŸèƒ½"""
        print("\nğŸ‘©â€ğŸ« æ•™å¸ˆé«˜çº§åŠŸèƒ½éªŒæ”¶æµ‹è¯•")
        print("=" * 50)
        
        # åœºæ™¯1ï¼šæ‰¹é‡æ“ä½œ
        print("\nğŸ“¦ åœºæ™¯1ï¼šæ‰¹é‡æ“ä½œæµ‹è¯•")
        try:
            # åˆ›å»ºå¤šä¸ªä½œä¸š
            assignment_ids = []
            for i in range(3):
                assignment_id = self.assignment_service.create_assignment(
                    class_id=1,
                    title=f"æ‰¹é‡æµ‹è¯•ä½œä¸š{i+1}",
                    description=f"ç¬¬{i+1}ä¸ªæ‰¹é‡æµ‹è¯•ä½œä¸š"
                )
                assignment_ids.append(assignment_id)
            
            # æ‰¹é‡æŸ¥çœ‹ä½œä¸š
            assignments = self.assignment_service.get_class_assignments(1)
            batch_assignments = [a for a in assignments if a.title.startswith("æ‰¹é‡æµ‹è¯•")]
            
            self.assertEqual(len(batch_assignments), 3)
            print(f"âœ… æˆåŠŸåˆ›å»ºå’ŒæŸ¥çœ‹ {len(batch_assignments)} ä¸ªæ‰¹é‡ä½œä¸š")
            
            self.record_test_scenario("æ‰¹é‡æ“ä½œ", True, f"æˆåŠŸå¤„ç† {len(batch_assignments)} ä¸ªä½œä¸š")
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡æ“ä½œå¤±è´¥: {e}")
            self.record_test_scenario("æ‰¹é‡æ“ä½œ", False, str(e))
        
        # åœºæ™¯2ï¼šæœç´¢å’Œç­›é€‰
        print("\nğŸ” åœºæ™¯2ï¼šæœç´¢å’Œç­›é€‰æµ‹è¯•")
        try:
            # æœç´¢ä½œä¸š
            search_results = self.assignment_service.search_assignments(keyword="æ‰¹é‡")
            self.assertGreater(len(search_results), 0)
            
            # æŒ‰æ•™å¸ˆç­›é€‰
            teacher_assignments = self.assignment_service.search_assignments(teacher_username="teacher_alice")
            self.assertGreater(len(teacher_assignments), 0)
            
            print(f"âœ… æœç´¢åŠŸèƒ½æ­£å¸¸ï¼Œæ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³ä½œä¸š")
            self.record_test_scenario("æœç´¢å’Œç­›é€‰", True, f"æœç´¢ç»“æœ: {len(search_results)} ä¸ª")
            
        except Exception as e:
            print(f"âŒ æœç´¢å’Œç­›é€‰å¤±è´¥: {e}")
            self.record_test_scenario("æœç´¢å’Œç­›é€‰", False, str(e))


class StudentWorkflowAcceptanceTests(UserAcceptanceTestBase):
    """å­¦ç”Ÿç”¨æˆ·å®Œæ•´å·¥ä½œæµç¨‹éªŒæ”¶æµ‹è¯•"""
    
    def test_student_complete_workflow(self):
        """æµ‹è¯•å­¦ç”Ÿå®Œæ•´å·¥ä½œæµç¨‹"""
        print("\nğŸ‘¨â€ğŸ“ å­¦ç”Ÿç”¨æˆ·å®Œæ•´å·¥ä½œæµç¨‹éªŒæ”¶æµ‹è¯•")
        print("=" * 50)
        
        student_username = "student_charlie"
        
        # å‡†å¤‡æµ‹è¯•ç¯å¢ƒï¼šæ•™å¸ˆå…ˆåˆ›å»ºä½œä¸š
        question_files, marking_files = self.create_test_files("assignment")
        assignment_id = self.assignment_service.create_assignment(
            class_id=1,
            title="å­¦ç”Ÿæµ‹è¯•ä½œä¸š",
            description="ç”¨äºå­¦ç”Ÿå·¥ä½œæµç¨‹æµ‹è¯•çš„ä½œä¸š",
            question_files=question_files,
            marking_files=marking_files,
            auto_grading_enabled=True,
            deadline=datetime.now() + timedelta(days=3)
        )
        
        # åœºæ™¯1ï¼šå­¦ç”Ÿç™»å½•å’ŒæŸ¥çœ‹ä½œä¸šåˆ—è¡¨
        print("\nğŸ“š åœºæ™¯1ï¼šå­¦ç”Ÿç™»å½•å’ŒæŸ¥çœ‹ä½œä¸šåˆ—è¡¨")
        try:
            assignments = self.assignment_service.get_student_assignments(student_username, class_id=1)
            
            print(f"âœ… å­¦ç”ŸæˆåŠŸæŸ¥çœ‹ä½œä¸šåˆ—è¡¨ï¼Œå…± {len(assignments)} ä¸ªä½œä¸š")
            for assignment in assignments:
                print(f"   - {assignment.title}: {assignment.status if hasattr(assignment, 'status') else 'æœªæäº¤'}")
            
            self.assertGreater(len(assignments), 0)
            self.record_test_scenario(
                "å­¦ç”ŸæŸ¥çœ‹ä½œä¸šåˆ—è¡¨",
                True,
                f"æˆåŠŸæŸ¥çœ‹ {len(assignments)} ä¸ªä½œä¸š"
            )
            
        except Exception as e:
            print(f"âŒ å­¦ç”ŸæŸ¥çœ‹ä½œä¸šåˆ—è¡¨å¤±è´¥: {e}")
            self.record_test_scenario("å­¦ç”ŸæŸ¥çœ‹ä½œä¸šåˆ—è¡¨", False, str(e))
            return
        
        # åœºæ™¯2ï¼šæŸ¥çœ‹ä½œä¸šè¯¦æƒ…
        print("\nğŸ“– åœºæ™¯2ï¼šæŸ¥çœ‹ä½œä¸šè¯¦æƒ…")
        try:
            assignment = self.assignment_service.get_assignment_by_id(assignment_id)
            
            print(f"âœ… å­¦ç”ŸæŸ¥çœ‹ä½œä¸šè¯¦æƒ…:")
            print(f"   - æ ‡é¢˜: {assignment.title}")
            print(f"   - æè¿°: {assignment.description}")
            print(f"   - æˆªæ­¢æ—¶é—´: {assignment.deadline}")
            print(f"   - é¢˜ç›®æ–‡ä»¶æ•°: {len(assignment.question_files)}")
            
            self.assertIsNotNone(assignment)
            self.assertEqual(assignment.title, "å­¦ç”Ÿæµ‹è¯•ä½œä¸š")
            
            self.record_test_scenario(
                "æŸ¥çœ‹ä½œä¸šè¯¦æƒ…",
                True,
                f"æˆåŠŸæŸ¥çœ‹ä½œä¸š: {assignment.title}"
            )
            
        except Exception as e:
            print(f"âŒ æŸ¥çœ‹ä½œä¸šè¯¦æƒ…å¤±è´¥: {e}")
            self.record_test_scenario("æŸ¥çœ‹ä½œä¸šè¯¦æƒ…", False, str(e))
        
        # åœºæ™¯3ï¼šå‡†å¤‡å’Œä¸Šä¼ ç­”æ¡ˆæ–‡ä»¶
        print("\nğŸ“ åœºæ™¯3ï¼šå‡†å¤‡å’Œä¸Šä¼ ç­”æ¡ˆæ–‡ä»¶")
        try:
            answer_files = self.create_test_files("student_answer")
            
            print(f"âœ… å­¦ç”Ÿå‡†å¤‡ç­”æ¡ˆæ–‡ä»¶:")
            for file_path in answer_files:
                file_size = Path(file_path).stat().st_size
                print(f"   - {Path(file_path).name}: {file_size} å­—èŠ‚")
            
            self.assertEqual(len(answer_files), 1)
            self.assertGreater(Path(answer_files[0]).stat().st_size, 0)
            
            self.record_test_scenario(
                "å‡†å¤‡ç­”æ¡ˆæ–‡ä»¶",
                True,
                f"æˆåŠŸå‡†å¤‡ {len(answer_files)} ä¸ªç­”æ¡ˆæ–‡ä»¶"
            )
            
        except Exception as e:
            print(f"âŒ å‡†å¤‡ç­”æ¡ˆæ–‡ä»¶å¤±è´¥: {e}")
            self.record_test_scenario("å‡†å¤‡ç­”æ¡ˆæ–‡ä»¶", False, str(e))
            return
        
        # åœºæ™¯4ï¼šæäº¤ä½œä¸š
        print("\nğŸ“¤ åœºæ™¯4ï¼šæäº¤ä½œä¸š")
        try:
            success = self.submission_service.submit_assignment(
                assignment_id=assignment_id,
                student_username=student_username,
                answer_files=answer_files
            )
            
            self.assertTrue(success)
            print(f"âœ… å­¦ç”ŸæˆåŠŸæäº¤ä½œä¸š")
            
            # éªŒè¯æäº¤è®°å½•
            submission = self.submission_service.get_submission(assignment_id, student_username)
            self.assertIsNotNone(submission)
            self.assertEqual(submission.status, SubmissionStatus.SUBMITTED)
            
            self.record_test_scenario(
                "æäº¤ä½œä¸š",
                True,
                f"æˆåŠŸæäº¤ä½œä¸šï¼ŒçŠ¶æ€: {submission.status.value}"
            )
            
        except Exception as e:
            print(f"âŒ æäº¤ä½œä¸šå¤±è´¥: {e}")
            self.record_test_scenario("æäº¤ä½œä¸š", False, str(e))
            return
        
        # åœºæ™¯5ï¼šæŸ¥çœ‹æäº¤çŠ¶æ€
        print("\nğŸ“Š åœºæ™¯5ï¼šæŸ¥çœ‹æäº¤çŠ¶æ€")
        try:
            submission = self.submission_service.get_submission(assignment_id, student_username)
            
            print(f"âœ… å­¦ç”ŸæŸ¥çœ‹æäº¤çŠ¶æ€:")
            print(f"   - æäº¤çŠ¶æ€: {submission.status.value}")
            print(f"   - æäº¤æ—¶é—´: {submission.submitted_at}")
            print(f"   - æ–‡ä»¶æ•°é‡: {len(submission.answer_files)}")
            
            self.assertEqual(submission.status, SubmissionStatus.SUBMITTED)
            self.record_test_scenario(
                "æŸ¥çœ‹æäº¤çŠ¶æ€",
                True,
                f"æäº¤çŠ¶æ€: {submission.status.value}"
            )
            
        except Exception as e:
            print(f"âŒ æŸ¥çœ‹æäº¤çŠ¶æ€å¤±è´¥: {e}")
            self.record_test_scenario("æŸ¥çœ‹æäº¤çŠ¶æ€", False, str(e))
        
        # åœºæ™¯6ï¼šç­‰å¾…æ‰¹æ”¹å®Œæˆï¼ˆæ¨¡æ‹ŸAIæ‰¹æ”¹ï¼‰
        print("\nâ³ åœºæ™¯6ï¼šç­‰å¾…æ‰¹æ”¹å®Œæˆï¼ˆæ¨¡æ‹ŸAIæ‰¹æ”¹ï¼‰")
        try:
            self.mock_task_service.create_task.return_value = 'student_task_123'
            
            # è§¦å‘è‡ªåŠ¨æ‰¹æ”¹
            task_id = self.classroom_grading_service.trigger_auto_grading(submission)
            
            # æ¨¡æ‹ŸAIæ‰¹æ”¹å®Œæˆ
            success = self.submission_service.update_submission_grading_result(
                submission.id,
                score=88.0,
                feedback="AIæ‰¹æ”¹ï¼šä½œä¸šå®Œæˆè´¨é‡ä¼˜ç§€ï¼è§£é¢˜æ­¥éª¤æ¸…æ™°ï¼Œç­”æ¡ˆæ­£ç¡®ã€‚",
                confidence=0.92,
                criteria_scores={'è§£æ–¹ç¨‹': 30, 'è®¡ç®—é¢˜': 28, 'å‡½æ•°é¢˜': 38},
                suggestions=['ç»§ç»­ä¿æŒä¼˜ç§€æ°´å¹³', 'å¯ä»¥å°è¯•æ›´å¤šæŒ‘æˆ˜æ€§é¢˜ç›®'],
                task_id=task_id
            )
            
            self.assertTrue(success)
            print(f"âœ… AIæ‰¹æ”¹å®Œæˆï¼Œåˆ†æ•°: 88.0")
            
            self.record_test_scenario(
                "AIæ‰¹æ”¹å®Œæˆ",
                True,
                "AIæ‰¹æ”¹æˆåŠŸï¼Œåˆ†æ•°: 88.0"
            )
            
        except Exception as e:
            print(f"âŒ AIæ‰¹æ”¹å¤±è´¥: {e}")
            self.record_test_scenario("AIæ‰¹æ”¹å®Œæˆ", False, str(e))
        
        # åœºæ™¯7ï¼šæŸ¥çœ‹æ‰¹æ”¹ç»“æœ
        print("\nğŸ¯ åœºæ™¯7ï¼šæŸ¥çœ‹æ‰¹æ”¹ç»“æœ")
        try:
            graded_submission = self.submission_service.get_submission(assignment_id, student_username)
            
            print(f"âœ… å­¦ç”ŸæŸ¥çœ‹æ‰¹æ”¹ç»“æœ:")
            print(f"   - æœ€ç»ˆåˆ†æ•°: {graded_submission.score}")
            print(f"   - æ‰¹æ”¹çŠ¶æ€: {graded_submission.status.value}")
            print(f"   - AIåé¦ˆ: {graded_submission.ai_result}")
            print(f"   - AIç½®ä¿¡åº¦: {graded_submission.ai_confidence}")
            
            self.assertEqual(graded_submission.status, SubmissionStatus.AI_GRADED)
            self.assertEqual(graded_submission.score, 88.0)
            self.assertIsNotNone(graded_submission.ai_result)
            
            self.record_test_scenario(
                "æŸ¥çœ‹æ‰¹æ”¹ç»“æœ",
                True,
                f"åˆ†æ•°: {graded_submission.score}, çŠ¶æ€: {graded_submission.status.value}"
            )
            
        except Exception as e:
            print(f"âŒ æŸ¥çœ‹æ‰¹æ”¹ç»“æœå¤±è´¥: {e}")
            self.record_test_scenario("æŸ¥çœ‹æ‰¹æ”¹ç»“æœ", False, str(e))
        
        # åœºæ™¯8ï¼šæŸ¥çœ‹æäº¤å†å²
        print("\nğŸ“š åœºæ™¯8ï¼šæŸ¥çœ‹æäº¤å†å²")
        try:
            history = self.submission_service.get_submission_history(student_username)
            
            print(f"âœ… å­¦ç”ŸæŸ¥çœ‹æäº¤å†å²:")
            for submission in history:
                print(f"   - {submission.assignment_title}: {submission.score or 'æœªæ‰¹æ”¹'} åˆ†")
            
            self.assertGreater(len(history), 0)
            self.record_test_scenario(
                "æŸ¥çœ‹æäº¤å†å²",
                True,
                f"å†å²è®°å½•æ•°: {len(history)}"
            )
            
        except Exception as e:
            print(f"âŒ æŸ¥çœ‹æäº¤å†å²å¤±è´¥: {e}")
            self.record_test_scenario("æŸ¥çœ‹æäº¤å†å²", False, str(e))
        
        # è¾“å‡ºå­¦ç”Ÿå·¥ä½œæµç¨‹æµ‹è¯•æ€»ç»“
        print(f"\nğŸ“‹ å­¦ç”Ÿå·¥ä½œæµç¨‹æµ‹è¯•æ€»ç»“:")
        print(f"âœ… é€šè¿‡åœºæ™¯: {len(self.test_results['passed_scenarios'])}")
        print(f"âŒ å¤±è´¥åœºæ™¯: {len(self.test_results['failed_scenarios'])}")
        
        # éªŒè¯å…³é”®åœºæ™¯éƒ½é€šè¿‡
        passed_scenario_names = [s['name'] for s in self.test_results['passed_scenarios']]
        critical_scenarios = ["æäº¤ä½œä¸š", "æŸ¥çœ‹æ‰¹æ”¹ç»“æœ", "æŸ¥çœ‹æäº¤å†å²"]
        
        for scenario in critical_scenarios:
            self.assertIn(scenario, passed_scenario_names, f"å…³é”®åœºæ™¯ '{scenario}' å¿…é¡»é€šè¿‡")
        
        print("ğŸ‰ å­¦ç”Ÿç”¨æˆ·å®Œæ•´å·¥ä½œæµç¨‹éªŒæ”¶æµ‹è¯•é€šè¿‡ï¼")
    
    def test_student_edge_cases(self):
        """æµ‹è¯•å­¦ç”Ÿè¾¹ç¼˜æƒ…å†µ"""
        print("\nğŸ‘¨â€ğŸ“ å­¦ç”Ÿè¾¹ç¼˜æƒ…å†µéªŒæ”¶æµ‹è¯•")
        print("=" * 50)
        
        student_username = "student_diana"
        
        # åœºæ™¯1ï¼šé‡å¤æäº¤æµ‹è¯•
        print("\nğŸ”„ åœºæ™¯1ï¼šé‡å¤æäº¤æµ‹è¯•")
        try:
            # åˆ›å»ºæµ‹è¯•ä½œä¸š
            assignment_id = self.assignment_service.create_assignment(
                class_id=1,
                title="é‡å¤æäº¤æµ‹è¯•ä½œä¸š",
                description="ç”¨äºæµ‹è¯•é‡å¤æäº¤åŠŸèƒ½"
            )
            
            answer_files = self.create_test_files("student_answer")
            
            # ç¬¬ä¸€æ¬¡æäº¤
            success1 = self.submission_service.submit_assignment(
                assignment_id=assignment_id,
                student_username=student_username,
                answer_files=answer_files
            )
            
            # ç¬¬äºŒæ¬¡æäº¤ï¼ˆåº”è¯¥è¦†ç›–ç¬¬ä¸€æ¬¡ï¼‰
            success2 = self.submission_service.submit_assignment(
                assignment_id=assignment_id,
                student_username=student_username,
                answer_files=answer_files
            )
            
            self.assertTrue(success1)
            self.assertTrue(success2)
            
            # éªŒè¯åªæœ‰ä¸€ä¸ªæäº¤è®°å½•
            submissions = self.submission_service.get_assignment_submissions(assignment_id)
            student_submissions = [s for s in submissions if s.student_username == student_username]
            self.assertEqual(len(student_submissions), 1)
            
            print("âœ… é‡å¤æäº¤å¤„ç†æ­£ç¡®ï¼Œç¬¬äºŒæ¬¡æäº¤è¦†ç›–ç¬¬ä¸€æ¬¡")
            self.record_test_scenario("é‡å¤æäº¤æµ‹è¯•", True, "é‡å¤æäº¤å¤„ç†æ­£ç¡®")
            
        except Exception as e:
            print(f"âŒ é‡å¤æäº¤æµ‹è¯•å¤±è´¥: {e}")
            self.record_test_scenario("é‡å¤æäº¤æµ‹è¯•", False, str(e))
        
        # åœºæ™¯2ï¼šè¿‡æœŸä½œä¸šæäº¤æµ‹è¯•
        print("\nâ° åœºæ™¯2ï¼šè¿‡æœŸä½œä¸šæäº¤æµ‹è¯•")
        try:
            # åˆ›å»ºå·²è¿‡æœŸçš„ä½œä¸š
            expired_assignment_id = self.assignment_service.create_assignment(
                class_id=1,
                title="è¿‡æœŸä½œä¸šæµ‹è¯•",
                description="ç”¨äºæµ‹è¯•è¿‡æœŸæäº¤",
                deadline=datetime.now() - timedelta(days=1)  # æ˜¨å¤©æˆªæ­¢
            )
            
            answer_files = self.create_test_files("student_answer")
            
            # å°è¯•æäº¤è¿‡æœŸä½œä¸š
            success = self.submission_service.submit_assignment(
                assignment_id=expired_assignment_id,
                student_username=student_username,
                answer_files=answer_files
            )
            
            # ç³»ç»Ÿåº”è¯¥å…è®¸è¿‡æœŸæäº¤ï¼Œä½†æ ‡è®°ä¸ºè¿Ÿäº¤
            self.assertTrue(success)
            
            submission = self.submission_service.get_submission(expired_assignment_id, student_username)
            self.assertIsNotNone(submission)
            
            print("âœ… è¿‡æœŸä½œä¸šæäº¤å¤„ç†æ­£ç¡®ï¼Œå…è®¸è¿Ÿäº¤")
            self.record_test_scenario("è¿‡æœŸä½œä¸šæäº¤", True, "å…è®¸è¿‡æœŸæäº¤")
            
        except Exception as e:
            print(f"âŒ è¿‡æœŸä½œä¸šæäº¤æµ‹è¯•å¤±è´¥: {e}")
            self.record_test_scenario("è¿‡æœŸä½œä¸šæäº¤", False, str(e))


class SystemAdminAcceptanceTests(UserAcceptanceTestBase):
    """ç³»ç»Ÿç®¡ç†å‘˜ç›‘æ§å’Œç»´æŠ¤éªŒæ”¶æµ‹è¯•"""
    
    def test_system_monitoring_workflow(self):
        """æµ‹è¯•ç³»ç»Ÿç›‘æ§å·¥ä½œæµç¨‹"""
        print("\nğŸ‘¨â€ğŸ’¼ ç³»ç»Ÿç®¡ç†å‘˜ç›‘æ§å’Œç»´æŠ¤éªŒæ”¶æµ‹è¯•")
        print("=" * 50)
        
        admin_username = "admin_frank"
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        self._prepare_monitoring_test_data()
        
        # åœºæ™¯1ï¼šç³»ç»Ÿæ•´ä½“çŠ¶æ€ç›‘æ§
        print("\nğŸ“Š åœºæ™¯1ï¼šç³»ç»Ÿæ•´ä½“çŠ¶æ€ç›‘æ§")
        try:
            # è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
            total_users = self._get_total_users()
            total_assignments = self._get_total_assignments()
            total_submissions = self._get_total_submissions()
            
            print(f"âœ… ç³»ç»Ÿæ•´ä½“çŠ¶æ€:")
            print(f"   - æ€»ç”¨æˆ·æ•°: {total_users}")
            print(f"   - æ€»ä½œä¸šæ•°: {total_assignments}")
            print(f"   - æ€»æäº¤æ•°: {total_submissions}")
            
            self.assertGreater(total_users, 0)
            self.assertGreater(total_assignments, 0)
            
            self.record_test_scenario(
                "ç³»ç»Ÿæ•´ä½“çŠ¶æ€ç›‘æ§",
                True,
                f"ç”¨æˆ·: {total_users}, ä½œä¸š: {total_assignments}, æäº¤: {total_submissions}"
            )
            
        except Exception as e:
            print(f"âŒ ç³»ç»ŸçŠ¶æ€ç›‘æ§å¤±è´¥: {e}")
            self.record_test_scenario("ç³»ç»Ÿæ•´ä½“çŠ¶æ€ç›‘æ§", False, str(e))
        
        # åœºæ™¯2ï¼šæ•™å¸ˆæ´»åŠ¨ç›‘æ§
        print("\nğŸ‘©â€ğŸ« åœºæ™¯2ï¼šæ•™å¸ˆæ´»åŠ¨ç›‘æ§")
        try:
            teachers = ['teacher_alice', 'teacher_bob']
            teacher_activities = {}
            
            for teacher in teachers:
                summary = self.assignment_service.get_teacher_assignment_summary(teacher)
                teacher_activities[teacher] = summary
                
                print(f"âœ… æ•™å¸ˆ {teacher} æ´»åŠ¨ç»Ÿè®¡:")
                print(f"   - æ€»ä½œä¸šæ•°: {summary.get('total_assignments', 0)}")
                print(f"   - æ´»è·ƒä½œä¸šæ•°: {summary.get('active_assignments', 0)}")
                print(f"   - å¾…æ‰¹æ”¹æ•°: {summary.get('pending_grading', 0)}")
            
            self.assertGreater(len(teacher_activities), 0)
            self.record_test_scenario(
                "æ•™å¸ˆæ´»åŠ¨ç›‘æ§",
                True,
                f"ç›‘æ§äº† {len(teacher_activities)} ä¸ªæ•™å¸ˆçš„æ´»åŠ¨"
            )
            
        except Exception as e:
            print(f"âŒ æ•™å¸ˆæ´»åŠ¨ç›‘æ§å¤±è´¥: {e}")
            self.record_test_scenario("æ•™å¸ˆæ´»åŠ¨ç›‘æ§", False, str(e))
        
        # åœºæ™¯3ï¼šæ‰¹æ”¹ä»»åŠ¡ç›‘æ§
        print("\nğŸ¤– åœºæ™¯3ï¼šæ‰¹æ”¹ä»»åŠ¡ç›‘æ§")
        try:
            # åˆ›å»ºä¸€äº›æ‰¹æ”¹ä»»åŠ¡è¿›è¡Œç›‘æ§
            assignment_id = self.assignment_service.create_assignment(
                class_id=1,
                title="ç›‘æ§æµ‹è¯•ä½œä¸š",
                description="ç”¨äºç›‘æ§æµ‹è¯•"
            )
            
            # æ¨¡æ‹Ÿå­¦ç”Ÿæäº¤
            students = ['student_charlie', 'student_diana']
            for student in students:
                answer_files = self.create_test_files("student_answer")
                self.submission_service.submit_assignment(
                    assignment_id=assignment_id,
                    student_username=student,
                    answer_files=answer_files
                )
            
            # è·å–æ‰¹æ”¹ç»Ÿè®¡
            grading_stats = self.classroom_grading_service.get_grading_statistics(assignment_id=assignment_id)
            
            print(f"âœ… æ‰¹æ”¹ä»»åŠ¡ç›‘æ§:")
            print(f"   - æ€»ä»»åŠ¡æ•°: {grading_stats.get('total_tasks', 0)}")
            print(f"   - å®Œæˆä»»åŠ¡æ•°: {grading_stats.get('completed_tasks', 0)}")
            print(f"   - å¤±è´¥ä»»åŠ¡æ•°: {grading_stats.get('failed_tasks', 0)}")
            print(f"   - å®Œæˆç‡: {grading_stats.get('completion_rate', 0):.1f}%")
            
            self.assertIn('total_tasks', grading_stats)
            self.record_test_scenario(
                "æ‰¹æ”¹ä»»åŠ¡ç›‘æ§",
                True,
                f"ä»»åŠ¡ç»Ÿè®¡: {grading_stats.get('total_tasks', 0)} ä¸ªä»»åŠ¡"
            )
            
        except Exception as e:
            print(f"âŒ æ‰¹æ”¹ä»»åŠ¡ç›‘æ§å¤±è´¥: {e}")
            self.record_test_scenario("æ‰¹æ”¹ä»»åŠ¡ç›‘æ§", False, str(e))
        
        # åœºæ™¯4ï¼šç³»ç»Ÿæ€§èƒ½ç›‘æ§
        print("\nâš¡ åœºæ™¯4ï¼šç³»ç»Ÿæ€§èƒ½ç›‘æ§")
        try:
            # æ¨¡æ‹Ÿæ€§èƒ½ç›‘æ§
            start_time = time.time()
            
            # æ‰§è¡Œä¸€äº›ç³»ç»Ÿæ“ä½œ
            assignments = self.assignment_service.get_class_assignments(1)
            submissions = self.submission_service.get_assignment_submissions(assignment_id)
            
            end_time = time.time()
            response_time = end_time - start_time
            
            print(f"âœ… ç³»ç»Ÿæ€§èƒ½ç›‘æ§:")
            print(f"   - æŸ¥è¯¢å“åº”æ—¶é—´: {response_time:.4f} ç§’")
            print(f"   - æŸ¥è¯¢ç»“æœæ•°: ä½œä¸š {len(assignments)} ä¸ª, æäº¤ {len(submissions)} ä¸ª")
            
            # æ€§èƒ½åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
            self.assertLess(response_time, 1.0, "æŸ¥è¯¢å“åº”æ—¶é—´åº”å°äº1ç§’")
            
            self.record_test_scenario(
                "ç³»ç»Ÿæ€§èƒ½ç›‘æ§",
                True,
                f"å“åº”æ—¶é—´: {response_time:.4f} ç§’"
            )
            
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿæ€§èƒ½ç›‘æ§å¤±è´¥: {e}")
            self.record_test_scenario("ç³»ç»Ÿæ€§èƒ½ç›‘æ§", False, str(e))
        
        # åœºæ™¯5ï¼šæ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        print("\nğŸ” åœºæ™¯5ï¼šæ•°æ®å®Œæ•´æ€§æ£€æŸ¥")
        try:
            # æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
            integrity_issues = self._check_data_integrity()
            
            print(f"âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥:")
            if integrity_issues:
                print(f"   - å‘ç°é—®é¢˜: {len(integrity_issues)} ä¸ª")
                for issue in integrity_issues:
                    print(f"     * {issue}")
            else:
                print(f"   - æ•°æ®å®Œæ•´æ€§è‰¯å¥½ï¼Œæœªå‘ç°é—®é¢˜")
            
            # è®°å½•æ£€æŸ¥ç»“æœ
            self.record_test_scenario(
                "æ•°æ®å®Œæ•´æ€§æ£€æŸ¥",
                len(integrity_issues) == 0,
                f"å‘ç° {len(integrity_issues)} ä¸ªé—®é¢˜" if integrity_issues else "æ•°æ®å®Œæ•´æ€§è‰¯å¥½"
            )
            
        except Exception as e:
            print(f"âŒ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            self.record_test_scenario("æ•°æ®å®Œæ•´æ€§æ£€æŸ¥", False, str(e))
        
        # è¾“å‡ºç®¡ç†å‘˜ç›‘æ§æµ‹è¯•æ€»ç»“
        print(f"\nğŸ“‹ ç³»ç»Ÿç®¡ç†å‘˜ç›‘æ§æµ‹è¯•æ€»ç»“:")
        print(f"âœ… é€šè¿‡åœºæ™¯: {len(self.test_results['passed_scenarios'])}")
        print(f"âŒ å¤±è´¥åœºæ™¯: {len(self.test_results['failed_scenarios'])}")
        
        # éªŒè¯å…³é”®ç›‘æ§åœºæ™¯éƒ½é€šè¿‡
        passed_scenario_names = [s['name'] for s in self.test_results['passed_scenarios']]
        critical_scenarios = ["ç³»ç»Ÿæ•´ä½“çŠ¶æ€ç›‘æ§", "æ•™å¸ˆæ´»åŠ¨ç›‘æ§", "ç³»ç»Ÿæ€§èƒ½ç›‘æ§"]
        
        for scenario in critical_scenarios:
            self.assertIn(scenario, passed_scenario_names, f"å…³é”®ç›‘æ§åœºæ™¯ '{scenario}' å¿…é¡»é€šè¿‡")
        
        print("ğŸ‰ ç³»ç»Ÿç®¡ç†å‘˜ç›‘æ§å’Œç»´æŠ¤éªŒæ”¶æµ‹è¯•é€šè¿‡ï¼")
    
    def _prepare_monitoring_test_data(self):
        """å‡†å¤‡ç›‘æ§æµ‹è¯•æ•°æ®"""
        # åˆ›å»ºä¸€äº›æµ‹è¯•ä½œä¸šå’Œæäº¤
        for i in range(3):
            assignment_id = self.assignment_service.create_assignment(
                class_id=1,
                title=f"ç›‘æ§æ•°æ®ä½œä¸š{i+1}",
                description=f"ç¬¬{i+1}ä¸ªç›‘æ§æ•°æ®ä½œä¸š"
            )
            
            # ä¸ºæ¯ä¸ªä½œä¸šåˆ›å»ºä¸€äº›æäº¤
            students = ['student_charlie', 'student_diana']
            for student in students:
                try:
                    answer_files = self.create_test_files("student_answer")
                    self.submission_service.submit_assignment(
                        assignment_id=assignment_id,
                        student_username=student,
                        answer_files=answer_files
                    )
                except:
                    pass  # å¿½ç•¥é‡å¤æäº¤é”™è¯¯
    
    def _get_total_users(self):
        """è·å–æ€»ç”¨æˆ·æ•°"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM users WHERE is_active = 1')
        count = cursor.fetchone()[0]
        conn.close()
        return count
    
    def _get_total_assignments(self):
        """è·å–æ€»ä½œä¸šæ•°"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM assignments WHERE is_active = 1')
        count = cursor.fetchone()[0]
        conn.close()
        return count
    
    def _get_total_submissions(self):
        """è·å–æ€»æäº¤æ•°"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM submissions')
        count = cursor.fetchone()[0]
        conn.close()
        return count
    
    def _check_data_integrity(self):
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        issues = []
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥å­¤ç«‹çš„æäº¤è®°å½•
            cursor.execute('''
                SELECT COUNT(*) FROM submissions s
                LEFT JOIN assignments a ON s.assignment_id = a.id
                WHERE a.id IS NULL
            ''')
            orphaned_submissions = cursor.fetchone()[0]
            if orphaned_submissions > 0:
                issues.append(f"å‘ç° {orphaned_submissions} ä¸ªå­¤ç«‹çš„æäº¤è®°å½•")
            
            # æ£€æŸ¥æ— æ•ˆçš„ç”¨æˆ·å¼•ç”¨
            cursor.execute('''
                SELECT COUNT(*) FROM submissions s
                LEFT JOIN users u ON s.student_username = u.username
                WHERE u.username IS NULL
            ''')
            invalid_users = cursor.fetchone()[0]
            if invalid_users > 0:
                issues.append(f"å‘ç° {invalid_users} ä¸ªæ— æ•ˆçš„ç”¨æˆ·å¼•ç”¨")
            
            conn.close()
            
        except Exception as e:
            issues.append(f"æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¼‚å¸¸: {e}")
        
        return issues


class UIUsabilityTests(UserAcceptanceTestBase):
    """ç”¨æˆ·ç•Œé¢å¯ç”¨æ€§å’Œå“åº”æ€§æµ‹è¯•"""
    
    def test_ui_component_usability(self):
        """æµ‹è¯•UIç»„ä»¶å¯ç”¨æ€§"""
        print("\nğŸ–¥ï¸ ç”¨æˆ·ç•Œé¢å¯ç”¨æ€§éªŒæ”¶æµ‹è¯•")
        print("=" * 50)
        
        # åœºæ™¯1ï¼šç»„ä»¶å®ä¾‹åŒ–æµ‹è¯•
        print("\nğŸ”§ åœºæ™¯1ï¼šUIç»„ä»¶å®ä¾‹åŒ–æµ‹è¯•")
        try:
            # æµ‹è¯•æ‰€æœ‰UIç»„ä»¶æ˜¯å¦å¯ä»¥æ­£å¸¸å®ä¾‹åŒ–
            ui_components = []
            
            try:
                from src.ui.components.assignment_center import AssignmentCenter
                assignment_center = AssignmentCenter(self.assignment_service, self.submission_service)
                ui_components.append(('AssignmentCenter', assignment_center))
            except ImportError:
                print("âš ï¸ AssignmentCenterç»„ä»¶æœªæ‰¾åˆ°")
            
            try:
                from src.ui.components.submission_interface import SubmissionInterface
                submission_interface = SubmissionInterface(self.assignment_service, self.submission_service)
                ui_components.append(('SubmissionInterface', submission_interface))
            except ImportError:
                print("âš ï¸ SubmissionInterfaceç»„ä»¶æœªæ‰¾åˆ°")
            
            try:
                from src.ui.components.grading_dashboard import GradingDashboard
                grading_dashboard = GradingDashboard(self.assignment_service, self.submission_service)
                ui_components.append(('GradingDashboard', grading_dashboard))
            except ImportError:
                print("âš ï¸ GradingDashboardç»„ä»¶æœªæ‰¾åˆ°")
            
            print(f"âœ… æˆåŠŸå®ä¾‹åŒ– {len(ui_components)} ä¸ªUIç»„ä»¶")
            for name, component in ui_components:
                print(f"   - {name}: {type(component).__name__}")
            
            self.record_test_scenario(
                "UIç»„ä»¶å®ä¾‹åŒ–",
                len(ui_components) > 0,
                f"æˆåŠŸå®ä¾‹åŒ– {len(ui_components)} ä¸ªç»„ä»¶"
            )
            
        except Exception as e:
            print(f"âŒ UIç»„ä»¶å®ä¾‹åŒ–å¤±è´¥: {e}")
            self.record_test_scenario("UIç»„ä»¶å®ä¾‹åŒ–", False, str(e))
        
        # åœºæ™¯2ï¼šç»„ä»¶æ–¹æ³•å¯ç”¨æ€§æµ‹è¯•
        print("\nâš™ï¸ åœºæ™¯2ï¼šç»„ä»¶æ–¹æ³•å¯ç”¨æ€§æµ‹è¯•")
        try:
            method_tests = []
            
            for name, component in ui_components:
                # æ£€æŸ¥ç»„ä»¶æ˜¯å¦æœ‰å¿…è¦çš„æ–¹æ³•
                required_methods = self._get_required_methods(name)
                
                for method_name in required_methods:
                    has_method = hasattr(component, method_name)
                    method_tests.append((name, method_name, has_method))
                    
                    if has_method:
                        print(f"âœ… {name}.{method_name} æ–¹æ³•å­˜åœ¨")
                    else:
                        print(f"âŒ {name}.{method_name} æ–¹æ³•ç¼ºå¤±")
            
            successful_methods = [t for t in method_tests if t[2]]
            success_rate = len(successful_methods) / len(method_tests) if method_tests else 0
            
            print(f"âœ… æ–¹æ³•å¯ç”¨æ€§æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸç‡: {success_rate:.1%}")
            
            self.record_test_scenario(
                "ç»„ä»¶æ–¹æ³•å¯ç”¨æ€§",
                success_rate >= 0.8,
                f"æ–¹æ³•æˆåŠŸç‡: {success_rate:.1%}"
            )
            
        except Exception as e:
            print(f"âŒ ç»„ä»¶æ–¹æ³•å¯ç”¨æ€§æµ‹è¯•å¤±è´¥: {e}")
            self.record_test_scenario("ç»„ä»¶æ–¹æ³•å¯ç”¨æ€§", False, str(e))
        
        # åœºæ™¯3ï¼šå“åº”æ€§æµ‹è¯•
        print("\nâš¡ åœºæ™¯3ï¼šUIå“åº”æ€§æµ‹è¯•")
        try:
            response_times = []
            
            # æµ‹è¯•å„ç§æ“ä½œçš„å“åº”æ—¶é—´
            operations = [
                ("è·å–ä½œä¸šåˆ—è¡¨", lambda: self.assignment_service.get_class_assignments(1)),
                ("è·å–æäº¤åˆ—è¡¨", lambda: self.submission_service.get_assignment_submissions(1)),
                ("è·å–ç»Ÿè®¡æ•°æ®", lambda: self.assignment_service.get_assignment_statistics(1)),
            ]
            
            for operation_name, operation in operations:
                start_time = time.time()
                try:
                    result = operation()
                    end_time = time.time()
                    response_time = end_time - start_time
                    response_times.append(response_time)
                    
                    print(f"âœ… {operation_name}: {response_time:.4f} ç§’")
                except Exception as e:
                    print(f"âŒ {operation_name} å¤±è´¥: {e}")
            
            if response_times:
                avg_response_time = sum(response_times) / len(response_times)
                max_response_time = max(response_times)
                
                print(f"âœ… å“åº”æ€§æµ‹è¯•ç»“æœ:")
                print(f"   - å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.4f} ç§’")
                print(f"   - æœ€å¤§å“åº”æ—¶é—´: {max_response_time:.4f} ç§’")
                
                # å“åº”æ—¶é—´åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
                is_responsive = avg_response_time < 0.5 and max_response_time < 1.0
                
                self.record_test_scenario(
                    "UIå“åº”æ€§",
                    is_responsive,
                    f"å¹³å‡: {avg_response_time:.4f}s, æœ€å¤§: {max_response_time:.4f}s"
                )
            
        except Exception as e:
            print(f"âŒ UIå“åº”æ€§æµ‹è¯•å¤±è´¥: {e}")
            self.record_test_scenario("UIå“åº”æ€§", False, str(e))
        
        # è¾“å‡ºUIå¯ç”¨æ€§æµ‹è¯•æ€»ç»“
        print(f"\nğŸ“‹ UIå¯ç”¨æ€§æµ‹è¯•æ€»ç»“:")
        print(f"âœ… é€šè¿‡åœºæ™¯: {len(self.test_results['passed_scenarios'])}")
        print(f"âŒ å¤±è´¥åœºæ™¯: {len(self.test_results['failed_scenarios'])}")
        
        print("ğŸ‰ ç”¨æˆ·ç•Œé¢å¯ç”¨æ€§éªŒæ”¶æµ‹è¯•å®Œæˆï¼")
    
    def _get_required_methods(self, component_name):
        """è·å–ç»„ä»¶å¿…éœ€çš„æ–¹æ³•åˆ—è¡¨"""
        method_map = {
            'AssignmentCenter': [
                'render_teacher_view',
                'render_student_view',
                'render_assignment_creation_form'
            ],
            'SubmissionInterface': [
                'render_assignment_details',
                'render_file_upload_form',
                'render_submission_status'
            ],
            'GradingDashboard': [
                'render_class_overview',
                'render_assignment_statistics',
                'render_grading_progress'
            ]
        }
        
        return method_map.get(component_name, [])


def run_user_acceptance_tests():
    """è¿è¡Œç”¨æˆ·éªŒæ”¶æµ‹è¯•å¥—ä»¶"""
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()
    
    # æ·»åŠ æ‰€æœ‰æµ‹è¯•ç±»
    test_classes = [
        TeacherWorkflowAcceptanceTests,
        StudentWorkflowAcceptanceTests,
        SystemAdminAcceptanceTests,
        UIUsabilityTests
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # è®¡ç®—æµ‹è¯•ç»“æœ
    total_tests = result.testsRun
    failures = len(result.failures)
    errors = len(result.errors)
    success_rate = ((total_tests - failures - errors) / total_tests) * 100 if total_tests > 0 else 0
    
    print(f"\n{'='*60}")
    print(f"ç”¨æˆ·éªŒæ”¶æµ‹è¯•ç»“æœ:")
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"æˆåŠŸ: {total_tests - failures - errors}")
    print(f"å¤±è´¥: {failures}")
    print(f"é”™è¯¯: {errors}")
    print(f"æˆåŠŸç‡: {success_rate:.2f}%")
    print(f"{'='*60}")
    
    return success_rate >= 80.0


if __name__ == '__main__':
    success = run_user_acceptance_tests()
    sys.exit(0 if success else 1)