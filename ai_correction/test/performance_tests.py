#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½å’Œè´Ÿè½½æµ‹è¯•å¥—ä»¶
ç¼–å†™æ‰¹é‡æ‰¹æ”¹æ€§èƒ½æµ‹è¯•ï¼ŒéªŒè¯ç³»ç»Ÿå¤„ç†èƒ½åŠ›
ç¼–å†™å¹¶å‘ç”¨æˆ·è®¿é—®è´Ÿè½½æµ‹è¯•
ç¼–å†™å¤§æ–‡ä»¶ä¸Šä¼ å’Œå¤„ç†æ€§èƒ½æµ‹è¯•
ç¼–å†™æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
"""

import unittest
import tempfile
import sqlite3
import json
import os
import sys
import time
import threading
import psutil
import statistics
from datetime import datetime, timedelta
from pathlib import Path
from unittest.mock import Mock, patch
from concurrent.futures import ThreadPoolExecutor, as_completed
import random
import string

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# å¯¼å…¥æ‰€æœ‰éœ€è¦æµ‹è¯•çš„æ¨¡å—
from src.services.assignment_service import AssignmentService
from src.services.submission_service import SubmissionService
from src.services.classroom_grading_service import ClassroomGradingService
from src.models.assignment import Assignment
from src.models.submission import Submission, SubmissionStatus


class PerformanceTestBase(unittest.TestCase):
    """æ€§èƒ½æµ‹è¯•åŸºç±»"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        # åˆ›å»ºä¸´æ—¶æ•°æ®åº“
        self.temp_db = tempfile.NamedTemporaryFile(delete=False, suffix='.db')
        self.temp_db.close()
        self.db_path = self.temp_db.name
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç›®å½•
        self.temp_dir = tempfile.mkdtemp()
        
        # åˆå§‹åŒ–æµ‹è¯•æ•°æ®åº“
        self._init_test_database()
        
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        self.assignment_service = AssignmentService(db_path=self.db_path)
        self.submission_service = SubmissionService(db_path=self.db_path)
        
        # åˆ›å»ºæ¨¡æ‹Ÿä¾èµ–
        self.mock_task_service = Mock()
        self.mock_grading_config_service = Mock()
        self.classroom_grading_service = ClassroomGradingService(
            db_path=self.db_path,
            task_service=self.mock_task_service,
            grading_config_service=self.mock_grading_config_service
        )
        
        # æ€§èƒ½ç›‘æ§
        self.performance_metrics = {
            'start_time': None,
            'end_time': None,
            'memory_usage': [],
            'cpu_usage': [],
            'response_times': []
        }
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        try:
            Path(self.db_path).unlink(missing_ok=True)
        except:
            pass
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        try:
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except:
            pass
    
    def _init_test_database(self):
        """åˆå§‹åŒ–æµ‹è¯•æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # åˆ›å»ºå®Œæ•´çš„è¡¨ç»“æ„
        cursor.execute('''
            CREATE TABLE users (
                username TEXT PRIMARY KEY,
                password_hash TEXT NOT NULL,
                role TEXT NOT NULL,
                real_name TEXT,
                email TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                is_active BOOLEAN DEFAULT 1
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE classes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                description TEXT,
                teacher_username TEXT NOT NULL,
                invite_code TEXT UNIQUE NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                is_active BOOLEAN DEFAULT 1,
                FOREIGN KEY (teacher_username) REFERENCES users (username)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE class_members (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                class_id INTEGER NOT NULL,
                student_username TEXT NOT NULL,
                joined_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                is_active BOOLEAN DEFAULT 1,
                FOREIGN KEY (class_id) REFERENCES classes (id),
                FOREIGN KEY (student_username) REFERENCES users (username),
                UNIQUE(class_id, student_username)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE assignments (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                class_id INTEGER NOT NULL,
                title TEXT NOT NULL,
                description TEXT,
                question_files TEXT,
                marking_files TEXT,
                grading_config_id TEXT,
                auto_grading_enabled BOOLEAN DEFAULT 1,
                grading_template_id TEXT,
                deadline TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                is_active BOOLEAN DEFAULT 1,
                FOREIGN KEY (class_id) REFERENCES classes (id)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE submissions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                assignment_id INTEGER NOT NULL,
                student_username TEXT NOT NULL,
                answer_files TEXT,
                ai_result TEXT,
                teacher_feedback TEXT,
                status TEXT DEFAULT 'submitted',
                score REAL,
                task_id TEXT,
                grading_details TEXT,
                ai_confidence REAL,
                manual_review_required BOOLEAN DEFAULT 0,
                submitted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                graded_at TIMESTAMP,
                returned_at TIMESTAMP,
                FOREIGN KEY (assignment_id) REFERENCES assignments (id),
                FOREIGN KEY (student_username) REFERENCES users (username),
                UNIQUE(assignment_id, student_username)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE notifications (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                recipient_username TEXT NOT NULL,
                title TEXT NOT NULL,
                content TEXT NOT NULL,
                type TEXT DEFAULT 'info',
                is_read BOOLEAN DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (recipient_username) REFERENCES users (username)
            )
        ''')
        
        # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
        cursor.execute('CREATE INDEX idx_assignments_class_id ON assignments(class_id)')
        cursor.execute('CREATE INDEX idx_submissions_assignment_id ON submissions(assignment_id)')
        cursor.execute('CREATE INDEX idx_submissions_student ON submissions(student_username)')
        cursor.execute('CREATE INDEX idx_submissions_status ON submissions(status)')
        cursor.execute('CREATE INDEX idx_notifications_recipient ON notifications(recipient_username)')
        
        # æ’å…¥æµ‹è¯•æ•°æ®
        cursor.execute('''
            INSERT INTO users (username, password_hash, role, real_name)
            VALUES ('teacher1', 'hash1', 'teacher', 'å¼ è€å¸ˆ')
        ''')
        
        cursor.execute('''
            INSERT INTO classes (id, name, description, teacher_username, invite_code)
            VALUES (1, 'æ€§èƒ½æµ‹è¯•ç­çº§', 'ç”¨äºæ€§èƒ½æµ‹è¯•', 'teacher1', 'PERF001')
        ''')
        
        conn.commit()
        conn.close()
    
    def start_performance_monitoring(self):
        """å¼€å§‹æ€§èƒ½ç›‘æ§"""
        self.performance_metrics['start_time'] = time.time()
        self.performance_metrics['memory_usage'] = []
        self.performance_metrics['cpu_usage'] = []
        self.performance_metrics['response_times'] = []
    
    def record_performance_metric(self, operation_time=None):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        # è®°å½•å†…å­˜ä½¿ç”¨
        memory_info = psutil.virtual_memory()
        self.performance_metrics['memory_usage'].append(memory_info.percent)
        
        # è®°å½•CPUä½¿ç”¨
        cpu_percent = psutil.cpu_percent()
        self.performance_metrics['cpu_usage'].append(cpu_percent)
        
        # è®°å½•å“åº”æ—¶é—´
        if operation_time is not None:
            self.performance_metrics['response_times'].append(operation_time)
    
    def stop_performance_monitoring(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        self.performance_metrics['end_time'] = time.time()
        
        # è®¡ç®—æ€»ä½“æ€§èƒ½æŒ‡æ ‡
        total_time = self.performance_metrics['end_time'] - self.performance_metrics['start_time']
        
        metrics_summary = {
            'total_time': total_time,
            'avg_memory_usage': statistics.mean(self.performance_metrics['memory_usage']) if self.performance_metrics['memory_usage'] else 0,
            'max_memory_usage': max(self.performance_metrics['memory_usage']) if self.performance_metrics['memory_usage'] else 0,
            'avg_cpu_usage': statistics.mean(self.performance_metrics['cpu_usage']) if self.performance_metrics['cpu_usage'] else 0,
            'max_cpu_usage': max(self.performance_metrics['cpu_usage']) if self.performance_metrics['cpu_usage'] else 0,
            'avg_response_time': statistics.mean(self.performance_metrics['response_times']) if self.performance_metrics['response_times'] else 0,
            'max_response_time': max(self.performance_metrics['response_times']) if self.performance_metrics['response_times'] else 0,
            'min_response_time': min(self.performance_metrics['response_times']) if self.performance_metrics['response_times'] else 0
        }
        
        return metrics_summary
    
    def generate_random_string(self, length=100):
        """ç”Ÿæˆéšæœºå­—ç¬¦ä¸²"""
        return ''.join(random.choices(string.ascii_letters + string.digits + ' ', k=length))
    
    def create_large_test_file(self, size_mb=1):
        """åˆ›å»ºå¤§æµ‹è¯•æ–‡ä»¶"""
        file_path = Path(self.temp_dir) / f"large_file_{size_mb}mb.txt"
        
        # ç”ŸæˆæŒ‡å®šå¤§å°çš„æ–‡ä»¶å†…å®¹
        content_size = size_mb * 1024 * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
        chunk_size = 1024  # æ¯æ¬¡å†™å…¥1KB
        
        with open(file_path, 'w', encoding='utf-8') as f:
            written = 0
            while written < content_size:
                chunk = self.generate_random_string(min(chunk_size, content_size - written))
                f.write(chunk)
                written += len(chunk.encode('utf-8'))
        
        return str(file_path)


class BatchGradingPerformanceTests(PerformanceTestBase):
    """æ‰¹é‡æ‰¹æ”¹æ€§èƒ½æµ‹è¯•"""
    
    def test_batch_grading_performance(self):
        """æµ‹è¯•æ‰¹é‡æ‰¹æ”¹æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•æ‰¹é‡æ‰¹æ”¹æ€§èƒ½...")
        
        # åˆ›å»ºå¤§é‡å­¦ç”Ÿç”¨æˆ·
        num_students = 100
        print(f"1. åˆ›å»º {num_students} ä¸ªå­¦ç”Ÿç”¨æˆ·...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for i in range(1, num_students + 1):
            cursor.execute('''
                INSERT INTO users (username, password_hash, role, real_name)
                VALUES (?, ?, ?, ?)
            ''', (f'student{i}', f'hash{i}', 'student', f'å­¦ç”Ÿ{i}'))
            
            cursor.execute('''
                INSERT INTO class_members (class_id, student_username)
                VALUES (1, ?)
            ''', (f'student{i}',))
        
        conn.commit()
        conn.close()
        
        # åˆ›å»ºä½œä¸š
        print("2. åˆ›å»ºæµ‹è¯•ä½œä¸š...")
        assignment_id = self.assignment_service.create_assignment(
            class_id=1,
            title="æ‰¹é‡æ‰¹æ”¹æ€§èƒ½æµ‹è¯•ä½œä¸š",
            description="ç”¨äºæµ‹è¯•æ‰¹é‡æ‰¹æ”¹æ€§èƒ½",
            auto_grading_enabled=True
        )
        
        # æ‰¹é‡æäº¤ä½œä¸š
        print(f"3. æ‰¹é‡æäº¤ {num_students} ä¸ªä½œä¸š...")
        self.start_performance_monitoring()
        
        submission_times = []
        for i in range(1, num_students + 1):
            start_time = time.time()
            
            success = self.submission_service.submit_assignment(
                assignment_id=assignment_id,
                student_username=f'student{i}',
                answer_files=[f'answer_{i}.txt']
            )
            
            end_time = time.time()
            submission_time = end_time - start_time
            submission_times.append(submission_time)
            
            self.assertTrue(success)
            self.record_performance_metric(submission_time)
        
        # æ‰¹é‡AIæ‰¹æ”¹
        print(f"4. æ‰¹é‡AIæ‰¹æ”¹ {num_students} ä¸ªæäº¤...")
        grading_times = []
        
        for i in range(1, num_students + 1):
            submission = self.submission_service.get_submission(assignment_id, f'student{i}')
            
            start_time = time.time()
            
            success = self.submission_service.update_submission_grading_result(
                submission.id,
                score=random.uniform(70, 95),
                feedback=f"AIæ‰¹æ”¹ï¼šå­¦ç”Ÿ{i}çš„ä½œä¸šå®Œæˆè´¨é‡è‰¯å¥½ã€‚",
                confidence=random.uniform(0.8, 0.95),
                criteria_scores={'å†…å®¹': random.uniform(80, 95), 'è¯­æ³•': random.uniform(75, 90)},
                suggestions=['ç»§ç»­ä¿æŒ', 'æ³¨æ„ç»†èŠ‚'],
                task_id=f'task_{i}'
            )
            
            end_time = time.time()
            grading_time = end_time - start_time
            grading_times.append(grading_time)
            
            self.assertTrue(success)
            self.record_performance_metric(grading_time)
        
        # åœæ­¢ç›‘æ§å¹¶åˆ†æç»“æœ
        metrics = self.stop_performance_monitoring()
        
        print(f"\nğŸ“Š æ‰¹é‡æ‰¹æ”¹æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"- æ€»å¤„ç†æ—¶é—´: {metrics['total_time']:.2f} ç§’")
        print(f"- å¹³å‡æäº¤æ—¶é—´: {statistics.mean(submission_times):.4f} ç§’")
        print(f"- å¹³å‡æ‰¹æ”¹æ—¶é—´: {statistics.mean(grading_times):.4f} ç§’")
        print(f"- æœ€å¤§å“åº”æ—¶é—´: {metrics['max_response_time']:.4f} ç§’")
        print(f"- å¹³å‡å†…å­˜ä½¿ç”¨: {metrics['avg_memory_usage']:.2f}%")
        print(f"- æœ€å¤§å†…å­˜ä½¿ç”¨: {metrics['max_memory_usage']:.2f}%")
        print(f"- å¹³å‡CPUä½¿ç”¨: {metrics['avg_cpu_usage']:.2f}%")
        
        # æ€§èƒ½æ–­è¨€
        self.assertLess(statistics.mean(submission_times), 0.1, "å¹³å‡æäº¤æ—¶é—´åº”å°äº100ms")
        self.assertLess(statistics.mean(grading_times), 0.2, "å¹³å‡æ‰¹æ”¹æ—¶é—´åº”å°äº200ms")
        self.assertLess(metrics['max_memory_usage'], 80, "æœ€å¤§å†…å­˜ä½¿ç”¨åº”å°äº80%")
        
        print("âœ… æ‰¹é‡æ‰¹æ”¹æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼")
    
    def test_concurrent_grading_performance(self):
        """æµ‹è¯•å¹¶å‘æ‰¹æ”¹æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•å¹¶å‘æ‰¹æ”¹æ€§èƒ½...")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        num_students = 50
        num_threads = 10
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for i in range(1, num_students + 1):
            cursor.execute('''
                INSERT INTO users (username, password_hash, role, real_name)
                VALUES (?, ?, ?, ?)
            ''', (f'concurrent_student{i}', f'hash{i}', 'student', f'å¹¶å‘å­¦ç”Ÿ{i}'))
        
        conn.commit()
        conn.close()
        
        # åˆ›å»ºä½œä¸š
        assignment_id = self.assignment_service.create_assignment(
            class_id=1,
            title="å¹¶å‘æ‰¹æ”¹æ€§èƒ½æµ‹è¯•ä½œä¸š",
            description="ç”¨äºæµ‹è¯•å¹¶å‘æ‰¹æ”¹æ€§èƒ½"
        )
        
        # å…ˆæäº¤æ‰€æœ‰ä½œä¸š
        for i in range(1, num_students + 1):
            self.submission_service.submit_assignment(
                assignment_id=assignment_id,
                student_username=f'concurrent_student{i}',
                answer_files=[f'concurrent_answer_{i}.txt']
            )
        
        # å¹¶å‘æ‰¹æ”¹å‡½æ•°
        def grade_submission(student_index):
            try:
                start_time = time.time()
                
                submission = self.submission_service.get_submission(
                    assignment_id, f'concurrent_student{student_index}'
                )
                
                success = self.submission_service.update_submission_grading_result(
                    submission.id,
                    score=random.uniform(70, 95),
                    feedback=f"å¹¶å‘æ‰¹æ”¹ï¼šå­¦ç”Ÿ{student_index}çš„ä½œä¸šã€‚",
                    confidence=random.uniform(0.8, 0.95)
                )
                
                end_time = time.time()
                return {
                    'student_index': student_index,
                    'success': success,
                    'time': end_time - start_time
                }
            except Exception as e:
                return {
                    'student_index': student_index,
                    'success': False,
                    'error': str(e),
                    'time': 0
                }
        
        # å¼€å§‹å¹¶å‘æ‰¹æ”¹
        print(f"å¼€å§‹å¹¶å‘æ‰¹æ”¹ {num_students} ä¸ªæäº¤ï¼Œä½¿ç”¨ {num_threads} ä¸ªçº¿ç¨‹...")
        self.start_performance_monitoring()
        
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [
                executor.submit(grade_submission, i) 
                for i in range(1, num_students + 1)
            ]
            
            results = []
            for future in as_completed(futures):
                result = future.result()
                results.append(result)
                self.record_performance_metric(result['time'])
        
        metrics = self.stop_performance_monitoring()
        
        # åˆ†æç»“æœ
        successful_gradings = [r for r in results if r['success']]
        failed_gradings = [r for r in results if not r['success']]
        grading_times = [r['time'] for r in successful_gradings]
        
        print(f"\nğŸ“Š å¹¶å‘æ‰¹æ”¹æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"- æˆåŠŸæ‰¹æ”¹: {len(successful_gradings)}/{num_students}")
        print(f"- å¤±è´¥æ‰¹æ”¹: {len(failed_gradings)}")
        print(f"- æ€»å¤„ç†æ—¶é—´: {metrics['total_time']:.2f} ç§’")
        print(f"- å¹³å‡æ‰¹æ”¹æ—¶é—´: {statistics.mean(grading_times):.4f} ç§’")
        print(f"- ååé‡: {len(successful_gradings) / metrics['total_time']:.2f} æ‰¹æ”¹/ç§’")
        print(f"- æœ€å¤§å†…å­˜ä½¿ç”¨: {metrics['max_memory_usage']:.2f}%")
        
        # æ€§èƒ½æ–­è¨€
        self.assertGreaterEqual(len(successful_gradings), num_students * 0.95, "æˆåŠŸç‡åº”å¤§äº95%")
        self.assertLess(metrics['total_time'], 30, "æ€»å¤„ç†æ—¶é—´åº”å°äº30ç§’")
        
        print("âœ… å¹¶å‘æ‰¹æ”¹æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼")


class LoadTests(PerformanceTestBase):
    """è´Ÿè½½æµ‹è¯•"""
    
    def test_concurrent_user_access_load(self):
        """æµ‹è¯•å¹¶å‘ç”¨æˆ·è®¿é—®è´Ÿè½½"""
        print("\nğŸ§ª æµ‹è¯•å¹¶å‘ç”¨æˆ·è®¿é—®è´Ÿè½½...")
        
        # åˆ›å»ºå¤§é‡ç”¨æˆ·å’Œä½œä¸š
        num_users = 200
        num_assignments = 20
        
        print(f"1. åˆ›å»º {num_users} ä¸ªç”¨æˆ·...")
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for i in range(1, num_users + 1):
            cursor.execute('''
                INSERT INTO users (username, password_hash, role, real_name)
                VALUES (?, ?, ?, ?)
            ''', (f'load_user{i}', f'hash{i}', 'student', f'è´Ÿè½½ç”¨æˆ·{i}'))
        
        conn.commit()
        conn.close()
        
        print(f"2. åˆ›å»º {num_assignments} ä¸ªä½œä¸š...")
        assignment_ids = []
        for i in range(1, num_assignments + 1):
            assignment_id = self.assignment_service.create_assignment(
                class_id=1,
                title=f"è´Ÿè½½æµ‹è¯•ä½œä¸š{i}",
                description=f"ç¬¬{i}ä¸ªè´Ÿè½½æµ‹è¯•ä½œä¸š"
            )
            assignment_ids.append(assignment_id)
        
        # æ¨¡æ‹Ÿç”¨æˆ·æ“ä½œ
        def simulate_user_operations(user_index):
            """æ¨¡æ‹Ÿå•ä¸ªç”¨æˆ·çš„æ“ä½œ"""
            operations = []
            
            try:
                # 1. è·å–ä½œä¸šåˆ—è¡¨
                start_time = time.time()
                assignments = self.assignment_service.get_student_assignments(f'load_user{user_index}')
                operations.append(('get_assignments', time.time() - start_time))
                
                # 2. éšæœºé€‰æ‹©å‡ ä¸ªä½œä¸šè¿›è¡Œæ“ä½œ
                selected_assignments = random.sample(assignment_ids, min(5, len(assignment_ids)))
                
                for assignment_id in selected_assignments:
                    # è·å–ä½œä¸šè¯¦æƒ…
                    start_time = time.time()
                    assignment = self.assignment_service.get_assignment_by_id(assignment_id)
                    operations.append(('get_assignment_detail', time.time() - start_time))
                    
                    # æäº¤ä½œä¸š
                    start_time = time.time()
                    success = self.submission_service.submit_assignment(
                        assignment_id=assignment_id,
                        student_username=f'load_user{user_index}',
                        answer_files=[f'load_answer_{user_index}_{assignment_id}.txt']
                    )
                    operations.append(('submit_assignment', time.time() - start_time))
                    
                    if success:
                        # æŸ¥çœ‹æäº¤çŠ¶æ€
                        start_time = time.time()
                        submission = self.submission_service.get_submission(
                            assignment_id, f'load_user{user_index}'
                        )
                        operations.append(('get_submission', time.time() - start_time))
                
                return {
                    'user_index': user_index,
                    'success': True,
                    'operations': operations
                }
                
            except Exception as e:
                return {
                    'user_index': user_index,
                    'success': False,
                    'error': str(e),
                    'operations': operations
                }
        
        # å¼€å§‹è´Ÿè½½æµ‹è¯•
        print(f"3. å¼€å§‹ {num_users} ä¸ªç”¨æˆ·çš„å¹¶å‘è®¿é—®...")
        self.start_performance_monitoring()
        
        with ThreadPoolExecutor(max_workers=50) as executor:
            futures = [
                executor.submit(simulate_user_operations, i) 
                for i in range(1, num_users + 1)
            ]
            
            results = []
            for future in as_completed(futures):
                result = future.result()
                results.append(result)
                
                # è®°å½•æ‰€æœ‰æ“ä½œçš„å“åº”æ—¶é—´
                for operation_name, operation_time in result.get('operations', []):
                    self.record_performance_metric(operation_time)
        
        metrics = self.stop_performance_monitoring()
        
        # åˆ†æç»“æœ
        successful_users = [r for r in results if r['success']]
        failed_users = [r for r in results if not r['success']]
        
        all_operations = []
        for result in successful_users:
            all_operations.extend(result['operations'])
        
        operation_times = [op[1] for op in all_operations]
        
        print(f"\nğŸ“Š å¹¶å‘ç”¨æˆ·è®¿é—®è´Ÿè½½æµ‹è¯•ç»“æœ:")
        print(f"- æˆåŠŸç”¨æˆ·: {len(successful_users)}/{num_users}")
        print(f"- å¤±è´¥ç”¨æˆ·: {len(failed_users)}")
        print(f"- æ€»æ“ä½œæ•°: {len(all_operations)}")
        print(f"- æ€»å¤„ç†æ—¶é—´: {metrics['total_time']:.2f} ç§’")
        print(f"- å¹³å‡æ“ä½œæ—¶é—´: {statistics.mean(operation_times):.4f} ç§’")
        print(f"- æ“ä½œååé‡: {len(all_operations) / metrics['total_time']:.2f} æ“ä½œ/ç§’")
        print(f"- æœ€å¤§å†…å­˜ä½¿ç”¨: {metrics['max_memory_usage']:.2f}%")
        print(f"- æœ€å¤§CPUä½¿ç”¨: {metrics['max_cpu_usage']:.2f}%")
        
        # æ€§èƒ½æ–­è¨€
        self.assertGreaterEqual(len(successful_users), num_users * 0.9, "æˆåŠŸç‡åº”å¤§äº90%")
        self.assertLess(statistics.mean(operation_times), 1.0, "å¹³å‡æ“ä½œæ—¶é—´åº”å°äº1ç§’")
        
        print("âœ… å¹¶å‘ç”¨æˆ·è®¿é—®è´Ÿè½½æµ‹è¯•é€šè¿‡ï¼")


class LargeFileProcessingTests(PerformanceTestBase):
    """å¤§æ–‡ä»¶å¤„ç†æ€§èƒ½æµ‹è¯•"""
    
    def test_large_file_upload_performance(self):
        """æµ‹è¯•å¤§æ–‡ä»¶ä¸Šä¼ æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•å¤§æ–‡ä»¶ä¸Šä¼ æ€§èƒ½...")
        
        # åˆ›å»ºä¸åŒå¤§å°çš„æµ‹è¯•æ–‡ä»¶
        file_sizes = [1, 5, 10, 20]  # MB
        test_files = {}
        
        print("1. åˆ›å»ºæµ‹è¯•æ–‡ä»¶...")
        for size in file_sizes:
            file_path = self.create_large_test_file(size)
            test_files[size] = file_path
            print(f"âœ… åˆ›å»º {size}MB æµ‹è¯•æ–‡ä»¶")
        
        # åˆ›å»ºä½œä¸š
        assignment_id = self.assignment_service.create_assignment(
            class_id=1,
            title="å¤§æ–‡ä»¶ä¸Šä¼ æµ‹è¯•ä½œä¸š",
            description="ç”¨äºæµ‹è¯•å¤§æ–‡ä»¶ä¸Šä¼ æ€§èƒ½"
        )
        
        # åˆ›å»ºæµ‹è¯•ç”¨æˆ·
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO users (username, password_hash, role, real_name)
            VALUES ('file_test_user', 'hash', 'student', 'æ–‡ä»¶æµ‹è¯•ç”¨æˆ·')
        ''')
        conn.commit()
        conn.close()
        
        # æµ‹è¯•ä¸åŒå¤§å°æ–‡ä»¶çš„ä¸Šä¼ æ€§èƒ½
        upload_results = {}
        
        print("2. æµ‹è¯•æ–‡ä»¶ä¸Šä¼ æ€§èƒ½...")
        for size, file_path in test_files.items():
            print(f"æµ‹è¯• {size}MB æ–‡ä»¶ä¸Šä¼ ...")
            
            self.start_performance_monitoring()
            start_time = time.time()
            
            # æ¨¡æ‹Ÿæ–‡ä»¶ä¸Šä¼ ï¼ˆå®é™…ä¸Šæ˜¯æ–‡ä»¶è·¯å¾„å…³è”ï¼‰
            success = self.submission_service.submit_assignment(
                assignment_id=assignment_id,
                student_username='file_test_user',
                answer_files=[file_path]
            )
            
            end_time = time.time()
            upload_time = end_time - start_time
            
            metrics = self.stop_performance_monitoring()
            
            upload_results[size] = {
                'success': success,
                'upload_time': upload_time,
                'file_size_mb': size,
                'upload_speed_mbps': size / upload_time if upload_time > 0 else 0,
                'memory_usage': metrics['max_memory_usage']
            }
            
            print(f"âœ… {size}MB æ–‡ä»¶ä¸Šä¼ å®Œæˆï¼Œè€—æ—¶: {upload_time:.2f}ç§’")
            
            # æ¸…ç†æäº¤è®°å½•ä»¥ä¾¿ä¸‹æ¬¡æµ‹è¯•
            submission = self.submission_service.get_submission(assignment_id, 'file_test_user')
            if submission:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                cursor.execute('DELETE FROM submissions WHERE id = ?', (submission.id,))
                conn.commit()
                conn.close()
        
        # åˆ†æç»“æœ
        print(f"\nğŸ“Š å¤§æ–‡ä»¶ä¸Šä¼ æ€§èƒ½æµ‹è¯•ç»“æœ:")
        for size, result in upload_results.items():
            print(f"- {size}MB æ–‡ä»¶:")
            print(f"  ä¸Šä¼ æ—¶é—´: {result['upload_time']:.2f} ç§’")
            print(f"  ä¸Šä¼ é€Ÿåº¦: {result['upload_speed_mbps']:.2f} MB/ç§’")
            print(f"  å†…å­˜ä½¿ç”¨: {result['memory_usage']:.2f}%")
        
        # æ€§èƒ½æ–­è¨€
        for size, result in upload_results.items():
            self.assertTrue(result['success'], f"{size}MBæ–‡ä»¶ä¸Šä¼ åº”è¯¥æˆåŠŸ")
            self.assertLess(result['upload_time'], size * 2, f"{size}MBæ–‡ä»¶ä¸Šä¼ æ—¶é—´åº”å°äº{size * 2}ç§’")
        
        print("âœ… å¤§æ–‡ä»¶ä¸Šä¼ æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼")
    
    def test_large_file_processing_performance(self):
        """æµ‹è¯•å¤§æ–‡ä»¶å¤„ç†æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•å¤§æ–‡ä»¶å¤„ç†æ€§èƒ½...")
        
        # åˆ›å»ºå¤§æ–‡ä»¶
        large_file = self.create_large_test_file(10)  # 10MBæ–‡ä»¶
        
        # åˆ›å»ºä½œä¸šå’Œæäº¤
        assignment_id = self.assignment_service.create_assignment(
            class_id=1,
            title="å¤§æ–‡ä»¶å¤„ç†æµ‹è¯•",
            description="æµ‹è¯•å¤§æ–‡ä»¶å¤„ç†æ€§èƒ½",
            question_files=[large_file],
            marking_files=[large_file]
        )
        
        # åˆ›å»ºç”¨æˆ·
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO users (username, password_hash, role, real_name)
            VALUES ('processing_user', 'hash', 'student', 'å¤„ç†æµ‹è¯•ç”¨æˆ·')
        ''')
        conn.commit()
        conn.close()
        
        # æäº¤å¤§æ–‡ä»¶
        self.submission_service.submit_assignment(
            assignment_id=assignment_id,
            student_username='processing_user',
            answer_files=[large_file]
        )
        
        submission = self.submission_service.get_submission(assignment_id, 'processing_user')
        
        # æµ‹è¯•æ‰¹æ”¹å¤„ç†æ€§èƒ½
        print("å¼€å§‹å¤§æ–‡ä»¶æ‰¹æ”¹å¤„ç†...")
        self.start_performance_monitoring()
        
        start_time = time.time()
        
        # æ¨¡æ‹Ÿæ‰¹æ”¹å¤„ç†
        result = self.classroom_grading_service.apply_grading_standards(
            answer_files=[large_file],
            marking_files=[large_file],
            grading_config=None
        )
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        metrics = self.stop_performance_monitoring()
        
        print(f"\nğŸ“Š å¤§æ–‡ä»¶å¤„ç†æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"- æ–‡ä»¶å¤§å°: 10MB")
        print(f"- å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
        print(f"- å¤„ç†é€Ÿåº¦: {10 / processing_time:.2f} MB/ç§’")
        print(f"- æœ€å¤§å†…å­˜ä½¿ç”¨: {metrics['max_memory_usage']:.2f}%")
        print(f"- æœ€å¤§CPUä½¿ç”¨: {metrics['max_cpu_usage']:.2f}%")
        
        # æ€§èƒ½æ–­è¨€
        self.assertIsNotNone(result)
        self.assertIn('score', result)
        self.assertLess(processing_time, 30, "10MBæ–‡ä»¶å¤„ç†æ—¶é—´åº”å°äº30ç§’")
        self.assertLess(metrics['max_memory_usage'], 90, "å†…å­˜ä½¿ç”¨åº”å°äº90%")
        
        print("âœ… å¤§æ–‡ä»¶å¤„ç†æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼")


class DatabasePerformanceTests(PerformanceTestBase):
    """æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æµ‹è¯•"""
    
    def test_database_query_performance(self):
        """æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½...")
        
        # åˆ›å»ºå¤§é‡æµ‹è¯•æ•°æ®
        num_users = 1000
        num_assignments = 100
        num_submissions = 5000
        
        print(f"1. åˆ›å»º {num_users} ä¸ªç”¨æˆ·...")
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ‰¹é‡æ’å…¥ç”¨æˆ·
        users_data = [
            (f'perf_user{i}', f'hash{i}', 'student', f'æ€§èƒ½ç”¨æˆ·{i}')
            for i in range(1, num_users + 1)
        ]
        cursor.executemany('''
            INSERT INTO users (username, password_hash, role, real_name)
            VALUES (?, ?, ?, ?)
        ''', users_data)
        
        print(f"2. åˆ›å»º {num_assignments} ä¸ªä½œä¸š...")
        # æ‰¹é‡æ’å…¥ä½œä¸š
        assignments_data = [
            (1, f'æ€§èƒ½æµ‹è¯•ä½œä¸š{i}', f'ç¬¬{i}ä¸ªæ€§èƒ½æµ‹è¯•ä½œä¸š', '[]', '[]', 1)
            for i in range(1, num_assignments + 1)
        ]
        cursor.executemany('''
            INSERT INTO assignments (class_id, title, description, question_files, marking_files, auto_grading_enabled)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', assignments_data)
        
        print(f"3. åˆ›å»º {num_submissions} ä¸ªæäº¤...")
        # æ‰¹é‡æ’å…¥æäº¤
        submissions_data = []
        for i in range(1, num_submissions + 1):
            assignment_id = random.randint(1, num_assignments)
            user_id = random.randint(1, num_users)
            status = random.choice(['submitted', 'ai_graded', 'teacher_reviewed'])
            score = random.uniform(60, 100) if status != 'submitted' else None
            
            submissions_data.append((
                assignment_id, f'perf_user{user_id}', '["answer.txt"]',
                f'AIæ‰¹æ”¹ç»“æœ{i}' if status != 'submitted' else None,
                f'æ•™å¸ˆåé¦ˆ{i}' if status == 'teacher_reviewed' else None,
                status, score
            ))
        
        cursor.executemany('''
            INSERT INTO submissions (assignment_id, student_username, answer_files, ai_result, teacher_feedback, status, score)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', submissions_data)
        
        conn.commit()
        conn.close()
        
        print("4. æµ‹è¯•å„ç§æŸ¥è¯¢æ€§èƒ½...")
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„æŸ¥è¯¢
        query_tests = [
            {
                'name': 'è·å–ç­çº§ä½œä¸šåˆ—è¡¨',
                'method': lambda: self.assignment_service.get_class_assignments(1),
                'expected_min_count': 1
            },
            {
                'name': 'è·å–å­¦ç”Ÿä½œä¸šåˆ—è¡¨',
                'method': lambda: self.assignment_service.get_student_assignments('perf_user1'),
                'expected_min_count': 0
            },
            {
                'name': 'è·å–ä½œä¸šç»Ÿè®¡',
                'method': lambda: self.assignment_service.get_assignment_statistics(1),
                'expected_keys': ['total_submissions', 'average_score']
            },
            {
                'name': 'è·å–ä½œä¸šæ‰€æœ‰æäº¤',
                'method': lambda: self.submission_service.get_assignment_submissions(1),
                'expected_min_count': 0
            },
            {
                'name': 'è·å–å­¦ç”Ÿæäº¤å†å²',
                'method': lambda: self.submission_service.get_submission_history('perf_user1'),
                'expected_min_count': 0
            },
            {
                'name': 'æœç´¢ä½œä¸š',
                'method': lambda: self.assignment_service.search_assignments(keyword='æ€§èƒ½'),
                'expected_min_count': 1
            }
        ]
        
        query_results = {}
        
        for test in query_tests:
            print(f"æµ‹è¯•æŸ¥è¯¢: {test['name']}")
            
            # é¢„çƒ­æŸ¥è¯¢
            test['method']()
            
            # æ­£å¼æµ‹è¯•
            query_times = []
            for _ in range(10):  # æ¯ä¸ªæŸ¥è¯¢æµ‹è¯•10æ¬¡
                start_time = time.time()
                result = test['method']()
                end_time = time.time()
                query_times.append(end_time - start_time)
                
                # éªŒè¯ç»“æœ
                if 'expected_min_count' in test:
                    self.assertGreaterEqual(len(result), test['expected_min_count'])
                elif 'expected_keys' in test:
                    for key in test['expected_keys']:
                        self.assertIn(key, result)
            
            query_results[test['name']] = {
                'avg_time': statistics.mean(query_times),
                'max_time': max(query_times),
                'min_time': min(query_times),
                'times': query_times
            }
        
        # åˆ†æç»“æœ
        print(f"\nğŸ“Š æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æµ‹è¯•ç»“æœ:")
        for query_name, result in query_results.items():
            print(f"- {query_name}:")
            print(f"  å¹³å‡æ—¶é—´: {result['avg_time']:.4f} ç§’")
            print(f"  æœ€å¤§æ—¶é—´: {result['max_time']:.4f} ç§’")
            print(f"  æœ€å°æ—¶é—´: {result['min_time']:.4f} ç§’")
        
        # æ€§èƒ½æ–­è¨€
        for query_name, result in query_results.items():
            self.assertLess(result['avg_time'], 1.0, f"{query_name}å¹³å‡æŸ¥è¯¢æ—¶é—´åº”å°äº1ç§’")
            self.assertLess(result['max_time'], 2.0, f"{query_name}æœ€å¤§æŸ¥è¯¢æ—¶é—´åº”å°äº2ç§’")
        
        print("âœ… æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼")
    
    def test_database_concurrent_access_performance(self):
        """æµ‹è¯•æ•°æ®åº“å¹¶å‘è®¿é—®æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•æ•°æ®åº“å¹¶å‘è®¿é—®æ€§èƒ½...")
        
        # åˆ›å»ºåŸºç¡€æµ‹è¯•æ•°æ®
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºä¸€äº›åŸºç¡€æ•°æ®
        for i in range(1, 101):
            cursor.execute('''
                INSERT INTO users (username, password_hash, role, real_name)
                VALUES (?, ?, ?, ?)
            ''', (f'concurrent_user{i}', f'hash{i}', 'student', f'å¹¶å‘ç”¨æˆ·{i}'))
        
        for i in range(1, 21):
            cursor.execute('''
                INSERT INTO assignments (class_id, title, description, question_files, marking_files, auto_grading_enabled)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (1, f'å¹¶å‘æµ‹è¯•ä½œä¸š{i}', f'ç¬¬{i}ä¸ªå¹¶å‘æµ‹è¯•ä½œä¸š', '[]', '[]', 1))
        
        conn.commit()
        conn.close()
        
        # å¹¶å‘è®¿é—®å‡½æ•°
        def concurrent_database_operations(thread_id):
            """å¹¶å‘æ•°æ®åº“æ“ä½œ"""
            operations = []
            
            try:
                for i in range(10):  # æ¯ä¸ªçº¿ç¨‹æ‰§è¡Œ10æ¬¡æ“ä½œ
                    # éšæœºé€‰æ‹©æ“ä½œç±»å‹
                    operation_type = random.choice([
                        'get_assignments',
                        'get_assignment_detail',
                        'submit_assignment',
                        'get_submission'
                    ])
                    
                    start_time = time.time()
                    
                    if operation_type == 'get_assignments':
                        result = self.assignment_service.get_class_assignments(1)
                    elif operation_type == 'get_assignment_detail':
                        assignment_id = random.randint(1, 20)
                        result = self.assignment_service.get_assignment_by_id(assignment_id)
                    elif operation_type == 'submit_assignment':
                        assignment_id = random.randint(1, 20)
                        username = f'concurrent_user{random.randint(1, 100)}'
                        result = self.submission_service.submit_assignment(
                            assignment_id, username, [f'answer_{thread_id}_{i}.txt']
                        )
                    elif operation_type == 'get_submission':
                        assignment_id = random.randint(1, 20)
                        username = f'concurrent_user{random.randint(1, 100)}'
                        result = self.submission_service.get_submission(assignment_id, username)
                    
                    end_time = time.time()
                    operations.append({
                        'type': operation_type,
                        'time': end_time - start_time,
                        'success': result is not None
                    })
                
                return {
                    'thread_id': thread_id,
                    'success': True,
                    'operations': operations
                }
                
            except Exception as e:
                return {
                    'thread_id': thread_id,
                    'success': False,
                    'error': str(e),
                    'operations': operations
                }
        
        # å¼€å§‹å¹¶å‘æµ‹è¯•
        num_threads = 20
        print(f"å¼€å§‹ {num_threads} ä¸ªçº¿ç¨‹çš„å¹¶å‘æ•°æ®åº“è®¿é—®...")
        
        self.start_performance_monitoring()
        
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [
                executor.submit(concurrent_database_operations, i) 
                for i in range(1, num_threads + 1)
            ]
            
            results = []
            for future in as_completed(futures):
                result = future.result()
                results.append(result)
                
                # è®°å½•æ“ä½œæ—¶é—´
                for op in result.get('operations', []):
                    self.record_performance_metric(op['time'])
        
        metrics = self.stop_performance_monitoring()
        
        # åˆ†æç»“æœ
        successful_threads = [r for r in results if r['success']]
        all_operations = []
        for result in successful_threads:
            all_operations.extend(result['operations'])
        
        operation_times = [op['time'] for op in all_operations]
        successful_operations = [op for op in all_operations if op['success']]
        
        print(f"\nğŸ“Š æ•°æ®åº“å¹¶å‘è®¿é—®æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"- æˆåŠŸçº¿ç¨‹: {len(successful_threads)}/{num_threads}")
        print(f"- æ€»æ“ä½œæ•°: {len(all_operations)}")
        print(f"- æˆåŠŸæ“ä½œ: {len(successful_operations)}")
        print(f"- æˆåŠŸç‡: {len(successful_operations) / len(all_operations) * 100:.2f}%")
        print(f"- æ€»å¤„ç†æ—¶é—´: {metrics['total_time']:.2f} ç§’")
        print(f"- å¹³å‡æ“ä½œæ—¶é—´: {statistics.mean(operation_times):.4f} ç§’")
        print(f"- æ“ä½œååé‡: {len(all_operations) / metrics['total_time']:.2f} æ“ä½œ/ç§’")
        print(f"- æœ€å¤§å†…å­˜ä½¿ç”¨: {metrics['max_memory_usage']:.2f}%")
        
        # æ€§èƒ½æ–­è¨€
        self.assertGreaterEqual(len(successful_threads), num_threads * 0.9, "æˆåŠŸçº¿ç¨‹åº”å¤§äº90%")
        self.assertGreaterEqual(len(successful_operations) / len(all_operations), 0.95, "æ“ä½œæˆåŠŸç‡åº”å¤§äº95%")
        self.assertLess(statistics.mean(operation_times), 0.5, "å¹³å‡æ“ä½œæ—¶é—´åº”å°äº0.5ç§’")
        
        print("âœ… æ•°æ®åº“å¹¶å‘è®¿é—®æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼")


def run_performance_tests():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•å¥—ä»¶"""
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()
    
    # æ·»åŠ æ‰€æœ‰æµ‹è¯•ç±»
    test_classes = [
        BatchGradingPerformanceTests,
        LoadTests,
        LargeFileProcessingTests,
        DatabasePerformanceTests
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # è®¡ç®—æµ‹è¯•ç»“æœ
    total_tests = result.testsRun
    failures = len(result.failures)
    errors = len(result.errors)
    success_rate = ((total_tests - failures - errors) / total_tests) * 100 if total_tests > 0 else 0
    
    print(f"\n{'='*60}")
    print(f"æ€§èƒ½å’Œè´Ÿè½½æµ‹è¯•ç»“æœ:")
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"æˆåŠŸ: {total_tests - failures - errors}")
    print(f"å¤±è´¥: {failures}")
    print(f"é”™è¯¯: {errors}")
    print(f"æˆåŠŸç‡: {success_rate:.2f}%")
    print(f"{'='*60}")
    
    return success_rate >= 70.0


if __name__ == '__main__':
    success = run_performance_tests()
    sys.exit(0 if success else 1)