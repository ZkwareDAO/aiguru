# Agentæˆæœ¬ä¼˜åŒ–ç­–ç•¥

## ğŸ“Œ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†åˆ†æAgentæ¶æ„çš„æˆæœ¬é—®é¢˜ï¼Œå¹¶æä¾›å¤šç§ä¼˜åŒ–æ–¹æ¡ˆå’Œå®æ–½å»ºè®®ã€‚

---

## 1. æˆæœ¬åˆ†æ

### 1.1 å½“å‰è®¾è®¡çš„æˆæœ¬ç»“æ„

**Agentåˆ†ç±»**ï¼š

| Agent | æ˜¯å¦è°ƒç”¨LLM | æˆæœ¬ | è¯´æ˜ |
|-------|------------|------|------|
| OrchestratorAgent | âŒ | $0 | çº¯æµç¨‹æ§åˆ¶ |
| PreprocessAgent | âŒ | $0 | æ–‡ä»¶å¤„ç†ã€OCR |
| **GradingAgent** | âœ… | **$0.008-0.015** | ä¸»è¦æˆæœ¬æ¥æº |
| ReviewAgent | âŒ | $0 | è§„åˆ™éªŒè¯ |
| **FeedbackAgent** | âš ï¸ | **$0.002-0.005** | å¯é€‰LLMè°ƒç”¨ |

**å•æ¬¡æ‰¹æ”¹æˆæœ¬**ï¼š
```
åŸºç¡€æ¨¡å¼: $0.008 (ä»…GradingAgent)
æ ‡å‡†æ¨¡å¼: $0.010 (GradingAgent + ç®€å•Feedback)
å®Œæ•´æ¨¡å¼: $0.015 (GradingAgent + è¯¦ç»†Feedback)
```

**æœˆåº¦æˆæœ¬ä¼°ç®—**ï¼š
```
å‡è®¾: æ¯å¤©1000æ¬¡æ‰¹æ”¹
- åŸºç¡€æ¨¡å¼: $0.008 Ã— 1000 Ã— 30 = $240/æœˆ
- æ ‡å‡†æ¨¡å¼: $0.010 Ã— 1000 Ã— 30 = $300/æœˆ
- å®Œæ•´æ¨¡å¼: $0.015 Ã— 1000 Ã— 30 = $450/æœˆ
```

---

## 2. ä¼˜åŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: æ™ºèƒ½Agentèåˆ (æ¨è)

**æ ¸å¿ƒæ€è·¯**: æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€é€‰æ‹©Agentç»„åˆ

#### 2.1 ä¸‰ç§æ¨¡å¼

```python
class AgentMode(Enum):
    """Agentè¿è¡Œæ¨¡å¼"""
    FAST = "fast"           # å¿«é€Ÿæ¨¡å¼ - å•Agent
    STANDARD = "standard"   # æ ‡å‡†æ¨¡å¼ - 2-3ä¸ªAgent
    PREMIUM = "premium"     # å®Œæ•´æ¨¡å¼ - å…¨éƒ¨Agent

class SmartOrchestrator:
    """æ™ºèƒ½ç¼–æ’å™¨ - æ ¹æ®åœºæ™¯é€‰æ‹©Agentç»„åˆ"""
    
    def __init__(self):
        # èåˆAgent - å°†å¤šä¸ªåŠŸèƒ½åˆå¹¶åˆ°ä¸€æ¬¡LLMè°ƒç”¨
        self.unified_agent = UnifiedGradingAgent()
        
        # ç‹¬ç«‹Agent - ç”¨äºå¤æ‚åœºæ™¯
        self.preprocess_agent = PreprocessAgent()
        self.grading_agent = GradingAgent()
        self.review_agent = ReviewAgent()
        self.feedback_agent = FeedbackAgent()
    
    async def execute(self, input_data: Dict) -> Dict:
        """æ ¹æ®åœºæ™¯é€‰æ‹©æ‰§è¡Œæ¨¡å¼"""
        # 1. è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦
        complexity = await self._assess_complexity(input_data)
        
        # 2. é€‰æ‹©æ‰§è¡Œæ¨¡å¼
        if complexity == "simple":
            return await self._fast_mode(input_data)
        elif complexity == "medium":
            return await self._standard_mode(input_data)
        else:
            return await self._premium_mode(input_data)
    
    async def _fast_mode(self, input_data: Dict) -> Dict:
        """å¿«é€Ÿæ¨¡å¼ - å•æ¬¡LLMè°ƒç”¨å®Œæˆæ‰€æœ‰ä»»åŠ¡"""
        # é¢„å¤„ç†(ä¸è°ƒç”¨LLM)
        state = await self.preprocess_agent.process(input_data)
        
        # ç»Ÿä¸€æ‰¹æ”¹(ä¸€æ¬¡LLMè°ƒç”¨å®Œæˆæ‰¹æ”¹+åé¦ˆ)
        result = await self.unified_agent.process(state)
        
        return result
    
    async def _standard_mode(self, input_data: Dict) -> Dict:
        """æ ‡å‡†æ¨¡å¼ - 2æ¬¡LLMè°ƒç”¨"""
        # é¢„å¤„ç†
        state = await self.preprocess_agent.process(input_data)
        
        # æ‰¹æ”¹(ç¬¬1æ¬¡LLMè°ƒç”¨)
        state = await self.grading_agent.process(state)
        
        # å®¡æ ¸(è§„åˆ™æ£€æŸ¥,ä¸è°ƒç”¨LLM)
        state = await self.review_agent.process(state)
        
        # åé¦ˆ(ç¬¬2æ¬¡LLMè°ƒç”¨,ä»…åœ¨éœ€è¦æ—¶)
        if state["confidence"] < 0.8:
            state = await self.feedback_agent.process(state)
        
        return state
    
    async def _premium_mode(self, input_data: Dict) -> Dict:
        """å®Œæ•´æ¨¡å¼ - ä½¿ç”¨æ‰€æœ‰Agent"""
        # å®Œæ•´çš„Pipeline
        state = await self.preprocess_agent.process(input_data)
        state = await self.grading_agent.process(state)
        state = await self.review_agent.process(state)
        state = await self.feedback_agent.process(state)
        return state
    
    async def _assess_complexity(self, input_data: Dict) -> str:
        """è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦"""
        # åŸºäºå¤šä¸ªå› ç´ åˆ¤æ–­
        factors = {
            "file_count": len(input_data.get("files", [])),
            "file_size": sum(f.get("size", 0) for f in input_data.get("files", [])),
            "question_count": input_data.get("question_count", 1),
            "subject": input_data.get("subject", ""),
            "grade_level": input_data.get("grade_level", ""),
        }
        
        # ç®€å•ä»»åŠ¡: å•æ–‡ä»¶ã€å°å°ºå¯¸ã€åŸºç¡€é¢˜ç›®
        if (factors["file_count"] == 1 and 
            factors["file_size"] < 1_000_000 and 
            factors["question_count"] <= 3):
            return "simple"
        
        # å¤æ‚ä»»åŠ¡: å¤šæ–‡ä»¶ã€å¤§å°ºå¯¸ã€å¤æ‚é¢˜ç›®
        elif (factors["file_count"] > 3 or 
              factors["file_size"] > 5_000_000 or 
              factors["question_count"] > 10):
            return "complex"
        
        # ä¸­ç­‰ä»»åŠ¡
        return "medium"
```

#### 2.2 ç»Ÿä¸€æ‰¹æ”¹Agent

```python
class UnifiedGradingAgent:
    """ç»Ÿä¸€æ‰¹æ”¹Agent - ä¸€æ¬¡LLMè°ƒç”¨å®Œæˆæ‰¹æ”¹+åé¦ˆ"""
    
    async def process(self, state: GradingState) -> GradingState:
        """å•æ¬¡LLMè°ƒç”¨å®Œæˆæ‰€æœ‰ä»»åŠ¡"""
        
        # æ„å»ºç»Ÿä¸€çš„æç¤ºè¯
        prompt = self._build_unified_prompt(state)
        
        # ä¸€æ¬¡LLMè°ƒç”¨
        response = await self.llm.ainvoke(prompt)
        
        # è§£æç»“æœ
        result = self._parse_unified_result(response)
        
        # æ›´æ–°çŠ¶æ€
        state.update({
            "score": result["score"],
            "errors": result["errors"],
            "confidence": result["confidence"],
            "feedback_text": result["feedback"],
            "suggestions": result["suggestions"],
            "knowledge_points": result["knowledge_points"]
        })
        
        return state
    
    def _build_unified_prompt(self, state: GradingState) -> str:
        """æ„å»ºç»Ÿä¸€æç¤ºè¯ - ä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰ä»»åŠ¡"""
        return f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•™å¸ˆ,è¯·å®Œæˆä»¥ä¸‹æ‰¹æ”¹ä»»åŠ¡:

ã€æ‰¹æ”¹æ ‡å‡†ã€‘
{state["grading_standard"]}

ã€å­¦ç”Ÿç­”æ¡ˆã€‘
{state["extracted_text"]}

è¯·ä¸€æ¬¡æ€§å®Œæˆä»¥ä¸‹æ‰€æœ‰ä»»åŠ¡,å¹¶ä»¥JSONæ ¼å¼è¾“å‡º:

1. **æ‰¹æ”¹è¯„åˆ†**: æ‰¾å‡ºé”™è¯¯,è®¡ç®—åˆ†æ•°
2. **é”™è¯¯åˆ†æ**: è¯¦ç»†è¯´æ˜æ¯ä¸ªé”™è¯¯
3. **æ€»ä½“åé¦ˆ**: ä¼˜ç‚¹ã€ä¸è¶³ã€æ”¹è¿›å»ºè®®
4. **çŸ¥è¯†ç‚¹å…³è”**: ç›¸å…³çŸ¥è¯†ç‚¹å’Œå­¦ä¹ å»ºè®®

è¾“å‡ºæ ¼å¼:
{{
    "score": åˆ†æ•°,
    "confidence": ç½®ä¿¡åº¦,
    "errors": [
        {{
            "type": "é”™è¯¯ç±»å‹",
            "description": "é”™è¯¯è¯´æ˜",
            "correct_answer": "æ­£ç¡®ç­”æ¡ˆ",
            "deduction": æ‰£åˆ†
        }}
    ],
    "overall_comment": "æ€»ä½“è¯„ä»·",
    "strengths": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2"],
    "weaknesses": ["ä¸è¶³1", "ä¸è¶³2"],
    "suggestions": ["å»ºè®®1", "å»ºè®®2"],
    "knowledge_points": [
        {{
            "name": "çŸ¥è¯†ç‚¹åç§°",
            "mastery_level": æŒæ¡ç¨‹åº¦(0-100),
            "suggestion": "å­¦ä¹ å»ºè®®"
        }}
    ]
}}
"""
```

**æˆæœ¬å¯¹æ¯”**ï¼š
```
åŸè®¾è®¡: GradingAgent($0.008) + FeedbackAgent($0.005) = $0.013
ä¼˜åŒ–å: UnifiedAgent($0.010) = $0.010
èŠ‚çœ: 23%
```

---

### æ–¹æ¡ˆ2: æ‰¹é‡å¤„ç†ä¼˜åŒ–

**æ ¸å¿ƒæ€è·¯**: å°†å¤šä¸ªå­¦ç”Ÿçš„ä½œä¸šåˆå¹¶åˆ°ä¸€æ¬¡LLMè°ƒç”¨

```python
class BatchGradingAgent:
    """æ‰¹é‡æ‰¹æ”¹Agent - ä¸€æ¬¡å¤„ç†å¤šä»½ä½œä¸š"""
    
    async def batch_process(
        self, 
        submissions: List[GradingState],
        batch_size: int = 5
    ) -> List[GradingState]:
        """æ‰¹é‡å¤„ç†å¤šä»½ä½œä¸š"""
        
        # æ„å»ºæ‰¹é‡æç¤ºè¯
        prompt = self._build_batch_prompt(submissions)
        
        # ä¸€æ¬¡LLMè°ƒç”¨å¤„ç†å¤šä»½ä½œä¸š
        response = await self.llm.ainvoke(prompt)
        
        # è§£ææ‰¹é‡ç»“æœ
        results = self._parse_batch_results(response, len(submissions))
        
        return results
    
    def _build_batch_prompt(self, submissions: List[GradingState]) -> str:
        """æ„å»ºæ‰¹é‡æç¤ºè¯"""
        submissions_text = "\n\n".join([
            f"ã€å­¦ç”Ÿ{i+1}ç­”æ¡ˆã€‘\n{sub['extracted_text']}"
            for i, sub in enumerate(submissions)
        ])
        
        return f"""
è¯·æ‰¹æ”¹ä»¥ä¸‹{len(submissions)}ä»½å­¦ç”Ÿä½œä¸š:

ã€æ‰¹æ”¹æ ‡å‡†ã€‘
{submissions[0]["grading_standard"]}

{submissions_text}

è¯·ä¸ºæ¯ä»½ä½œä¸šåˆ†åˆ«è¾“å‡ºæ‰¹æ”¹ç»“æœ,æ ¼å¼ä¸ºJSONæ•°ç»„:
[
    {{"student_index": 1, "score": ..., "errors": [...], ...}},
    {{"student_index": 2, "score": ..., "errors": [...], ...}},
    ...
]
"""
```

**æˆæœ¬å¯¹æ¯”**ï¼š
```
åŸè®¾è®¡: 5ä»½ä½œä¸š Ã— $0.010 = $0.050
æ‰¹é‡å¤„ç†: 1æ¬¡è°ƒç”¨ = $0.020
èŠ‚çœ: 60%
```

**æ³¨æ„äº‹é¡¹**ï¼š
- âš ï¸ æ‰¹é‡å¤§å°ä¸å®œè¿‡å¤§(å»ºè®®3-5ä»½)
- âš ï¸ éœ€è¦ç¡®ä¿LLMèƒ½æ­£ç¡®åŒºåˆ†ä¸åŒå­¦ç”Ÿçš„ç­”æ¡ˆ
- âš ï¸ é€‚åˆç®€å•ã€æ ‡å‡†åŒ–çš„ä½œä¸š

---

### æ–¹æ¡ˆ3: æ™ºèƒ½ç¼“å­˜ç­–ç•¥

**æ ¸å¿ƒæ€è·¯**: ç¼“å­˜ç›¸ä¼¼é—®é¢˜çš„æ‰¹æ”¹ç»“æœ

```python
class CachedGradingAgent:
    """å¸¦ç¼“å­˜çš„æ‰¹æ”¹Agent"""
    
    def __init__(self):
        self.cache = GradingCache()
        self.similarity_threshold = 0.85
    
    async def process(self, state: GradingState) -> GradingState:
        """å¸¦ç¼“å­˜çš„æ‰¹æ”¹"""
        
        # 1. è®¡ç®—ç­”æ¡ˆæŒ‡çº¹
        answer_hash = self._compute_hash(state["extracted_text"])
        
        # 2. æŸ¥æ‰¾ç›¸ä¼¼çš„ç¼“å­˜ç»“æœ
        cached_result = await self.cache.find_similar(
            answer_hash,
            threshold=self.similarity_threshold
        )
        
        if cached_result:
            logger.info("Cache hit! Reusing previous grading result")
            # ä½¿ç”¨ç¼“å­˜ç»“æœ,ç¨ä½œè°ƒæ•´
            return self._adapt_cached_result(cached_result, state)
        
        # 3. ç¼“å­˜æœªå‘½ä¸­,è°ƒç”¨LLM
        result = await self._call_llm(state)
        
        # 4. ç¼“å­˜ç»“æœ
        await self.cache.store(answer_hash, result)
        
        return result
    
    def _compute_hash(self, text: str) -> str:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦å“ˆå¸Œ"""
        # ä½¿ç”¨SimHashæˆ–MinHash
        from simhash import Simhash
        return str(Simhash(text).value)
    
    async def _adapt_cached_result(
        self, 
        cached: Dict, 
        current: GradingState
    ) -> GradingState:
        """è°ƒæ•´ç¼“å­˜ç»“æœä»¥é€‚åº”å½“å‰ä»»åŠ¡"""
        # ä¿ç•™æ ¸å¿ƒæ‰¹æ”¹ç»“æœ,ä½†æ›´æ–°æ—¶é—´æˆ³ç­‰å…ƒæ•°æ®
        current.update({
            "score": cached["score"],
            "errors": cached["errors"],
            "confidence": cached["confidence"] * 0.95,  # ç•¥å¾®é™ä½ç½®ä¿¡åº¦
            "feedback_text": cached["feedback_text"],
            "from_cache": True
        })
        return current
```

**æˆæœ¬èŠ‚çœ**ï¼š
```
å‡è®¾ç¼“å­˜å‘½ä¸­ç‡30%:
åŸæˆæœ¬: $300/æœˆ
ä¼˜åŒ–å: $300 Ã— (1 - 0.3) = $210/æœˆ
èŠ‚çœ: 30%
```

---

### æ–¹æ¡ˆ4: åˆ†å±‚å®šä»·ç­–ç•¥

**æ ¸å¿ƒæ€è·¯**: è®©ç”¨æˆ·é€‰æ‹©ä¸åŒçš„æ‰¹æ”¹è´¨é‡ç­‰çº§

```python
class TieredGradingService:
    """åˆ†å±‚æ‰¹æ”¹æœåŠ¡"""
    
    PRICING_TIERS = {
        "basic": {
            "name": "åŸºç¡€æ‰¹æ”¹",
            "price": 0.5,  # å…ƒ/æ¬¡
            "features": ["è‡ªåŠ¨è¯„åˆ†", "é”™è¯¯æ ‡æ³¨"],
            "agent_mode": "fast",
            "llm_model": "gpt-3.5-turbo"
        },
        "standard": {
            "name": "æ ‡å‡†æ‰¹æ”¹",
            "price": 1.0,  # å…ƒ/æ¬¡
            "features": ["è‡ªåŠ¨è¯„åˆ†", "é”™è¯¯æ ‡æ³¨", "è¯¦ç»†åé¦ˆ"],
            "agent_mode": "standard",
            "llm_model": "gpt-4-turbo"
        },
        "premium": {
            "name": "ç²¾å“æ‰¹æ”¹",
            "price": 2.0,  # å…ƒ/æ¬¡
            "features": ["è‡ªåŠ¨è¯„åˆ†", "é”™è¯¯æ ‡æ³¨", "è¯¦ç»†åé¦ˆ", "å­¦ä¹ å»ºè®®", "äººå·¥å®¡æ ¸"],
            "agent_mode": "premium",
            "llm_model": "gpt-4-turbo"
        }
    }
    
    async def grade_with_tier(
        self, 
        submission_id: UUID,
        tier: str = "standard"
    ) -> GradingResult:
        """æ ¹æ®ç­‰çº§è¿›è¡Œæ‰¹æ”¹"""
        config = self.PRICING_TIERS[tier]
        
        # ä½¿ç”¨å¯¹åº”çš„Agentæ¨¡å¼å’Œæ¨¡å‹
        orchestrator = SmartOrchestrator(
            mode=config["agent_mode"],
            llm_model=config["llm_model"]
        )
        
        result = await orchestrator.execute({
            "submission_id": submission_id,
            "tier": tier
        })
        
        return result
```

---

## 3. æ¨èå®æ–½æ–¹æ¡ˆ

### é˜¶æ®µ1: ç«‹å³å®æ–½ (æˆæœ¬èŠ‚çœ ~40%)

```python
# 1. å®ç°æ™ºèƒ½Agentèåˆ
class OptimizedOrchestrator:
    """ä¼˜åŒ–åçš„ç¼–æ’å™¨"""
    
    async def execute(self, input_data: Dict) -> Dict:
        # é»˜è®¤ä½¿ç”¨å¿«é€Ÿæ¨¡å¼
        mode = input_data.get("mode", "fast")
        
        if mode == "fast":
            # å•æ¬¡LLMè°ƒç”¨å®Œæˆæ‰¹æ”¹+åé¦ˆ
            return await self.unified_agent.process(input_data)
        
        elif mode == "standard":
            # æ‰¹æ”¹ + è§„åˆ™å®¡æ ¸ + ç®€å•åé¦ˆ
            state = await self.grading_agent.process(input_data)
            state = await self.review_agent.process(state)  # ä¸è°ƒç”¨LLM
            return state
        
        else:  # premium
            # å®Œæ•´æµç¨‹
            return await self.full_pipeline(input_data)

# 2. æ·»åŠ æ™ºèƒ½ç¼“å­˜
@cache_similar(similarity_threshold=0.85)
async def grade_submission(submission_id: UUID):
    return await grading_agent.process(submission_id)
```

**é¢„æœŸæ•ˆæœ**ï¼š
- æˆæœ¬ä» $0.015 é™è‡³ $0.009
- èŠ‚çœ 40%
- é€Ÿåº¦æå‡ 30%

---

### é˜¶æ®µ2: ä¸­æœŸä¼˜åŒ– (æˆæœ¬èŠ‚çœ ~60%)

```python
# 3. å®ç°æ‰¹é‡å¤„ç†
async def batch_grade_class(assignment_id: UUID):
    """æ‰¹é‡æ‰¹æ”¹æ•´ä¸ªç­çº§çš„ä½œä¸š"""
    submissions = await get_submissions(assignment_id)
    
    # æŒ‰ç›¸ä¼¼åº¦åˆ†ç»„
    groups = group_by_similarity(submissions, group_size=5)
    
    # æ‰¹é‡å¤„ç†æ¯ç»„
    results = []
    for group in groups:
        batch_result = await batch_grading_agent.process(group)
        results.extend(batch_result)
    
    return results

# 4. ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹
class ModelSelector:
    """æ™ºèƒ½æ¨¡å‹é€‰æ‹©"""
    
    def select_model(self, complexity: str) -> str:
        if complexity == "simple":
            return "gpt-3.5-turbo"  # $0.001/1K tokens
        elif complexity == "medium":
            return "gpt-4-turbo"    # $0.01/1K tokens
        else:
            return "gpt-4"          # $0.03/1K tokens
```

**é¢„æœŸæ•ˆæœ**ï¼š
- æ‰¹é‡å¤„ç†èŠ‚çœ 50%
- æ¨¡å‹é€‰æ‹©èŠ‚çœ 30%
- ç»¼åˆèŠ‚çœ 60%

---

### é˜¶æ®µ3: é•¿æœŸä¼˜åŒ– (æˆæœ¬èŠ‚çœ ~80%)

```python
# 5. è®­ç»ƒä¸“ç”¨æ¨¡å‹
class CustomGradingModel:
    """å¾®è°ƒçš„ä¸“ç”¨æ‰¹æ”¹æ¨¡å‹"""
    
    def __init__(self):
        # ä½¿ç”¨å¼€æºæ¨¡å‹å¾®è°ƒ
        self.model = load_finetuned_model("grading-model-v1")
    
    async def grade(self, submission):
        # ä½¿ç”¨è‡ªå·±çš„æ¨¡å‹,æˆæœ¬æä½
        return await self.model.predict(submission)

# 6. æ··åˆç­–ç•¥
async def hybrid_grading(submission):
    """æ··åˆä½¿ç”¨è‡ªæœ‰æ¨¡å‹å’ŒAPI"""
    
    # å…ˆç”¨è‡ªæœ‰æ¨¡å‹å¿«é€Ÿæ‰¹æ”¹
    quick_result = await custom_model.grade(submission)
    
    # å¦‚æœç½®ä¿¡åº¦ä½,å†ç”¨GPT-4å®¡æ ¸
    if quick_result.confidence < 0.8:
        final_result = await gpt4_agent.review(quick_result)
    else:
        final_result = quick_result
    
    return final_result
```

**é¢„æœŸæ•ˆæœ**ï¼š
- 80%çš„ç®€å•ä»»åŠ¡ç”¨è‡ªæœ‰æ¨¡å‹(æˆæœ¬ ~$0.001)
- 20%çš„å¤æ‚ä»»åŠ¡ç”¨GPT-4(æˆæœ¬ ~$0.015)
- ç»¼åˆæˆæœ¬: $0.003
- èŠ‚çœ 80%

---

## 4. æˆæœ¬å¯¹æ¯”æ€»ç»“

| æ–¹æ¡ˆ | å•æ¬¡æˆæœ¬ | æœˆåº¦æˆæœ¬(1000æ¬¡/å¤©) | èŠ‚çœæ¯”ä¾‹ | å®æ–½éš¾åº¦ |
|------|---------|-------------------|---------|---------|
| åŸè®¾è®¡(å®Œæ•´æ¨¡å¼) | $0.015 | $450 | 0% | - |
| æ™ºèƒ½èåˆ | $0.009 | $270 | 40% | â­ ç®€å• |
| + æ‰¹é‡å¤„ç† | $0.006 | $180 | 60% | â­â­ ä¸­ç­‰ |
| + æ™ºèƒ½ç¼“å­˜ | $0.004 | $120 | 73% | â­â­ ä¸­ç­‰ |
| + è‡ªæœ‰æ¨¡å‹ | $0.003 | $90 | 80% | â­â­â­ å›°éš¾ |

---

## 5. æœ€ç»ˆå»ºè®®

### æ¨èæ–¹æ¡ˆ: æ™ºèƒ½Agentèåˆ + åˆ†å±‚å®šä»·

```python
class ProductionGradingSystem:
    """ç”Ÿäº§ç¯å¢ƒæ‰¹æ”¹ç³»ç»Ÿ"""
    
    def __init__(self):
        self.unified_agent = UnifiedGradingAgent()  # å¿«é€Ÿæ¨¡å¼
        self.standard_pipeline = StandardPipeline()  # æ ‡å‡†æ¨¡å¼
        self.premium_pipeline = PremiumPipeline()    # å®Œæ•´æ¨¡å¼
        self.cache = GradingCache()
    
    async def grade(
        self, 
        submission_id: UUID,
        tier: str = "standard"
    ) -> GradingResult:
        """æ™ºèƒ½æ‰¹æ”¹"""
        
        # 1. æ£€æŸ¥ç¼“å­˜
        cached = await self.cache.get(submission_id)
        if cached:
            return cached
        
        # 2. è¯„ä¼°å¤æ‚åº¦
        complexity = await self._assess_complexity(submission_id)
        
        # 3. é€‰æ‹©æ‰§è¡Œç­–ç•¥
        if tier == "basic" or complexity == "simple":
            result = await self.unified_agent.process(submission_id)
        elif tier == "standard":
            result = await self.standard_pipeline.process(submission_id)
        else:  # premium
            result = await self.premium_pipeline.process(submission_id)
        
        # 4. ç¼“å­˜ç»“æœ
        await self.cache.set(submission_id, result)
        
        return result
```

### å®šä»·å»ºè®®

| å¥—é¤ | ä»·æ ¼ | æˆæœ¬ | åˆ©æ¶¦ç‡ | é€‚ç”¨åœºæ™¯ |
|------|------|------|--------|---------|
| åŸºç¡€ç‰ˆ | Â¥0.5/æ¬¡ | Â¥0.06 | 88% | ç®€å•é€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜ |
| æ ‡å‡†ç‰ˆ | Â¥1.0/æ¬¡ | Â¥0.09 | 91% | ä¸€èˆ¬ä¸»è§‚é¢˜ |
| ç²¾å“ç‰ˆ | Â¥2.0/æ¬¡ | Â¥0.15 | 92% | å¤æ‚è®ºè¿°é¢˜ã€ä½œæ–‡ |

---

## 6. å®æ–½æ£€æŸ¥æ¸…å•

- [ ] å®ç°UnifiedGradingAgent
- [ ] å®ç°æ™ºèƒ½å¤æ‚åº¦è¯„ä¼°
- [ ] æ·»åŠ ç›¸ä¼¼åº¦ç¼“å­˜
- [ ] å®ç°åˆ†å±‚å®šä»·
- [ ] æ·»åŠ æˆæœ¬ç›‘æ§
- [ ] è¿›è¡ŒA/Bæµ‹è¯•
- [ ] ä¼˜åŒ–æç¤ºè¯é•¿åº¦
- [ ] å®ç°æ‰¹é‡å¤„ç†(å¯é€‰)

---

**æ€»ç»“**: é€šè¿‡æ™ºèƒ½Agentèåˆ,å¯ä»¥åœ¨ä¿æŒæ‰¹æ”¹è´¨é‡çš„åŒæ—¶,å°†æˆæœ¬é™ä½40-60%,å¹¶ä¸ºç”¨æˆ·æä¾›çµæ´»çš„é€‰æ‹©ã€‚

